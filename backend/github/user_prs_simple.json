[
  {
    "source": "github",
    "candidate_id": "github_pr_97449",
    "raw_data": {
      "pr_title": "Add RBAC test for the bulk secondary register host",
      "pr_summary": "## Summary:\n- Added rbac check for bulk secondary register api.\r\n- Created request and response message protos for the same.\r\n\r\nRBAC Design:\r\nhttps://docs.google.com/document/d/1PfqHPiWWrg6N2iZ3pvJ1Boub6fBDY56Vxj1mp_ydrhQ/edit?tab=t.0#heading=h.udxd12mbwnoc\r\n\r\nMCR Design:\r\nhttps://docs.google.com/document/d/1AlLURIn1x6pgJ6YFT655KJy15EHmtXDgEDdGDnKa-7c/edit?tab=t.0#heading=h.9b8h6v6gn4me\n\n## Test Plan:\nUnit tests\n\n## JIRA Issues:\nSPARK-572184\n\n## Revert Plan:\n## PR Stack:\nStack from arc wrapper with help from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):\n* #97821\n* #97551\n* #97450\n* __->__ #97449\n",
      "pr_url": "https://github.com/scaledata/sdmain/pull/97449",
      "metadata": {
        "number": 97449,
        "state": "open",
        "author": "moht-agrawal-rubrik",
        "created_at": "2025-09-02T06:40:19Z",
        "updated_at": "2025-09-10T07:05:04Z",
        "merged_at": null,
        "base_branch": "master",
        "head_branch": "gh/moht-agrawal-rubrik/15/head",
        "labels": [
          "SAILING"
        ],
        "assignees": [
          "punosp",
          "avinashb-17",
          "mthilesh-karnati",
          "ramanguleria",
          "Nagavenimythri",
          "Arqum212"
        ],
        "reviewers": [
          "ilya-netchitailo",
          "ramanguleria",
          "Nagavenimythri"
        ]
      },
      "comments": {
        "global_comments": [
          {
            "type": "discussion",
            "author": "rogers-sail-information[bot]",
            "created_at": "2025-09-02T06:40:44Z",
            "body": "<!-- rogers sail info comment -->\n## Sail Information: ([badmnr-reyoxj4](https://rogers.rubrik.com/api/sail_requests/badmnr-reyoxj4/))\n\n\n\n\n\n> \n> [!NOTE]\n> CI is currently running. You'll receive updates as each step completes.\n> \n> <sub><b>Sail Status:</b> \u231bSAILING</sub>\n\n\n\n\n\n\n#### \u26f5 Sail Steps\n\n<table>\n  <thead>\n    <tr>\n      <th>Jobs</th>\n      <th>Time Created</th>\n      <th>Status</th>\n      <th>Message</th>\n    </tr>\n  </thead>\n  <tbody>\n  \n  <tr>\n    <td><a href=\"https://arc-reactor.stark.rubrik.com/job/ARC_Expedited_Build_CDM_Colo_BB/54188\">ARC_Expedited_Build_CDM_Colo_BB</a></td>\n    <td>2025-09-09 18:43 UTC</td>\n    <td>\u2705 <a href=\"https://rogers.rubrik.com/api/jenkins_job_steps/74ppt6-cxt3gcc/\">SUCCEEDED</a></td>\n    <td></td>\n  </tr>\n  \n  <tr>\n    <td><a href=\"https://arc-reactor.stark.rubrik.com/job/ARC_Jedi_Build_Colo/41289\">ARC_Jedi_Build_Colo</a></td>\n    <td>2025-09-09 18:43 UTC</td>\n    <td>\u2705 <a href=\"https://rogers.rubrik.com/api/jenkins_job_steps/m425wd-qvrmzww/\">SUCCEEDED</a></td>\n    <td></td>\n  </tr>\n  \n  <tr>\n    <td><a href=\"https://polaris-arc-reactor.stark.rubrik.com/job/ARC_Build_Polaris/457078/display/redirect\">ARC_Build_Polaris</a></td>\n    <td>2025-09-09 18:43 UTC</td>\n    <td>\u2705 <a href=\"https://rogers.rubrik.com/api/jenkins_job_steps/fuiaws-kuwdtne/\">SUCCEEDED</a></td>\n    <td></td>\n  </tr>\n  \n  <tr>\n    <td><a href=\"https://polaris-arc-reactor.stark.rubrik.com/job/ARC_Land_Polaris\">ARC_Land_Polaris</a></td>\n    <td>2025-09-09 18:43 UTC</td>\n    <td>\u26aa <a href=\"https://rogers.rubrik.com/api/jenkins_job_steps/ercce7-kuzjj32/\">QUEUED</a></td>\n    <td>PR97449 for sail Sail(sid=7tqvqj-thxbqai) has failed required check run Pull Request Approval Status with status `completed` and conclusion `failure`.  See https://github.com/scaledata/sdmain/runs/49989653408 for more details. Keeping the step queued.</td>\n  </tr>\n  \n  </tbody>\n</table>\n\n\n\n---\n\n<sub>\n<b><a href=\"https://github.com/scaledata/sdmain/runs/49976342891\">Previous Sail Requests (4)</a></b> | <b>Last Updated:</b> 2025-09-10 07:04 UTC<br><br>\n</sub>\n\n\n\n\n",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3243991227"
          },
          {
            "type": "discussion",
            "author": "SD-111029",
            "created_at": "2025-09-02T06:56:07Z",
            "body": "\nBackward compatibility guidelines: https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2269250186\n\n```\nBACKWARD COMPATIBILITY CHECK REPORT\n\n=========================================================\nPROTOBUF REPORT (#polaris-backward-compatibility-reviews)\n=========================================================\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:70:/message::BulkRegisterSecondaryHostsReq/field::2 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:73:/message::BulkRegisterSecondaryHostsReq/field::3 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:91:/message::BulkRegisterSecondaryHostsReply/field::1 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n==================================\nFEATURE FLAG REPORT (#sre-reviews)\n==================================\nLooks good. No feature flags removed.\n\n```\n",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3244030318"
          },
          {
            "type": "discussion",
            "author": "polaris-jenkins-sails[bot]",
            "created_at": "2025-09-03T03:16:02Z",
            "body": "<h2>Coverage Report</h2> <table> <tr><th>PR/PRs</th><th>Upstream</th> <th>Diff (delta)</th><th>New (# new lines)</th> <th>Passed</th><th>Notes</th></tr><tr> <td><b>PR97449</b></td><td>N/A</td><td>N/A (0)</td><td><a href='https://vision.stark.rubrik.com/component_measures?id=polaris-test&metric=new_lines_to_cover&branch=PR97449&view=list'>0</a></td><td>:white_check_mark:</td><td></td> </tr> </table><b> NOTE: </b><i>If you encounter any issues with the coverage calculation or reporting, please reach out to us on #stark-dev-experience. <b>Coverage bot will be approved during sail before land stage if your PR met the coverage criteria<b/>.</i><br/><br/><p><a href='https://polaris-arc-reactor.stark.rubrik.com/job/polaris_diff_coverage/434313/'>Jenkins Build Link</a></p>",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3247542036"
          },
          {
            "type": "discussion",
            "author": "polaris-jenkins-sails[bot]",
            "created_at": "2025-09-03T05:05:19Z",
            "body": "<h2>Coverage Report</h2> <table> <tr><th>PR/PRs</th><th>Upstream</th> <th>Diff (delta)</th><th>New (# new lines)</th> <th>Passed</th><th>Notes</th></tr><tr> <td><b>PR97449</b></td><td>N/A</td><td>N/A (0)</td><td><a href='https://vision.stark.rubrik.com/component_measures?id=polaris-test&metric=new_lines_to_cover&branch=PR97449&view=list'>0</a></td><td>:white_check_mark:</td><td></td> </tr> </table><b> NOTE: </b><i>If you encounter any issues with the coverage calculation or reporting, please reach out to us on #stark-dev-experience. <b>Coverage bot will be approved during sail before land stage if your PR met the coverage criteria<b/>.</i><br/><br/><p><a href='https://polaris-arc-reactor.stark.rubrik.com/job/polaris_diff_coverage/434335/'>Jenkins Build Link</a></p>",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3247698930"
          },
          {
            "type": "discussion",
            "author": "SD-111029",
            "created_at": "2025-09-03T11:33:50Z",
            "body": "\nBackward compatibility guidelines: https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2269250186\n\n```\nBACKWARD COMPATIBILITY CHECK REPORT\n\n=========================================================\nPROTOBUF REPORT (#polaris-backward-compatibility-reviews)\n=========================================================\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:70:/message::BulkRegisterSecondaryHostsReq/field::2 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:73:/message::BulkRegisterSecondaryHostsReq/field::3 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:91:/message::BulkRegisterSecondaryHostsReply/field::1 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n==================================\nFEATURE FLAG REPORT (#sre-reviews)\n==================================\nLooks good. No feature flags removed.\n\n```\n",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3248860365"
          },
          {
            "type": "discussion",
            "author": "SD-111029",
            "created_at": "2025-09-03T11:56:08Z",
            "body": "\nBackward compatibility guidelines: https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2269250186\n\n```\nBACKWARD COMPATIBILITY CHECK REPORT\n\n=========================================================\nPROTOBUF REPORT (#polaris-backward-compatibility-reviews)\n=========================================================\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:70:/message::BulkRegisterSecondaryHostsReq/field::2 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:73:/message::BulkRegisterSecondaryHostsReq/field::3 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:91:/message::BulkRegisterSecondaryHostsReply/field::1 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n==================================\nFEATURE FLAG REPORT (#sre-reviews)\n==================================\nLooks good. No feature flags removed.\n\n```\n",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3248938866"
          },
          {
            "type": "discussion",
            "author": "polaris-jenkins-sails[bot]",
            "created_at": "2025-09-03T12:09:59Z",
            "body": "<h2>Coverage Report</h2> <table> <tr><th>PR/PRs</th><th>Upstream</th> <th>Diff (delta)</th><th>New (# new lines)</th> <th>Passed</th><th>Notes</th></tr><tr> <td><b>PR97449</b></td><td>N/A</td><td>N/A (0)</td><td><a href='https://vision.stark.rubrik.com/component_measures?id=polaris-test&metric=new_lines_to_cover&branch=PR97449&view=list'>0</a></td><td>:white_check_mark:</td><td></td> </tr> </table><b> NOTE: </b><i>If you encounter any issues with the coverage calculation or reporting, please reach out to us on #stark-dev-experience. <b>Coverage bot will be approved during sail before land stage if your PR met the coverage criteria<b/>.</i><br/><br/><p><a href='https://polaris-arc-reactor.stark.rubrik.com/job/polaris_diff_coverage/434464/'>Jenkins Build Link</a></p>",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3248984548"
          },
          {
            "type": "discussion",
            "author": "SD-111029",
            "created_at": "2025-09-03T12:39:11Z",
            "body": "\nBackward compatibility guidelines: https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2269250186\n\n```\nBACKWARD COMPATIBILITY CHECK REPORT\n\n=========================================================\nPROTOBUF REPORT (#polaris-backward-compatibility-reviews)\n=========================================================\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:70:/message::BulkRegisterSecondaryHostsReq/field::2 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:73:/message::BulkRegisterSecondaryHostsReq/field::3 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:91:/message::BulkRegisterSecondaryHostsReply/field::1 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n==================================\nFEATURE FLAG REPORT (#sre-reviews)\n==================================\nLooks good. No feature flags removed.\n\n```\n",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3249083207"
          },
          {
            "type": "discussion",
            "author": "SD-111029",
            "created_at": "2025-09-03T13:11:07Z",
            "body": "\nBackward compatibility guidelines: https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2269250186\n\n```\nBACKWARD COMPATIBILITY CHECK REPORT\n\n=========================================================\nPROTOBUF REPORT (#polaris-backward-compatibility-reviews)\n=========================================================\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:70:/message::BulkRegisterSecondaryHostsReq/field::2 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:73:/message::BulkRegisterSecondaryHostsReq/field::3 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:91:/message::BulkRegisterSecondaryHostsReply/field::1 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n==================================\nFEATURE FLAG REPORT (#sre-reviews)\n==================================\nLooks good. No feature flags removed.\n\n```\n",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3249198343"
          },
          {
            "type": "discussion",
            "author": "polaris-jenkins-sails[bot]",
            "created_at": "2025-09-03T13:21:27Z",
            "body": "<h2>Coverage Report</h2> <table> <tr><th>PR/PRs</th><th>Upstream</th> <th>Diff (delta)</th><th>New (# new lines)</th> <th>Passed</th><th>Notes</th></tr><tr> <td><b>PR97449</b></td><td>N/A</td><td>N/A (0)</td><td><a href='https://vision.stark.rubrik.com/component_measures?id=polaris-test&metric=new_lines_to_cover&branch=PR97449&view=list'>0</a></td><td>:white_check_mark:</td><td></td> </tr> </table><b> NOTE: </b><i>If you encounter any issues with the coverage calculation or reporting, please reach out to us on #stark-dev-experience. <b>Coverage bot will be approved during sail before land stage if your PR met the coverage criteria<b/>.</i><br/><br/><p><a href='https://polaris-arc-reactor.stark.rubrik.com/job/polaris_diff_coverage/434481/'>Jenkins Build Link</a></p>",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3249238893"
          },
          {
            "type": "discussion",
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-04T07:16:24Z",
            "body": "_:hourglass: Your RR [scaledata/sdmain/97449](https://github.com/scaledata/sdmain/pull/97449) has not been reviewed within the SLO. Resigning the following blocking reviewers:_\n * @scaledata/polaris-backward-compatibility-polaris-backward-compatibility-reviews",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3252256819"
          },
          {
            "type": "discussion",
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-04T07:46:58Z",
            "body": "_:hourglass: Your RR [scaledata/sdmain/97449](https://github.com/scaledata/sdmain/pull/97449) has not been reviewed within the SLO. Resigning the following blocking reviewers:_\n * @scaledata/rba-shadow\n * @scaledata/rba-rba-reviews",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3252357693"
          },
          {
            "type": "discussion",
            "author": "moht-agrawal-rubrik",
            "created_at": "2025-09-04T10:46:22Z",
            "body": "> not from security perspective but from performance perspective futures should be better ? WDYT ?\r\n\r\n@punosp\r\nI think we are fine with this implementation also. Realistically, the majority of time will be spent by the CDM (The API is implemented in the next stacked diff). Even if we optimise this with multi-threading, the overall gains in the API will not be much. Though, can't say much without benchmarking it with different number of hosts.",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3253066605"
          },
          {
            "type": "discussion",
            "author": "rubrik-alfred[bot]",
            "created_at": "2025-09-09T18:39:41Z",
            "body": "## :man_in_tuxedo: Alfred Comments\n<input type='hidden' commit='019d1b3aafd388520f2d4f17bccf712a22da0f00' global='true'/>\n<!--Header_Done-->\n\nChanges on RBAC policies or `CustomRbacCheck` should be reviewed by #security-leads_security-leads-code-review according to [RSC RBAC Policy review guideline](https://rubrik.atlassian.net/wiki/spaces/EN/pages/2812282937/How+to+Review+RSC+RBAC+Policy).\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala</code></li>\n<li><code>polaris/src/rubrik/api-server/test/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImplTest.scala</code></li>\n</ul>\n</details>\n\n\n------\n\nAll changes to the API server and associated files have to be reviewed by Polaris API team #gql-sdmain_get_reviews_on_gql-sdmain.      \n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code></li>\n</ul>\n</details>\n\n\n------\n\nAll changes to public GraphQL API have to be reviewed by Polaris Documentation team #rsc_documentation_rsc_doc_diff_reviews.      \n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql</code></li>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql</code></li>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code></li>\n</ul>\n</details>\n\n\n------\n\nTriggering the GqlSchema_Check job.\n\n\nThe following jobs are triggered:\n\n\n- [GqlSchema_Check](https://polaris-builds.stark.rubrik.com/job/GqlSchema_Check)\n\n\n<details>\n<summary>Click here to view the file paths triggering these jobs</summary>\n<ul>\n<li><code>polaris/src/rubrik/api-server/app/services/physicalhost/rbac/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala</code></li>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql</code></li>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql</code></li>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code></li>\n<li><code>polaris/src/rubrik/api-server/test/app/services/physicalhost/rbac/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/api-server/test/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImplTest.scala</code></li>\n<li><code>polaris/src/rubrik/physicalhost/proto/physicalhost.proto</code></li>\n</ul>\n</details>\n\n\n------\n\nBelow coding pattern require review from #rsc-perf-anti-pattern-reviews.\n\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala</code></li>\n</ul>\n</details>\n\n\n------\n\nTriggering the detect-changed-services pipeline. If your PR is raised against a Polaris release branch, this pipeline will leave a comment with a list of the services that will be affected by the changes in your PR.\n\n\nThe following jobs are triggered:\n\n\n- [detect-changed-services](https://polaris-builds.stark.rubrik.com/job/detect-changed-services)\n\n\n<details>\n<summary>Click here to view the file paths triggering these jobs</summary>\n<ul>\n<li><code>polaris/src/rubrik/api-server/app/services/physicalhost/rbac/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala</code></li>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql</code></li>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql</code></li>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code></li>\n<li><code>polaris/src/rubrik/api-server/test/app/services/physicalhost/rbac/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/api-server/test/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImplTest.scala</code></li>\n<li><code>polaris/src/rubrik/global-api/schema/schema.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/proto/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/physicalhost/proto/physicalhost.proto</code></li>\n<li><code>polaris/yodalibs/generated/gql_inputs.py</code></li>\n</ul>\n</details>\n\n\n------\n\nPolaris Backward Compatibility changes will be reviewed by Edith Automated Review.\n\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/physicalhost/proto/physicalhost.proto</code></li>\n</ul>\n</details>\n\n\n------\n\nChanges in dlc related files require review from #polaris-dlc-reviewers_get_review_on_dlc-review. Please refer [wiki](https://rubrik.atlassian.net/wiki/spaces/EN/pages/2859927199/DLC+Code+Review+Guidelines) for guidlines.\n\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql</code></li>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql</code></li>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code></li>\n</ul>\n</details>\n\n\n------\n\nChanges within polaris/src/rubrik/ need review by polaris_code_coverage_reviewer:. Please see [Code Coverage @Rubrik](https://docs.google.com/document/d/17OJ1OUG77mMJEhgXQMZYIvT17dLbOMUZkSvrsuvQdjY/edit?usp=sharing)\n\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/global-api/schema/schema.go</code></li>\n</ul>\n</details>\n\n\n------\n\nDuring the upgrade, this code will be talking to services from the release currently in production. That means to avoid outages, we should be backwards compatible to the previous release.\n\nhttps://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2269250186/Polaris+Version+Compatibility+Guidelines\n\nThe following jobs is triggered [backward-compatibility-check](https://polaris-builds.stark.rubrik.com/job/backward-compatibility-check/).\nPlease make sure to check the status of the job.\n\n\n------\n\nChanges in RBA code require review from #rba_rba-reviews. For guidelines, please check [RBA Code Review Checklist](https://rubrik.atlassian.net/wiki/spaces/EN/pages/3835331585/RBA+Code+Review+Checklist).\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/api-server/app/services/physicalhost/rbac/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala</code></li>\n<li><code>polaris/src/rubrik/api-server/test/app/services/physicalhost/rbac/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/api-server/test/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImplTest.scala</code></li>\n<li><code>polaris/src/rubrik/physicalhost/proto/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/physicalhost/proto/physicalhost.proto</code></li>\n</ul>\n</details>\n\n\n------\n\n<!--Footer_Start-->\n\n",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3271865285"
          },
          {
            "type": "discussion",
            "author": "polaris-jenkins-sails[bot]",
            "created_at": "2025-09-09T19:01:00Z",
            "body": "<h2>Coverage Report</h2> <table> <tr><th>PR/PRs</th><th>Upstream</th> <th>Diff (delta)</th><th>New (# new lines)</th> <th>Passed</th><th>Notes</th></tr><tr> <td><b>PR97449</b></td><td>N/A</td><td>N/A (0)</td><td><a href='https://vision.stark.rubrik.com/component_measures?id=polaris-test&metric=new_lines_to_cover&branch=PR97449&view=list'>0</a></td><td>:white_check_mark:</td><td></td> </tr> </table><b> NOTE: </b><i>If you encounter any issues with the coverage calculation or reporting, please reach out to us on #stark-dev-experience. <b>Coverage bot will be approved during sail before land stage if your PR met the coverage criteria<b/>.</i><br/><br/><p><a href='https://polaris-arc-reactor.stark.rubrik.com/job/polaris_diff_coverage/435986/'>Jenkins Build Link</a></p>",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3271930173"
          }
        ],
        "inline_comments": [
          {
            "author": "moht-agrawal-rubrik",
            "created_at": "2025-09-02T06:50:14Z",
            "body": "borrowing this from the api-v1 implementation.\r\nref: `polaris/src/rubrik/api-server/app/apps/physicalhost/schema/rbac/PhysicalHostRbacPolicies.scala`",
            "file_path": "polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala",
            "line_number": 40,
            "diff_hunk": "@@ -1,17 +1,243 @@\n package services.physicalhost.rbac\n \n+import authzservice.authzservice.InventorySubHierarchyRootEnum.LINUX_HOST_ROOT\n+import authzservice.authzservice.InventorySubHierarchyRootEnum.WINDOWS_HOST_ROOT\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister.HostRegisterOsType\n+import dal.grpc.UnifiedFeatureFlagService\n+import javax.inject.Inject\n+import models.graphql.AttributedFeatureFlagName\n+import models.graphql.FeatureFlagAttribute\n+import models.graphql.FlagAttribute\n import physicalhost.physicalhost.BulkRegisterSecondaryHostsReq\n import sangria.schema.Context\n import security.UserContext\n-import security.rbac.AdminOrOwnerAccessForDev\n+import security.rbac.And\n+import security.rbac.CustomRbacCheck\n+import security.rbac.CustomRbacCheckResult\n+import security.rbac.MoreRbacChecksNeeded\n+import security.rbac.Operation.AddInventory\n+import security.rbac.Operation.Ctx\n+import security.rbac.Operation.ManageDataSource\n+import security.rbac.Or\n+import security.rbac.RbacCheck\n import security.rbac.RbacPolicy\n \n-class PhysicalHostRbacPoliciesImpl extends PhysicalHostRbacPolicies {\n+class PhysicalHostRbacPoliciesImpl @Inject() (\n+  uffs: UnifiedFeatureFlagService\n+) extends PhysicalHostRbacPolicies {\n   // Add your custom RBAC policies here\n   def bulkRegisterSecondaryHosts(\n     argSupplier: Context[UserContext, _] => BulkRegisterSecondaryHostsReq\n   ): RbacPolicy = {\n-    // TODO(SPARK-572184): Add RBAC policy\n-    RbacPolicy(AdminOrOwnerAccessForDev)\n+    RbacPolicy(\n+      BulkSecondaryRegisterHostRbacCheck(argSupplier, uffs)\n+    )\n+  }\n+\n+  // TODO SPARK-283757 Fix RbacPolicy to use list of objects instead of\n+  //  multiple RBACChecks for each object.\n+  private case class BulkRegisterHostRbacCheck(",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2315088579"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-02T06:57:51Z",
            "body": "<h2>RSC ANTI PATTERN GITHUB RULE</h2>\n\n**Refactor `bulkRegisterSecondaryHosts` to use `NamedFetcher` for batching, adhering to Confluence Rule on hierarchical data queries.**\n\n```scala\n// Example refactor snippet\nval BulkRegisterSecondaryHostsFetcher: NamedFetcher[UserContext, HostRegister, HostRegister, UUID] =\n  NamedFetcher(\n    \"BulkRegisterSecondaryHostsFetcher\",\n    (ctx: UserContext, hostFids: Seq[String], span: Option[Span]) => {\n      implicit val spanOpt: Option[Span] = span\n      queries.bulkRegisterSecondaryHostsBatched(ctx, hostFids)\n    }\n  )(HasId(_.fid))\n\ndef bulkRegisterSecondaryHosts(\n  argSupplier: Context[UserContext, _] => BulkRegisterSecondaryHostsReq\n): RbacPolicy = {\n  RbacPolicy(\n    DeferredValue(BulkRegisterSecondaryHostsFetcher.defer(argSupplier(ctx).hosts.map(_.hostFid)))\n  )\n}\n\n```\n<details ><summary>More details here</summary><br>The `bulkRegisterSecondaryHosts` method uses `BulkSecondaryRegisterHostRbacCheck`. While this implementation is clear, no batching behavior has been introduced for any downstream calls made by this method. As per the Confluence Rule, batching should be introduced to avoid performance degradation for queries involving hierarchical data. Consider refactoring the implementation with a `NamedFetcher` for batching.  \n\n```scala\n// Example refactor snippet\nval BulkRegisterSecondaryHostsFetcher: NamedFetcher[UserContext, HostRegister, HostRegister, UUID] =\n  NamedFetcher(\n    \"BulkRegisterSecondaryHostsFetcher\",\n    (ctx: UserContext, hostFids: Seq[String], span: Option[Span]) => {\n      implicit val spanOpt: Option[Span] = span\n      queries.bulkRegisterSecondaryHostsBatched(ctx, hostFids)\n    }\n  )(HasId(_.fid))\n\ndef bulkRegisterSecondaryHosts(\n  argSupplier: Context[UserContext, _] => BulkRegisterSecondaryHostsReq\n): RbacPolicy = {\n  RbacPolicy(\n    DeferredValue(BulkRegisterSecondaryHostsFetcher.defer(argSupplier(ctx).hosts.map(_.hostFid)))\n  )\n}\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala</code>\n<ul><li>76 to 87</li></ul></details>\n<h2></h2>\n<!-- rule:rsc_anti_pattern_github_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/SPARK/pag...](https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/3463545100/graphql-batching)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"rsc_anti_pattern_github_rule\", \"processable\": true, \"contextual_eligible\": true, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala\": [[76, 87]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala",
            "line_number": 36,
            "diff_hunk": "@@ -1,17 +1,243 @@\n package services.physicalhost.rbac\n \n+import authzservice.authzservice.InventorySubHierarchyRootEnum.LINUX_HOST_ROOT\n+import authzservice.authzservice.InventorySubHierarchyRootEnum.WINDOWS_HOST_ROOT\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister.HostRegisterOsType\n+import dal.grpc.UnifiedFeatureFlagService\n+import javax.inject.Inject\n+import models.graphql.AttributedFeatureFlagName\n+import models.graphql.FeatureFlagAttribute\n+import models.graphql.FlagAttribute\n import physicalhost.physicalhost.BulkRegisterSecondaryHostsReq\n import sangria.schema.Context\n import security.UserContext\n-import security.rbac.AdminOrOwnerAccessForDev\n+import security.rbac.And\n+import security.rbac.CustomRbacCheck\n+import security.rbac.CustomRbacCheckResult\n+import security.rbac.MoreRbacChecksNeeded\n+import security.rbac.Operation.AddInventory\n+import security.rbac.Operation.Ctx\n+import security.rbac.Operation.ManageDataSource\n+import security.rbac.Or\n+import security.rbac.RbacCheck\n import security.rbac.RbacPolicy\n \n-class PhysicalHostRbacPoliciesImpl extends PhysicalHostRbacPolicies {\n+class PhysicalHostRbacPoliciesImpl @Inject() (\n+  uffs: UnifiedFeatureFlagService\n+) extends PhysicalHostRbacPolicies {\n   // Add your custom RBAC policies here\n   def bulkRegisterSecondaryHosts(\n     argSupplier: Context[UserContext, _] => BulkRegisterSecondaryHostsReq\n   ): RbacPolicy = {\n-    // TODO(SPARK-572184): Add RBAC policy\n-    RbacPolicy(AdminOrOwnerAccessForDev)\n+    RbacPolicy(\n+      BulkSecondaryRegisterHostRbacCheck(argSupplier, uffs)\n+    )\n+  }",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2315105851"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-02T06:57:54Z",
            "body": "<h2>POLARIS BACKWARD COMPATIBILITY RULE</h2>\n\n**Add `_UNSPECIFIED` to `HostRegisterOsType` ENUM and handle it in server code to ensure a default value.**\n\n```diff\n-        cdmrestservice.HostRegister.HostRegisterOsType os_type = 3;\n+        cdmrestservice.HostRegister.HostRegisterOsType os_type = 3 [(api.graphql_field).default_value = \"UNSPECIFIED\"];\n\n```\n<details ><summary>More details here</summary><br>The `os_type` field uses `cdmrestservice.HostRegister.HostRegisterOsType` without specifying a default value for the ENUM. As per guidelines, the ENUM type should include an `_UNSPECIFIED` value for the default case to prevent ambiguity. Update the ENUM definition in `HostRegisterOsType` to include an `_UNSPECIFIED` value and handle it appropriately in the server code.\n\n```diff\n-        cdmrestservice.HostRegister.HostRegisterOsType os_type = 3;\n+        cdmrestservice.HostRegister.HostRegisterOsType os_type = 3 [(api.graphql_field).default_value = \"UNSPECIFIED\"];\n```\n</details><h2></h2>\n<!-- rule:polaris_backward_compatibility_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/SPARK/pag...](https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2296840439/Guidelines)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"polaris_backward_compatibility_rule\", \"processable\": true, \"contextual_eligible\": true, \"distilled_type\": \"not_distilled\", \"other_locations\": {}} -->\n",
            "file_path": "polaris/src/rubrik/physicalhost/proto/physicalhost.proto",
            "line_number": 63,
            "diff_hunk": "@@ -53,11 +50,43 @@ message EchoReply {\n   string reply = 1;\n }\n \n+// Host details for secondary registration.\n+message SecondaryRegisterHostInput {\n+  // The host FID (unique identifier).\n+  string host_fid = 1 [(api.graphql_field).requiredness = REQUIRED];\n+\n+  // UUID of the primary cluster where the host currently resides.\n+  string primary_cluster_uuid = 2 [(api.graphql_field).requiredness = REQUIRED];\n+\n+  // Operating system type of the host.\n+  cdmrestservice.HostRegister.HostRegisterOsType os_type = 3;\n+}",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2315105936"
          },
          {
            "author": "ilya-netchitailo",
            "created_at": "2025-09-02T19:40:44Z",
            "body": "Are these the protos being used in the schema? cause the output looks different in terms of comments at least.\r\n\r\nI was going to say here, use `string_to_uuid` transform, but will it even apply?",
            "file_path": "polaris/src/rubrik/physicalhost/proto/physicalhost.proto",
            "line_number": 54,
            "diff_hunk": "@@ -53,11 +50,43 @@ message EchoReply {\n   string reply = 1;\n }\n \n+// Host details for secondary registration.\n+message SecondaryRegisterHostInput {",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2316996506"
          },
          {
            "author": "moht-agrawal-rubrik",
            "created_at": "2025-09-03T02:43:46Z",
            "body": "> Are these the protos being used in the schema\r\n\r\nYes this message proto is being used in the schema. `BulkRegisterSecondaryHostsReq` takes in array of `SecondaryRegisterHostInput`. The former is being used in the rpc.\r\n\r\n> cause the output looks different in terms of comments at least\r\n\r\nDidn't understood this point, which output are we talking about?\r\n\r\n> I was going to say here, use string_to_uuid transform, but will it even apply?\r\n\r\nSeems like a good idea. Why would it not apply? It is part of schema, BulkRegisterSecondaryHostsReq type uses this type.\r\n",
            "file_path": "polaris/src/rubrik/physicalhost/proto/physicalhost.proto",
            "line_number": 54,
            "diff_hunk": "@@ -53,11 +50,43 @@ message EchoReply {\n   string reply = 1;\n }\n \n+// Host details for secondary registration.\n+message SecondaryRegisterHostInput {",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2317616738"
          },
          {
            "author": "moht-agrawal-rubrik",
            "created_at": "2025-09-03T02:52:15Z",
            "body": "why i need to call fetcher for rbac check?",
            "file_path": "polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala",
            "line_number": 36,
            "diff_hunk": "@@ -1,17 +1,243 @@\n package services.physicalhost.rbac\n \n+import authzservice.authzservice.InventorySubHierarchyRootEnum.LINUX_HOST_ROOT\n+import authzservice.authzservice.InventorySubHierarchyRootEnum.WINDOWS_HOST_ROOT\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister.HostRegisterOsType\n+import dal.grpc.UnifiedFeatureFlagService\n+import javax.inject.Inject\n+import models.graphql.AttributedFeatureFlagName\n+import models.graphql.FeatureFlagAttribute\n+import models.graphql.FlagAttribute\n import physicalhost.physicalhost.BulkRegisterSecondaryHostsReq\n import sangria.schema.Context\n import security.UserContext\n-import security.rbac.AdminOrOwnerAccessForDev\n+import security.rbac.And\n+import security.rbac.CustomRbacCheck\n+import security.rbac.CustomRbacCheckResult\n+import security.rbac.MoreRbacChecksNeeded\n+import security.rbac.Operation.AddInventory\n+import security.rbac.Operation.Ctx\n+import security.rbac.Operation.ManageDataSource\n+import security.rbac.Or\n+import security.rbac.RbacCheck\n import security.rbac.RbacPolicy\n \n-class PhysicalHostRbacPoliciesImpl extends PhysicalHostRbacPolicies {\n+class PhysicalHostRbacPoliciesImpl @Inject() (\n+  uffs: UnifiedFeatureFlagService\n+) extends PhysicalHostRbacPolicies {\n   // Add your custom RBAC policies here\n   def bulkRegisterSecondaryHosts(\n     argSupplier: Context[UserContext, _] => BulkRegisterSecondaryHostsReq\n   ): RbacPolicy = {\n-    // TODO(SPARK-572184): Add RBAC policy\n-    RbacPolicy(AdminOrOwnerAccessForDev)\n+    RbacPolicy(\n+      BulkSecondaryRegisterHostRbacCheck(argSupplier, uffs)\n+    )\n+  }",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2317626786"
          },
          {
            "author": "moht-agrawal-rubrik",
            "created_at": "2025-09-03T02:53:48Z",
            "body": "You can't specify \"UNSPECIFIED\" to HostRegisterOsType. Also by default it is automatically taking the *EMPTY_VALUE, I don't think it is required to pass in explicitly. ",
            "file_path": "polaris/src/rubrik/physicalhost/proto/physicalhost.proto",
            "line_number": 63,
            "diff_hunk": "@@ -53,11 +50,43 @@ message EchoReply {\n   string reply = 1;\n }\n \n+// Host details for secondary registration.\n+message SecondaryRegisterHostInput {\n+  // The host FID (unique identifier).\n+  string host_fid = 1 [(api.graphql_field).requiredness = REQUIRED];\n+\n+  // UUID of the primary cluster where the host currently resides.\n+  string primary_cluster_uuid = 2 [(api.graphql_field).requiredness = REQUIRED];\n+\n+  // Operating system type of the host.\n+  cdmrestservice.HostRegister.HostRegisterOsType os_type = 3;\n+}",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2317628330"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T11:51:46Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Update `input` parameter description in `bulkRegisterSecondaryHosts` to: \"The request contains the secondary cluster UUID and the hosts to register.\"**\n\n```diff\n-\t    # The request containing secondary cluster UUID and hosts to register.\n+\t    # The request contains the secondary cluster UUID and the hosts to register.\n\n```\n<details ><summary>More details here</summary><br>The description for the `input` parameter in `bulkRegisterSecondaryHosts` is provided, but it does not follow the grammar rule. The description should use correct grammar. Suggestion: Update the description to \"The request contains the secondary cluster UUID and the hosts to register.\"\n\n```diff\n-\t    # The request containing secondary cluster UUID and hosts to register.\n+\t    # The request contains the secondary cluster UUID and the hosts to register.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 21 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql</code>\n<ul><li>52212 to 52213</li><li>98350 to 98360</li><li>168252 to 168254</li><li>168259 to 168261</li></ul>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql</code>\n<ul><li>10139 to 10142</li><li>37032 to 37033</li><li>37034 to 37036</li><li>37040 to 37041</li><li>69691 to 69693</li><li>69694 to 69696</li><li>69697 to 69699</li><li>118844</li><li>118851 to 118853</li></ul>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>10139 to 10140</li><li>10141 to 10142</li><li>37031</li><li>37032 to 37033</li><li>37035 to 37036</li><li>37038 to 37039</li><li>37040 to 37041</li><li>69697 to 69699</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql\": [[52212, 52213], [98350, 98360], [168252, 168254], [168259, 168261]], \"polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql\": [[10139, 10142], [37032, 37033], [37034, 37036], [37040, 37041], [69691, 69693], [69694, 69696], [69697, 69699], [118844, 118844], [118851, 118853]], \"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[10139, 10140], [10141, 10142], [37031, 37031], [37032, 37033], [37035, 37036], [37038, 37039], [37040, 37041], [69697, 69699]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql",
            "line_number": 17247,
            "diff_hunk": "@@ -17242,7 +17242,9 @@ type Mutation {\n     input: BulkRegisterHostAsyncInput!): BulkRegisterHostAsyncReply!\n \n   # BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n-  bulkRegisterSecondaryHosts: Void\n+  bulkRegisterSecondaryHosts(\n+    # The request containing secondary cluster UUID and hosts to register.\n+    input: BulkRegisterSecondaryHostsInput!): BulkRegisterSecondaryHostsReply!",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318722788"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T11:51:48Z",
            "body": "<h2>POLARIS BACKWARD COMPATIBILITY RULE</h2>\n\n**Add `HOST_REGISTER_OS_TYPE_UNSPECIFIED` as value `0` in `HostRegisterOsType` to ensure default enum clarity.**\n\n```diff\n-    cdmrestservice.HostRegister.HostRegisterOsType os_type = 3;\n+    cdmrestservice.HostRegister.HostRegisterOsType os_type = 3 [(api.graphql_field).default_value = HOSTREGISTER_UNSPECIFIED];\n\n```\n<details ><summary>More details here</summary><br>The `os_type` field in the `SecondaryRegisterHostInput` message does not include a default value for the enum type `cdmrestservice.HostRegister.HostRegisterOsType`. As per guidelines, all enums should have a value for `0` named `<ENUM_TYPE>_UNSPECIFIED` to avoid ambiguity. This should be added in the `HostRegisterOsType` definition.  \n\n```diff\n-    cdmrestservice.HostRegister.HostRegisterOsType os_type = 3;\n+    cdmrestservice.HostRegister.HostRegisterOsType os_type = 3 [(api.graphql_field).default_value = HOSTREGISTER_UNSPECIFIED];\n```\n</details><h2></h2>\n<!-- rule:polaris_backward_compatibility_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/SPARK/pag...](https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2296840439/Guidelines)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"polaris_backward_compatibility_rule\", \"processable\": true, \"contextual_eligible\": true, \"distilled_type\": \"not_distilled\", \"other_locations\": {}} -->\n",
            "file_path": "polaris/src/rubrik/physicalhost/proto/physicalhost.proto",
            "line_number": 63,
            "diff_hunk": "@@ -53,11 +50,43 @@ message EchoReply {\n   string reply = 1;\n }\n \n+// Host details for secondary registration.\n+message SecondaryRegisterHostInput {\n+  // The host FID (unique identifier).\n+  string host_fid = 1 [(api.graphql_field).requiredness = REQUIRED];\n+\n+  // UUID of the primary cluster where the host currently resides.\n+  string primary_cluster_uuid = 2 [(api.graphql_field).requiredness = REQUIRED];\n+\n+  // Operating system type of the host.\n+  cdmrestservice.HostRegister.HostRegisterOsType os_type = 3;\n+}",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318722841"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T11:51:50Z",
            "body": "<h2>POLARIS BACKWARD COMPATIBILITY RULE</h2>\n\n**Revert `HIDDEN` tag removal or implement deprecation process to maintain GraphQL endpoint visibility and adhere to guidelines.**\n\n```diff\n-\t    tags: [\n-\t      { type: HIDDEN }\n-\t    ]\n\n```\n<details ><summary>More details here</summary><br>The removal of the `HIDDEN` tag in the `option (api.graphql_method)` for the `BulkRegisterSecondaryHosts` endpoint changes its visibility in the GraphQL schema. According to the guidelines, modifications to GraphQL endpoints that affect their visibility should follow a deprecation process to ensure backward compatibility and proper client adaptation. The removal of the `HIDDEN` tag should be done cautiously, and documentation should include a note regarding this change for developers relying on the endpoint.  \n\nConsider reverting this change or implementing a deprecation process for the `HIDDEN` tag to ensure alignment with guidelines.  \n```diff\n-\t    tags: [\n-\t      { type: HIDDEN }\n-\t    ]\n```\n</details><h2></h2>\n<!-- rule:polaris_backward_compatibility_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/SPARK/pag...](https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2296840439/Guidelines)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"polaris_backward_compatibility_rule\", \"processable\": true, \"contextual_eligible\": true, \"distilled_type\": \"not_distilled\", \"other_locations\": {}} -->\n",
            "file_path": "polaris/src/rubrik/physicalhost/proto/physicalhost.proto",
            "line_number": 34,
            "diff_hunk": "@@ -23,16 +24,12 @@ service PhysicalHost {\n     }\n   };\n \n-  // TODO(SPARK-572184): Implement BulkRegisterSecondaryHosts\n-\n   // BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n+  // @param input The request containing secondary cluster UUID and hosts to register.\n   rpc BulkRegisterSecondaryHosts (BulkRegisterSecondaryHostsReq) returns (BulkRegisterSecondaryHostsReply) {\n     option (api.graphql_method) = {\n       type: MUTATION\n       name: \"bulkRegisterSecondaryHosts\"\n-      tags: [\n-        { type: HIDDEN }\n-      ]\n     };\n   }",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318722924"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T11:51:52Z",
            "body": "<h2>RSC ANTI PATTERN GITHUB RULE</h2>\n\n**Construct `BulkSecondaryRegisterHostRbacCheck` checks concurrently instead of using sequence comprehensions to avoid sequential RBAC execution.**\n\n```diff\n-\t        val primaryClusterChecks =\n-\t          primaryClusterUuids.map {\n-\t            primaryClusterUuid =>\n-\t              val hostsForCluster =\n-\t                req.hosts.filter(_.primaryClusterUuid == primaryClusterUuid)\n-\t              RbacCheck(\n-\t                ManageDataSource,\n-\t                _ => hostsForCluster.map(_.hostFid),\n-\t                clusterIdsOpt = _ => Some(Seq(primaryClusterUuid))\n-\t              )\n-\t          }\n-\t        val allChecks = secondaryClusterCheck +: primaryClusterChecks\n+\t        val primaryClusterChecksFutures = primaryClusterUuids.map {\n+\t          primaryClusterUuid =>\n+\t            Future {\n+\t              val hostsForCluster =\n+\t                req.hosts.filter(_.primaryClusterUuid == primaryClusterUuid)\n+\t              RbacCheck(\n+\t                ManageDataSource,\n+\t                _ => hostsForCluster.map(_.hostFid),\n+\t                clusterIdsOpt = _ => Some(Seq(primaryClusterUuid))\n+\t              )\n+\t            }\n+\t        }\n+\t\n+\t        val combinedCheckFuture = for {\n+\t          secondaryCheck <- Future.successful(secondaryClusterCheck)\n+\t          primaryClusterChecks <- Future.sequence(primaryClusterChecksFutures)\n+\t        } yield {\n+\t          secondaryCheck +: primaryClusterChecks.reduce(And(_, _))\n+\t        }\n+\t\n+\t        combinedCheckFuture.map(MoreRbacChecksNeeded)\n\n```\n<details ><summary>More details here</summary><br>The `BulkSecondaryRegisterHostRbacCheck` implementation uses sequence comprehensions for `primaryClusterChecks`, which might introduce sequential execution for RBAC checks. Consider constructing individual checks concurrently and combining them afterward.\n```diff\n-\t        val primaryClusterChecks =\n-\t          primaryClusterUuids.map {\n-\t            primaryClusterUuid =>\n-\t              val hostsForCluster =\n-\t                req.hosts.filter(_.primaryClusterUuid == primaryClusterUuid)\n-\t              RbacCheck(\n-\t                ManageDataSource,\n-\t                _ => hostsForCluster.map(_.hostFid),\n-\t                clusterIdsOpt = _ => Some(Seq(primaryClusterUuid))\n-\t              )\n-\t          }\n-\t        val allChecks = secondaryClusterCheck +: primaryClusterChecks\n+\t        val primaryClusterChecksFutures = primaryClusterUuids.map {\n+\t          primaryClusterUuid =>\n+\t            Future {\n+\t              val hostsForCluster =\n+\t                req.hosts.filter(_.primaryClusterUuid == primaryClusterUuid)\n+\t              RbacCheck(\n+\t                ManageDataSource,\n+\t                _ => hostsForCluster.map(_.hostFid),\n+\t                clusterIdsOpt = _ => Some(Seq(primaryClusterUuid))\n+\t              )\n+\t            }\n+\t        }\n+\t\n+\t        val combinedCheckFuture = for {\n+\t          secondaryCheck <- Future.successful(secondaryClusterCheck)\n+\t          primaryClusterChecks <- Future.sequence(primaryClusterChecksFutures)\n+\t        } yield {\n+\t          secondaryCheck +: primaryClusterChecks.reduce(And(_, _))\n+\t        }\n+\t\n+\t        combinedCheckFuture.map(MoreRbacChecksNeeded)\n```\n</details><h2></h2>\n<!-- rule:rsc_anti_pattern_github_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/SPARK/pag...](https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/3606118517/Sequential+chaining+of+Futures+in+API+Server)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"rsc_anti_pattern_github_rule\", \"processable\": true, \"contextual_eligible\": true, \"distilled_type\": \"not_distilled\", \"other_locations\": {}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala",
            "line_number": 239,
            "diff_hunk": "@@ -1,17 +1,243 @@\n package services.physicalhost.rbac\n \n+import authzservice.authzservice.InventorySubHierarchyRootEnum.LINUX_HOST_ROOT\n+import authzservice.authzservice.InventorySubHierarchyRootEnum.WINDOWS_HOST_ROOT\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister.HostRegisterOsType\n+import dal.grpc.UnifiedFeatureFlagService\n+import javax.inject.Inject\n+import models.graphql.AttributedFeatureFlagName\n+import models.graphql.FeatureFlagAttribute\n+import models.graphql.FlagAttribute\n import physicalhost.physicalhost.BulkRegisterSecondaryHostsReq\n import sangria.schema.Context\n import security.UserContext\n-import security.rbac.AdminOrOwnerAccessForDev\n+import security.rbac.And\n+import security.rbac.CustomRbacCheck\n+import security.rbac.CustomRbacCheckResult\n+import security.rbac.MoreRbacChecksNeeded\n+import security.rbac.Operation.AddInventory\n+import security.rbac.Operation.Ctx\n+import security.rbac.Operation.ManageDataSource\n+import security.rbac.Or\n+import security.rbac.RbacCheck\n import security.rbac.RbacPolicy\n \n-class PhysicalHostRbacPoliciesImpl extends PhysicalHostRbacPolicies {\n+class PhysicalHostRbacPoliciesImpl @Inject() (\n+  uffs: UnifiedFeatureFlagService\n+) extends PhysicalHostRbacPolicies {\n   // Add your custom RBAC policies here\n   def bulkRegisterSecondaryHosts(\n     argSupplier: Context[UserContext, _] => BulkRegisterSecondaryHostsReq\n   ): RbacPolicy = {\n-    // TODO(SPARK-572184): Add RBAC policy\n-    RbacPolicy(AdminOrOwnerAccessForDev)\n+    RbacPolicy(\n+      BulkSecondaryRegisterHostRbacCheck(argSupplier, uffs)\n+    )\n+  }\n+\n+  // TODO SPARK-283757 Fix RbacPolicy to use list of objects instead of\n+  //  multiple RBACChecks for each object.\n+  private case class BulkRegisterHostRbacCheck(\n+    clusterUuid: Ctx => String,\n+    hosts: Ctx => Seq[HostRegister]\n+  ) extends CustomRbacCheck {\n+    override def doRbacCheck(ctx: Ctx): CustomRbacCheckResult = {\n+      val hostRoots: Seq[String] =\n+        mapHostsToOsType(hosts, clusterUuid(ctx), ctx)\n+      // iterate over all hosts and check if they are linux or windows\n+      // if they are linux or windows, check if the user has the right to\n+      // manage the datasource\n+      val linuxHostRoots: Seq[String] =\n+        hostRoots.filter(\n+          _ == LINUX_HOST_ROOT.name\n+        )\n+      val windowsHostRoots: Seq[String] =\n+        hostRoots.filter(\n+          _ == WINDOWS_HOST_ROOT.name\n+        )\n+\n+      // If linuxHostRoots and windowsHostRoots both are empty,\n+      // then check access on\n+      // OR of Manage Data Source on linux and windows host roots\n+      (linuxHostRoots.nonEmpty, windowsHostRoots.nonEmpty) match {\n+        case (false, false) => {\n+          MoreRbacChecksNeeded(\n+            Or(\n+              RbacCheck(\n+                ManageDataSource,\n+                _ => Seq(LINUX_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+              RbacCheck(\n+                ManageDataSource,\n+                _ => Seq(WINDOWS_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+              And(\n+                RbacCheck(\n+                  AddInventory,\n+                  _ => Seq(LINUX_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+                RbacCheck(\n+                  AddInventory,\n+                  _ => Seq(WINDOWS_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+              )\n+            )\n+          )\n+        }\n+        // If linuxHostRoots and windowsHostRoots both are non-empty, then check\n+        // access on AND of Manage Data Source on linux and windows host roots\n+        case (true, true) => {\n+          MoreRbacChecksNeeded(\n+            Or(\n+              And(\n+                RbacCheck(\n+                  ManageDataSource,\n+                  _ => Seq(LINUX_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+                RbacCheck(\n+                  ManageDataSource,\n+                  _ => Seq(WINDOWS_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+              ),\n+              And(\n+                RbacCheck(\n+                  AddInventory,\n+                  _ => Seq(LINUX_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+                RbacCheck(\n+                  AddInventory,\n+                  _ => Seq(WINDOWS_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+              )\n+            )\n+          )\n+        }\n+        case (true, false) => {\n+          MoreRbacChecksNeeded(\n+            Or(\n+              RbacCheck(\n+                ManageDataSource,\n+                _ => Seq(LINUX_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+              RbacCheck(\n+                AddInventory,\n+                _ => Seq(LINUX_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+            )\n+          )\n+        }\n+        case (false, true) => {\n+          MoreRbacChecksNeeded(\n+            Or(\n+              RbacCheck(\n+                ManageDataSource,\n+                _ => Seq(WINDOWS_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+              RbacCheck(\n+                AddInventory,\n+                _ => Seq(WINDOWS_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+            )\n+          )\n+        }\n+      }\n+    }\n+  }\n+\n+  // A function that takes a Seq of HostRegister and filters it based on\n+  // osType of hosts\n+  private def mapHostsToOsType(\n+    hosts: Ctx => Seq[HostRegister],\n+    clusterUuid: String,\n+    ctx: Ctx\n+  ): Seq[String] = {\n+    val isRegisterHostOsTypeEnabled =\n+      uffs.isFeatureFlagTrue(\n+        ctx.ctx,\n+        AttributedFeatureFlagName.REGISTER_HOST_OS_TYPE_ENABLED.toString,\n+        Seq(\n+          FeatureFlagAttribute(\n+            FlagAttribute.CLUSTER_UUID,\n+            clusterUuid\n+          )\n+        )\n+      )\n+\n+    if (isRegisterHostOsTypeEnabled) {\n+      val hostRootsSeq: Seq[String] =\n+        hosts(ctx).map {\n+          host =>\n+            val osType = host.osType\n+            val hostRoot =\n+              Some(osType) match {\n+                case Some(HostRegisterOsType.HOST_REGISTER_OS_TYPE_LINUX) =>\n+                  LINUX_HOST_ROOT.name\n+                case Some(HostRegisterOsType.HOST_REGISTER_OS_TYPE_WINDOWS) =>\n+                  WINDOWS_HOST_ROOT.name\n+                case _ => \"\"\n+              }\n+            hostRoot\n+        }\n+      hostRootsSeq\n+    } else {\n+      Seq.empty\n+    }\n+  }\n+\n+  private case class BulkSecondaryRegisterHostRbacCheck(\n+    argSupplier: Context[UserContext, _] => BulkRegisterSecondaryHostsReq,\n+    uffs: UnifiedFeatureFlagService\n+  ) extends CustomRbacCheck {\n+    override def doRbacCheck(\n+      ctx: Context[UserContext, _]\n+    ): CustomRbacCheckResult = {\n+      val req = argSupplier(ctx)\n+      val primaryClusterUuids = req.hosts.map(_.primaryClusterUuid).distinct\n+\n+      // Secondary cluster check: Use the reusable BulkRegisterHostRbacCheck\n+      // class\n+      val secondaryClusterCheck =\n+        BulkRegisterHostRbacCheck(\n+          clusterUuid = _ => req.secondaryClusterUuid,\n+          hosts =\n+            ctx =>\n+              argSupplier(ctx).hosts.map(\n+                host =>\n+                  HostRegister()\n+                    .withOsType(host.osType)\n+              )\n+        )\n+\n+      // Primary cluster checks: requires ManageDataSource on individual host FIDs\n+      val primaryClusterChecks =\n+        primaryClusterUuids.map {\n+          primaryClusterUuid =>\n+            val hostsForCluster =\n+              req.hosts.filter(_.primaryClusterUuid == primaryClusterUuid)\n+            RbacCheck(\n+              ManageDataSource,\n+              _ => hostsForCluster.map(_.hostFid),\n+              clusterIdsOpt = _ => Some(Seq(primaryClusterUuid))\n+            )\n+        }\n+\n+      // Combine all checks with AND logic\n+      val allChecks = secondaryClusterCheck +: primaryClusterChecks\n+      val combinedCheck = allChecks.reduce(And(_, _))\n+",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318723054"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T12:37:11Z",
            "body": "<h2>POLARIS BACKWARD COMPATIBILITY RULE</h2>\n\n**Retain `tags: [{ type: HIDDEN }]` in `api.graphql_method` to prevent unintentional exposure of the GraphQL endpoint.**\n\n```diff\n+\t    option (api.graphql_method) = {\n+\t      type: MUTATION\n+\t      name: \"bulkRegisterSecondaryHosts\"\n+\t      tags: [\n+\t        { type: HIDDEN }\n+\t      ]\n+\t    };\n\n```\n<details ><summary>More details here</summary><br>The `BulkRegisterSecondaryHosts` method has been updated, but the removal of the `tags: [{ type: HIDDEN }]` option from the `api.graphql_method` is not addressed. As per the guidelines, changes to the visibility of GraphQL methods must be carefully considered to avoid exposing endpoints prematurely or unintentionally. If the endpoint is meant to remain hidden, the `tags: [{ type: HIDDEN }]` option should be retained.  \n\n```diff\n+\t    option (api.graphql_method) = {\n+\t      type: MUTATION\n+\t      name: \"bulkRegisterSecondaryHosts\"\n+\t      tags: [\n+\t        { type: HIDDEN }\n+\t      ]\n+\t    };\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/physicalhost/proto/physicalhost.proto</code>\n<ul><li>53 to 63</li></ul></details>\n<h2></h2>\n<!-- rule:polaris_backward_compatibility_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/SPARK/pag...](https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2296840439/Guidelines)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"polaris_backward_compatibility_rule\", \"processable\": true, \"contextual_eligible\": true, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/physicalhost/proto/physicalhost.proto\": [[53, 63]]}} -->\n",
            "file_path": "polaris/src/rubrik/physicalhost/proto/physicalhost.proto",
            "line_number": 35,
            "diff_hunk": "@@ -23,16 +24,12 @@ service PhysicalHost {\n     }\n   };\n \n-  // TODO(SPARK-572184): Implement BulkRegisterSecondaryHosts\n-\n   // BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n+  // @param input The request containing secondary cluster UUID and hosts to register.\n   rpc BulkRegisterSecondaryHosts (BulkRegisterSecondaryHostsReq) returns (BulkRegisterSecondaryHostsReply) {\n     option (api.graphql_method) = {\n       type: MUTATION\n       name: \"bulkRegisterSecondaryHosts\"\n-      tags: [\n-        { type: HIDDEN }\n-      ]\n     };\n   }\n ",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318838482"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T12:37:13Z",
            "body": "<h2>RSC ANTI PATTERN GITHUB RULE</h2>\n\n**Avoid `Await.result` and `Await.ready`; use Future combinators (`map`, `flatMap`, `for-yield`) for non-blocking asynchronous execution.**\n\n```diff\n-      override def doRbacCheck(ctx: Ctx): CustomRbacCheckResult = {\n-        val hostRoots: Seq[String] =\n-          mapHostsToOsType(hosts, clusterUuid(ctx), ctx)\n+      override def doRbacCheck(ctx: Ctx): CustomRbacCheckResult = {\n+        mapHostsToOsType(hosts, clusterUuid(ctx), ctx).map { hostRoots =>\n\n```\n<details ><summary>More details here</summary><br>Using `Await.result` or `Await.ready` is discouraged as per the Confluence Rule. Prefer using Future combinators like `map`, `flatMap`, or `for-yield`. This ensures non-blocking and asynchronous execution.  \n```diff\n-      override def doRbacCheck(ctx: Ctx): CustomRbacCheckResult = {\n-        val hostRoots: Seq[String] =\n-          mapHostsToOsType(hosts, clusterUuid(ctx), ctx)\n+      override def doRbacCheck(ctx: Ctx): CustomRbacCheckResult = {\n+        mapHostsToOsType(hosts, clusterUuid(ctx), ctx).map { hostRoots =>\n```\n</details><h2></h2>\n<!-- rule:rsc_anti_pattern_github_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/SPARK/pag...](https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/3605495935/Await+in+API+Server)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"rsc_anti_pattern_github_rule\", \"processable\": true, \"contextual_eligible\": true, \"distilled_type\": \"not_distilled\", \"other_locations\": {}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala",
            "line_number": 45,
            "diff_hunk": "@@ -1,17 +1,243 @@\n package services.physicalhost.rbac\n \n+import authzservice.authzservice.InventorySubHierarchyRootEnum.LINUX_HOST_ROOT\n+import authzservice.authzservice.InventorySubHierarchyRootEnum.WINDOWS_HOST_ROOT\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister.HostRegisterOsType\n+import dal.grpc.UnifiedFeatureFlagService\n+import javax.inject.Inject\n+import models.graphql.AttributedFeatureFlagName\n+import models.graphql.FeatureFlagAttribute\n+import models.graphql.FlagAttribute\n import physicalhost.physicalhost.BulkRegisterSecondaryHostsReq\n import sangria.schema.Context\n import security.UserContext\n-import security.rbac.AdminOrOwnerAccessForDev\n+import security.rbac.And\n+import security.rbac.CustomRbacCheck\n+import security.rbac.CustomRbacCheckResult\n+import security.rbac.MoreRbacChecksNeeded\n+import security.rbac.Operation.AddInventory\n+import security.rbac.Operation.Ctx\n+import security.rbac.Operation.ManageDataSource\n+import security.rbac.Or\n+import security.rbac.RbacCheck\n import security.rbac.RbacPolicy\n \n-class PhysicalHostRbacPoliciesImpl extends PhysicalHostRbacPolicies {\n+class PhysicalHostRbacPoliciesImpl @Inject() (\n+  uffs: UnifiedFeatureFlagService\n+) extends PhysicalHostRbacPolicies {\n   // Add your custom RBAC policies here\n   def bulkRegisterSecondaryHosts(\n     argSupplier: Context[UserContext, _] => BulkRegisterSecondaryHostsReq\n   ): RbacPolicy = {\n-    // TODO(SPARK-572184): Add RBAC policy\n-    RbacPolicy(AdminOrOwnerAccessForDev)\n+    RbacPolicy(\n+      BulkSecondaryRegisterHostRbacCheck(argSupplier, uffs)\n+    )\n+  }\n+\n+  // TODO SPARK-283757 Fix RbacPolicy to use list of objects instead of\n+  //  multiple RBACChecks for each object.\n+  private case class BulkRegisterHostRbacCheck(\n+    clusterUuid: Ctx => String,\n+    hosts: Ctx => Seq[HostRegister]\n+  ) extends CustomRbacCheck {\n+    override def doRbacCheck(ctx: Ctx): CustomRbacCheckResult = {\n+      val hostRoots: Seq[String] =",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318838578"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:21:54Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure `input` field description in `bulkRegisterSecondaryHosts` uses sentence case and proper grammar for clarity.**\n\n```diff\n-\t    # The request containing secondary cluster UUID and hosts to register.\n+\t    # The request contains the secondary cluster UUID and hosts to register.\n\n```\n<details ><summary>More details here</summary><br>The description for the `input` field in `bulkRegisterSecondaryHosts` is missing sentence case adherence and proper grammar. The description should begin with a capitalized word and use correct grammar to ensure clarity.  \n\n```diff\n-\t    # The request containing secondary cluster UUID and hosts to register.\n+\t    # The request contains the secondary cluster UUID and hosts to register.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 18 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql</code>\n<ul><li>52208 to 52213</li><li>52215 to 52218</li><li>98350 to 98360</li><li>98857 to 98859</li><li>168252 to 168262</li></ul>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql</code>\n<ul><li>10140 to 10142</li><li>37032 to 37033</li><li>37035 to 37036</li><li>37040 to 37041</li><li>69691 to 69700</li><li>70195 to 70199</li><li>118852 to 118853</li></ul>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>10139 to 10142</li><li>69691 to 69693</li><li>69694 to 69696</li><li>69697 to 69699</li><li>118845 to 118846</li><li>118851 to 118853</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql\": [[52208, 52213], [52215, 52218], [98350, 98360], [98857, 98859], [168252, 168262]], \"polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql\": [[10140, 10142], [37032, 37033], [37035, 37036], [37040, 37041], [69691, 69700], [70195, 70199], [118852, 118853]], \"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[10139, 10142], [69691, 69693], [69694, 69696], [69697, 69699], [118845, 118846], [118851, 118853]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql",
            "line_number": 17250,
            "diff_hunk": "@@ -17242,7 +17242,9 @@ type Mutation {\n     input: BulkRegisterHostAsyncInput!): BulkRegisterHostAsyncReply!\n \n   # BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n-  bulkRegisterSecondaryHosts: Void\n+  bulkRegisterSecondaryHosts(\n+    # The request containing secondary cluster UUID and hosts to register.\n+    input: BulkRegisterSecondaryHostsInput!): BulkRegisterSecondaryHostsReply!\n \n   # BulkRestoreM365BackupStorageObjects triggers the restore for the M365 Backup\n   # Storage Group workloads.",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318966891"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:21:57Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure `activeDirectoryAdditionalInfo` descriptions are in sentence case with proper grammar.**\n\n```diff\n-\t  # v9.3+: Additional Active Directory info for the host if applicable.\n+\t  # v9.3+: Additional Active Directory information for the host, if applicable.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `activeDirectoryAdditionalInfo` must be in sentence case and use correct grammar. Suggested fix:  \n```diff\n-\t  # v9.3+: Additional Active Directory info for the host if applicable.\n+\t  # v9.3+: Additional Active Directory information for the host, if applicable.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68937,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318966986"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:21:59Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Use sentence case for `compressionEnabled` descriptions.**\n\n```diff\n-\t  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+\t  # v5.3+: Indicates whether compression is enabled while transferring data between the host and the Rubrik cluster.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `compressionEnabled` must be in sentence case. Suggested fix:  \n```diff\n-\t  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+\t  # v5.3+: Indicates whether compression is enabled while transferring data between the host and the Rubrik cluster.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68947,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318967090"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:02Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Fix grammar in `hostDomainId` and `hostDomainName` descriptions.**\n\n```diff\n-\t  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+\t  # v9.2+: (DEPRECATED) This field is deprecated in favor of activeDirectoryAdditionalInfo. ID of the Active Directory domain if the Windows host has a domain controller hosted.\n\n-\t  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+\t  # v9.2+: (DEPRECATED) This field is deprecated in favor of activeDirectoryAdditionalInfo. Specifies the name of the Active Directory domain.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `hostDomainId` and `hostDomainName` must use correct grammar. Suggested fix:  \n```diff\n-\t  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+\t  # v9.2+: (DEPRECATED) This field is deprecated in favor of activeDirectoryAdditionalInfo. ID of the Active Directory domain if the Windows host has a domain controller hosted.\n\n-\t  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+\t  # v9.2+: (DEPRECATED) This field is deprecated in favor of activeDirectoryAdditionalInfo. Specifies the name of the Active Directory domain.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68957,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318967225"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:05Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Fix grammar in `hostVfdDriverState` descriptions.**\n\n```diff\n-\t  # Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+\t  # Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequired' when the driver is present but requires a restart of the Windows host to function.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `hostVfdDriverState` must use correct grammar. Suggested fix:  \n```diff\n-\t  # Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+\t  # Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequired' when the driver is present but requires a restart of the Windows host to function.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68963,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318967340"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:07Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure descriptions for `hostVfdEnabled` use correct grammar.**\n\n```diff\n-\t  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+\t  # Specifies whether VFD-based volume backups are enabled on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `hostVfdEnabled` must use correct grammar. Suggested fix:  \n```diff\n-\t  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+\t  # Specifies whether VFD-based volume backups are enabled on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68967,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318967432"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:09Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure `isOracleHost` descriptions use correct grammar. Suggested fix:**\n\n```diff\n-\t  # Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+\t  # Specifies whether the host is an Oracle host. This indicates whether Oracle discovery fields should be displayed in the UI.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `isOracleHost` must use correct grammar. Suggested fix:  \n```diff\n-\t  # Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+\t  # Specifies whether the host is an Oracle host. This indicates whether Oracle discovery fields should be displayed in the UI.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68973,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318967557"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:12Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Use sentence case for `isRefreshPaused` descriptions.**\n\n```diff\n-\t  # Specifies whether the refresh of host metadata for this host is paused.\n+\t  # Specifies whether the refresh of host metadata is paused for this host.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `isRefreshPaused` must be in sentence case. Suggested fix:  \n```diff\n-\t  # Specifies whether the refresh of host metadata for this host is paused.\n+\t  # Specifies whether the refresh of host metadata is paused for this host.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68977,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean\n+\n+  # Supported in v9.0+\n+  # Specifies whether the refresh of host metadata for this host is paused.\n+  isRefreshPaused: Boolean",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318967703"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:14Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure `mssqlCbtDriverInstalled` descriptions use correct grammar. Apply suggested fixes.**\n\n```diff\n-\t  # Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+\t  # Indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `mssqlCbtDriverInstalled` must use correct grammar. Suggested fix:  \n```diff\n-\t  # Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+\t  # Indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68987,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean\n+\n+  # Supported in v9.0+\n+  # Specifies whether the refresh of host metadata for this host is paused.\n+  isRefreshPaused: Boolean\n+\n+  # Required. Supported in v5.0+\n+  # A relic host is deleted, but still may have snapshots associated with its children (e.g. Fileset).\n+  isRelic: Boolean!\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v5.2: Boolean value that indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v5.3: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v6.0+: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+  mssqlCbtDriverInstalled: Boolean!",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318967784"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:16Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure `mssqlSddCertificateId` descriptions use correct grammar. Apply suggested fixes.**\n\n```diff\n-\t  # Specifies the certificate ID corresponding to the public key certificate of the CA that signed the SQL server certificate for Sensitive Data Discovery.\n+\t  # Specifies the certificate ID for the public key certificate of the CA that signed the SQL Server certificate for sensitive data discovery.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `mssqlSddCertificateId` must use correct grammar. Suggested fix:  \n```diff\n-\t  # Specifies the certificate ID corresponding to the public key certificate of the CA that signed the SQL server certificate for Sensitive Data Discovery.\n+\t  # Specifies the certificate ID for the public key certificate of the CA that signed the SQL Server certificate for sensitive data discovery.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68991,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean\n+\n+  # Supported in v9.0+\n+  # Specifies whether the refresh of host metadata for this host is paused.\n+  isRefreshPaused: Boolean\n+\n+  # Required. Supported in v5.0+\n+  # A relic host is deleted, but still may have snapshots associated with its children (e.g. Fileset).\n+  isRelic: Boolean!\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v5.2: Boolean value that indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v5.3: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v6.0+: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+  mssqlCbtDriverInstalled: Boolean!\n+\n+  # Supported in v9.2+\n+  # Specifies the certificate ID corresponding to the public key certificate of the CA that signed the SQL server certificate for Sensitive Data Discovery.\n+  mssqlSddCertificateId: String",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318967880"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:18Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Use sentence case for `mssqlSddUsername` descriptions.**\n\n```diff\n-\t  # Specifies the username configured for the SQL server instance for sensitive data discovery.\n+\t  # Specifies the username configured for the SQL Server instance for sensitive data discovery.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `mssqlSddUsername` must be in sentence case. Suggested fix:  \n```diff\n-\t  # Specifies the username configured for the SQL server instance for sensitive data discovery.\n+\t  # Specifies the username configured for the SQL Server instance for sensitive data discovery.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68995,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean\n+\n+  # Supported in v9.0+\n+  # Specifies whether the refresh of host metadata for this host is paused.\n+  isRefreshPaused: Boolean\n+\n+  # Required. Supported in v5.0+\n+  # A relic host is deleted, but still may have snapshots associated with its children (e.g. Fileset).\n+  isRelic: Boolean!\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v5.2: Boolean value that indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v5.3: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v6.0+: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+  mssqlCbtDriverInstalled: Boolean!\n+\n+  # Supported in v9.2+\n+  # Specifies the certificate ID corresponding to the public key certificate of the CA that signed the SQL server certificate for Sensitive Data Discovery.\n+  mssqlSddCertificateId: String\n+\n+  # Supported in v9.2+\n+  # Specifies the username configured for the SQL server instance for sensitive data discovery.\n+  mssqlSddUsername: String",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318967964"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:20Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure `oracleQueryUser` descriptions use correct grammar. Apply suggested fix.**\n\n```diff\n-\t  # Specifies the Oracle username for an account with query privileges.\n+\t  # Specifies the Oracle username for an account that has query privileges.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `oracleQueryUser` must use correct grammar. Suggested fix:  \n```diff\n-\t  # Specifies the Oracle username for an account with query privileges.\n+\t  # Specifies the Oracle username for an account that has query privileges.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68999,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean\n+\n+  # Supported in v9.0+\n+  # Specifies whether the refresh of host metadata for this host is paused.\n+  isRefreshPaused: Boolean\n+\n+  # Required. Supported in v5.0+\n+  # A relic host is deleted, but still may have snapshots associated with its children (e.g. Fileset).\n+  isRelic: Boolean!\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v5.2: Boolean value that indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v5.3: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v6.0+: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+  mssqlCbtDriverInstalled: Boolean!\n+\n+  # Supported in v9.2+\n+  # Specifies the certificate ID corresponding to the public key certificate of the CA that signed the SQL server certificate for Sensitive Data Discovery.\n+  mssqlSddCertificateId: String\n+\n+  # Supported in v9.2+\n+  # Specifies the username configured for the SQL server instance for sensitive data discovery.\n+  mssqlSddUsername: String\n+\n+  # Supported in v5.0+\n+  # Specifies the Oracle username for an account with query privileges.\n+  oracleQueryUser: String",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318968058"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:22Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure descriptions for `oracleSddUsername` use correct grammar.**\n\n```diff\n-\t  # Specifies the username configured for the Oracle host for sensitive data discovery.\n+\t  # Specifies the username that is configured for the Oracle host for sensitive data discovery.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `oracleSddUsername` must use correct grammar. Suggested fix:  \n```diff\n-\t  # Specifies the username configured for the Oracle host for sensitive data discovery.\n+\t  # Specifies the username that is configured for the Oracle host for sensitive data discovery.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 69003,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean\n+\n+  # Supported in v9.0+\n+  # Specifies whether the refresh of host metadata for this host is paused.\n+  isRefreshPaused: Boolean\n+\n+  # Required. Supported in v5.0+\n+  # A relic host is deleted, but still may have snapshots associated with its children (e.g. Fileset).\n+  isRelic: Boolean!\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v5.2: Boolean value that indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v5.3: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v6.0+: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+  mssqlCbtDriverInstalled: Boolean!\n+\n+  # Supported in v9.2+\n+  # Specifies the certificate ID corresponding to the public key certificate of the CA that signed the SQL server certificate for Sensitive Data Discovery.\n+  mssqlSddCertificateId: String\n+\n+  # Supported in v9.2+\n+  # Specifies the username configured for the SQL server instance for sensitive data discovery.\n+  mssqlSddUsername: String\n+\n+  # Supported in v5.0+\n+  # Specifies the Oracle username for an account with query privileges.\n+  oracleQueryUser: String\n+\n+  # Supported in v9.3+\n+  # Specifies the username configured for the Oracle host for sensitive data discovery.\n+  oracleSddUsername: String",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318968152"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:24Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure `oracleSddWalletPath` descriptions use correct grammar. Suggested fix: [insert specific grammar correction].**\n\n```diff\n-\t  # Specifies the wallet path on the Oracle host which is used to authenticate remote connections to oracle databases during Sensitive Data Discovery.\n+\t  # Specifies the wallet path on the Oracle host used to authenticate remote connections to Oracle databases during sensitive data discovery.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `oracleSddWalletPath` must use correct grammar. Suggested fix:  \n```diff\n-\t  # Specifies the wallet path on the Oracle host which is used to authenticate remote connections to oracle databases during Sensitive Data Discovery.\n+\t  # Specifies the wallet path on the Oracle host used to authenticate remote connections to Oracle databases during sensitive data discovery.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 69007,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean\n+\n+  # Supported in v9.0+\n+  # Specifies whether the refresh of host metadata for this host is paused.\n+  isRefreshPaused: Boolean\n+\n+  # Required. Supported in v5.0+\n+  # A relic host is deleted, but still may have snapshots associated with its children (e.g. Fileset).\n+  isRelic: Boolean!\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v5.2: Boolean value that indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v5.3: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v6.0+: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+  mssqlCbtDriverInstalled: Boolean!\n+\n+  # Supported in v9.2+\n+  # Specifies the certificate ID corresponding to the public key certificate of the CA that signed the SQL server certificate for Sensitive Data Discovery.\n+  mssqlSddCertificateId: String\n+\n+  # Supported in v9.2+\n+  # Specifies the username configured for the SQL server instance for sensitive data discovery.\n+  mssqlSddUsername: String\n+\n+  # Supported in v5.0+\n+  # Specifies the Oracle username for an account with query privileges.\n+  oracleQueryUser: String\n+\n+  # Supported in v9.3+\n+  # Specifies the username configured for the Oracle host for sensitive data discovery.\n+  oracleSddUsername: String\n+\n+  # Supported in v9.3+\n+  # Specifies the wallet path on the Oracle host which is used to authenticate remote connections to oracle databases during Sensitive Data Discovery.\n+  oracleSddWalletPath: String",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318968248"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:26Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure descriptions for `oracleSepsSettings` use correct grammar; apply suggested fixes.**\n\n```diff\n-\t  # Oracle SEPS settings for the host.\n+\t  # Specifies Oracle SEPS settings for the host.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `oracleSepsSettings` must use correct grammar. Suggested fix:  \n```diff\n-\t  # Oracle SEPS settings for the host.\n+\t  # Specifies Oracle SEPS settings for the host.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 69011,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean\n+\n+  # Supported in v9.0+\n+  # Specifies whether the refresh of host metadata for this host is paused.\n+  isRefreshPaused: Boolean\n+\n+  # Required. Supported in v5.0+\n+  # A relic host is deleted, but still may have snapshots associated with its children (e.g. Fileset).\n+  isRelic: Boolean!\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v5.2: Boolean value that indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v5.3: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v6.0+: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+  mssqlCbtDriverInstalled: Boolean!\n+\n+  # Supported in v9.2+\n+  # Specifies the certificate ID corresponding to the public key certificate of the CA that signed the SQL server certificate for Sensitive Data Discovery.\n+  mssqlSddCertificateId: String\n+\n+  # Supported in v9.2+\n+  # Specifies the username configured for the SQL server instance for sensitive data discovery.\n+  mssqlSddUsername: String\n+\n+  # Supported in v5.0+\n+  # Specifies the Oracle username for an account with query privileges.\n+  oracleQueryUser: String\n+\n+  # Supported in v9.3+\n+  # Specifies the username configured for the Oracle host for sensitive data discovery.\n+  oracleSddUsername: String\n+\n+  # Supported in v9.3+\n+  # Specifies the wallet path on the Oracle host which is used to authenticate remote connections to oracle databases during Sensitive Data Discovery.\n+  oracleSddWalletPath: String\n+\n+  # Supported in v9.4+\n+  # Oracle SEPS settings for the host.\n+  oracleSepsSettings: OracleSepsWalletSettings",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318968331"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:29Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Fix grammar in `oracleSysDbaUser` descriptions.**\n\n```diff\n-\t  # Specifies the Oracle username for an account with sysdba privileges.\n+\t  # Specifies the Oracle username for an account that has sysdba privileges.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `oracleSysDbaUser` must use correct grammar. Suggested fix:  \n```diff\n-\t  # Specifies the Oracle username for an account with sysdba privileges.\n+\t  # Specifies the Oracle username for an account that has sysdba privileges.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 69015,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean\n+\n+  # Supported in v9.0+\n+  # Specifies whether the refresh of host metadata for this host is paused.\n+  isRefreshPaused: Boolean\n+\n+  # Required. Supported in v5.0+\n+  # A relic host is deleted, but still may have snapshots associated with its children (e.g. Fileset).\n+  isRelic: Boolean!\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v5.2: Boolean value that indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v5.3: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v6.0+: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+  mssqlCbtDriverInstalled: Boolean!\n+\n+  # Supported in v9.2+\n+  # Specifies the certificate ID corresponding to the public key certificate of the CA that signed the SQL server certificate for Sensitive Data Discovery.\n+  mssqlSddCertificateId: String\n+\n+  # Supported in v9.2+\n+  # Specifies the username configured for the SQL server instance for sensitive data discovery.\n+  mssqlSddUsername: String\n+\n+  # Supported in v5.0+\n+  # Specifies the Oracle username for an account with query privileges.\n+  oracleQueryUser: String\n+\n+  # Supported in v9.3+\n+  # Specifies the username configured for the Oracle host for sensitive data discovery.\n+  oracleSddUsername: String\n+\n+  # Supported in v9.3+\n+  # Specifies the wallet path on the Oracle host which is used to authenticate remote connections to oracle databases during Sensitive Data Discovery.\n+  oracleSddWalletPath: String\n+\n+  # Supported in v9.4+\n+  # Oracle SEPS settings for the host.\n+  oracleSepsSettings: OracleSepsWalletSettings\n+\n+  # Supported in v5.0+\n+  # Specifies the Oracle username for an account with sysdba privileges.\n+  oracleSysDbaUser: String",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318968444"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:31Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure `shouldMssqlSddThroughRba` descriptions use correct grammar. Apply suggested fixes.**\n\n```diff\n-\t  # A Boolean flag that specifies whether to perform the Data Discovery and Classification data acquisition workflow for SQL Server host through RBA.\n+\t  # A Boolean flag that specifies whether to perform the data discovery and classification data acquisition workflow for the SQL Server host through RBA.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `shouldMssqlSddThroughRba` must use correct grammar. Suggested fix:  \n```diff\n-\t  # A Boolean flag that specifies whether to perform the Data Discovery and Classification data acquisition workflow for SQL Server host through RBA.\n+\t  # A Boolean flag that specifies whether to perform the data discovery and classification data acquisition workflow for the SQL Server host through RBA.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 69019,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean\n+\n+  # Supported in v9.0+\n+  # Specifies whether the refresh of host metadata for this host is paused.\n+  isRefreshPaused: Boolean\n+\n+  # Required. Supported in v5.0+\n+  # A relic host is deleted, but still may have snapshots associated with its children (e.g. Fileset).\n+  isRelic: Boolean!\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v5.2: Boolean value that indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v5.3: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v6.0+: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+  mssqlCbtDriverInstalled: Boolean!\n+\n+  # Supported in v9.2+\n+  # Specifies the certificate ID corresponding to the public key certificate of the CA that signed the SQL server certificate for Sensitive Data Discovery.\n+  mssqlSddCertificateId: String\n+\n+  # Supported in v9.2+\n+  # Specifies the username configured for the SQL server instance for sensitive data discovery.\n+  mssqlSddUsername: String\n+\n+  # Supported in v5.0+\n+  # Specifies the Oracle username for an account with query privileges.\n+  oracleQueryUser: String\n+\n+  # Supported in v9.3+\n+  # Specifies the username configured for the Oracle host for sensitive data discovery.\n+  oracleSddUsername: String\n+\n+  # Supported in v9.3+\n+  # Specifies the wallet path on the Oracle host which is used to authenticate remote connections to oracle databases during Sensitive Data Discovery.\n+  oracleSddWalletPath: String\n+\n+  # Supported in v9.4+\n+  # Oracle SEPS settings for the host.\n+  oracleSepsSettings: OracleSepsWalletSettings\n+\n+  # Supported in v5.0+\n+  # Specifies the Oracle username for an account with sysdba privileges.\n+  oracleSysDbaUser: String\n+\n+  # Supported in v9.4+\n+  # A Boolean flag that specifies whether to perform the Data Discovery and Classification data acquisition workflow for SQL Server host through RBA.\n+  shouldMssqlSddThroughRba: Boolean",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318968555"
          }
        ]
      },
      "files_changed": [
        {
          "filename": "polaris/src/rubrik/api-server/app/services/physicalhost/rbac/BUILD.bazel",
          "status": "modified",
          "additions": 2,
          "deletions": 0,
          "patch": "@@ -8,6 +8,8 @@ rkscala_library(\n     deps = [\n         \"//rubrik/api-server:app_lib\",\n         \"//rubrik/api-server:external_library_deps\",\n+        \"//rubrik/api-server:proto_deps\",\n         \"//rubrik/api-server/app/services/physicalhost:physicalhost_proto\",\n+        \"//rubrik/common-scala\",\n     ],\n )"
        },
        {
          "filename": "polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala",
          "status": "modified",
          "additions": 230,
          "deletions": 4,
          "patch": "@@ -1,17 +1,243 @@\n package services.physicalhost.rbac\n \n+import authzservice.authzservice.InventorySubHierarchyRootEnum.LINUX_HOST_ROOT\n+import authzservice.authzservice.InventorySubHierarchyRootEnum.WINDOWS_HOST_ROOT\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister.HostRegisterOsType\n+import dal.grpc.UnifiedFeatureFlagService\n+import javax.inject.Inject\n+import models.graphql.AttributedFeatureFlagName\n+import models.graphql.FeatureFlagAttribute\n+import models.graphql.FlagAttribute\n import physicalhost.physicalhost.BulkRegisterSecondaryHostsReq\n import sangria.schema.Context\n import security.UserContext\n-import security.rbac.AdminOrOwnerAccessForDev\n+import security.rbac.And\n+import security.rbac.CustomRbacCheck\n+import security.rbac.CustomRbacCheckResult\n+import security.rbac.MoreRbacChecksNeeded\n+import security.rbac.Operation.AddInventory\n+import security.rbac.Operation.Ctx\n+import security.rbac.Operation.ManageDataSource\n+import security.rbac.Or\n+import security.rbac.RbacCheck\n import security.rbac.RbacPolicy\n \n-class PhysicalHostRbacPoliciesImpl extends PhysicalHostRbacPolicies {\n+class PhysicalHostRbacPoliciesImpl @Inject() (\n+  uffs: UnifiedFeatureFlagService\n+) extends PhysicalHostRbacPolicies {\n   // Add your custom RBAC policies here\n   def bulkRegisterSecondaryHosts(\n     argSupplier: Context[UserContext, _] => BulkRegisterSecondaryHostsReq\n   ): RbacPolicy = {\n-    // TODO(SPARK-572184): Add RBAC policy\n-    RbacPolicy(AdminOrOwnerAccessForDev)\n+    RbacPolicy(\n+      BulkSecondaryRegisterHostRbacCheck(argSupplier, uffs)\n+    )\n+  }\n+\n+  // TODO SPARK-283757 Fix RbacPolicy to use list of objects instead of\n+  //  multiple RBACChecks for each object.\n+  private case class BulkRegisterHostRbacCheck(\n+    clusterUuid: Ctx => String,\n+    hosts: Ctx => Seq[HostRegister]\n+  ) extends CustomRbacCheck {\n+    override def doRbacCheck(ctx: Ctx): CustomRbacCheckResult = {\n+      val hostRoots: Seq[String] =\n+        mapHostsToOsType(hosts, clusterUuid(ctx), ctx)\n+      // iterate over all hosts and check if they are linux or windows\n+      // if they are linux or windows, check if the user has the right to\n+      // manage the datasource\n+      val linuxHostRoots: Seq[String] =\n+        hostRoots.filter(\n+          _ == LINUX_HOST_ROOT.name\n+        )\n+      val windowsHostRoots: Seq[String] =\n+        hostRoots.filter(\n+          _ == WINDOWS_HOST_ROOT.name\n+        )\n+\n+      // If linuxHostRoots and windowsHostRoots both are empty,\n+      // then check access on\n+      // OR of Manage Data Source on linux and windows host roots\n+      (linuxHostRoots.nonEmpty, windowsHostRoots.nonEmpty) match {\n+        case (false, false) => {\n+          MoreRbacChecksNeeded(\n+            Or(\n+              RbacCheck(\n+                ManageDataSource,\n+                _ => Seq(LINUX_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+              RbacCheck(\n+                ManageDataSource,\n+                _ => Seq(WINDOWS_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+              And(\n+                RbacCheck(\n+                  AddInventory,\n+                  _ => Seq(LINUX_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+                RbacCheck(\n+                  AddInventory,\n+                  _ => Seq(WINDOWS_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+              )\n+            )\n+          )\n+        }\n+        // If linuxHostRoots and windowsHostRoots both are non-empty, then check\n+        // access on AND of Manage Data Source on linux and windows host roots\n+        case (true, true) => {\n+          MoreRbacChecksNeeded(\n+            Or(\n+              And(\n+                RbacCheck(\n+                  ManageDataSource,\n+                  _ => Seq(LINUX_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+                RbacCheck(\n+                  ManageDataSource,\n+                  _ => Seq(WINDOWS_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+              ),\n+              And(\n+                RbacCheck(\n+                  AddInventory,\n+                  _ => Seq(LINUX_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+                RbacCheck(\n+                  AddInventory,\n+                  _ => Seq(WINDOWS_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+              )\n+            )\n+          )\n+        }\n+        case (true, false) => {\n+          MoreRbacChecksNeeded(\n+            Or(\n+              RbacCheck(\n+                ManageDataSource,\n+                _ => Seq(LINUX_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+              RbacCheck(\n+                AddInventory,\n+                _ => Seq(LINUX_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+            )\n+          )\n+        }\n+        case (false, true) => {\n+          MoreRbacChecksNeeded(\n+            Or(\n+              RbacCheck(\n+                ManageDataSource,\n+                _ => Seq(WINDOWS_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+              RbacCheck(\n+                AddInventory,\n+                _ => Seq(WINDOWS_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+            )\n+          )\n+        }\n+      }\n+    }\n+  }\n+\n+  // A function that takes a Seq of HostRegister and filters it based on\n+  // osType of hosts\n+  private def mapHostsToOsType(\n+    hosts: Ctx => Seq[HostRegister],\n+    clusterUuid: String,\n+    ctx: Ctx\n+  ): Seq[String] = {\n+    val isRegisterHostOsTypeEnabled =\n+      uffs.isFeatureFlagTrue(\n+        ctx.ctx,\n+        AttributedFeatureFlagName.REGISTER_HOST_OS_TYPE_ENABLED.toString,\n+        Seq(\n+          FeatureFlagAttribute(\n+            FlagAttribute.CLUSTER_UUID,\n+            clusterUuid\n+          )\n+        )\n+      )\n+\n+    if (isRegisterHostOsTypeEnabled) {\n+      val hostRootsSeq: Seq[String] =\n+        hosts(ctx).map {\n+          host =>\n+            val osType = host.osType\n+            val hostRoot =\n+              Some(osType) match {\n+                case Some(HostRegisterOsType.HOST_REGISTER_OS_TYPE_LINUX) =>\n+                  LINUX_HOST_ROOT.name\n+                case Some(HostRegisterOsType.HOST_REGISTER_OS_TYPE_WINDOWS) =>\n+                  WINDOWS_HOST_ROOT.name\n+                case _ => \"\"\n+              }\n+            hostRoot\n+        }\n+      hostRootsSeq\n+    } else {\n+      Seq.empty\n+    }\n+  }\n+\n+  private case class BulkSecondaryRegisterHostRbacCheck(\n+    argSupplier: Context[UserContext, _] => BulkRegisterSecondaryHostsReq,\n+    uffs: UnifiedFeatureFlagService\n+  ) extends CustomRbacCheck {\n+    override def doRbacCheck(\n+      ctx: Context[UserContext, _]\n+    ): CustomRbacCheckResult = {\n+      val req = argSupplier(ctx)\n+      val primaryClusterUuids = req.hosts.map(_.primaryClusterUuid).distinct\n+\n+      // Secondary cluster check: Use the reusable BulkRegisterHostRbacCheck\n+      // class\n+      val secondaryClusterCheck =\n+        BulkRegisterHostRbacCheck(\n+          clusterUuid = _ => req.secondaryClusterUuid,\n+          hosts =\n+            ctx =>\n+              argSupplier(ctx).hosts.map(\n+                host =>\n+                  HostRegister()\n+                    .withOsType(host.osType)\n+              )\n+        )\n+\n+      // Primary cluster checks: requires ManageDataSource on individual host FIDs\n+      val primaryClusterChecks =\n+        primaryClusterUuids.map {\n+          primaryClusterUuid =>\n+            val hostsForCluster =\n+              req.hosts.filter(_.primaryClusterUuid == primaryClusterUuid)\n+            RbacCheck(\n+              ManageDataSource,\n+              _ => hostsForCluster.map(_.hostFid),\n+              clusterIdsOpt = _ => Some(Seq(primaryClusterUuid))\n+            )\n+        }\n+\n+      // Combine all checks with AND logic\n+      val allChecks = secondaryClusterCheck +: primaryClusterChecks\n+      val combinedCheck = allChecks.reduce(And(_, _))\n+\n+      MoreRbacChecksNeeded(combinedCheck)\n+    }\n   }\n }"
        },
        {
          "filename": "polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql",
          "status": "modified",
          "additions": 38,
          "deletions": 1,
          "patch": "@@ -17357,7 +17357,9 @@ type Mutation {\n     input: BulkRegisterHostAsyncInput!): BulkRegisterHostAsyncReply!\n \n   # BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n-  bulkRegisterSecondaryHosts: Void\n+  bulkRegisterSecondaryHosts(\n+    # The request containing secondary cluster UUID and hosts to register.\n+    input: BulkRegisterSecondaryHostsInput!): BulkRegisterSecondaryHostsReply!\n \n   # BulkRestoreM365BackupStorageObjects triggers the restore for the M365 Backup\n   # Storage Group workloads.\n@@ -52393,6 +52395,19 @@ type BulkRegisterHostReply {\n   # Total list responses.\n   total: Long\n }\n+# Request message for bulk registration of secondary hosts.\n+input BulkRegisterSecondaryHostsInput {\n+  # List of hosts to register as secondary hosts.\n+  hosts: [SecondaryRegisterHostInput!]!\n+\n+  # UUID of the secondary cluster where hosts will be registered.\n+  secondaryClusterUuid: String!\n+}\n+# Response message for bulk registration of secondary hosts.\n+type BulkRegisterSecondaryHostsReply {\n+  # Results for each host that was processed.\n+  hostResults: [HostSecondaryRegistrationResult!]!\n+}\n # Configuration for O365 Backup Storage Groups workload restore.\n input BulkRestoreM365BackupStorageObjectsInput {\n   # Collection of UUIDs of the all the group workloads.\n@@ -98730,6 +98745,17 @@ enum HostRoot {\n   # Windows Host Root.\n   WINDOWS_HOST_ROOT\n }\n+# Result for a single host registration.\n+type HostSecondaryRegistrationResult {\n+  # Error message if registration failed.\n+  errorMessage: String!\n+\n+  # Host details of secondary registration if registration was successful.\n+  hostDetail: HostDetail\n+\n+  # The host FID that was processed.\n+  primaryHostFid: String!\n+}\n # Host share type.\n type HostShare implements CdmHierarchyObject & HierarchyObject & PhysicalHostDescendantType & PhysicalHostPhysicalChildType {\n   # Organizations to which this hierarchy object belongs.\n@@ -169036,6 +169062,17 @@ type SecAppsUsage {\n   # Timestamp of the sec apps usage data.\n   timestamp: DateTime\n }\n+# Host details for secondary registration.\n+input SecondaryRegisterHostInput {\n+  # The host FID (unique identifier).\n+  hostFid: String!\n+\n+  # Operating system type of the host.\n+  osType: HostRegisterOsType\n+\n+  # UUID of the primary cluster where the host currently resides.\n+  primaryClusterUuid: String!\n+}\n # This is used by report tables that support a two-layer view of data.\n type SecondaryTableConfig {\n   # The primary table metadata values."
        },
        {
          "filename": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
          "status": "modified",
          "additions": 40,
          "deletions": 0,
          "patch": "@@ -10142,6 +10142,11 @@ type Mutation {\n     # Input for V1BulkRegisterHostAsync.\n     input: BulkRegisterHostAsyncInput!): BulkRegisterHostAsyncReply!\n \n+  # BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n+  bulkRegisterSecondaryHosts(\n+    # The request containing secondary cluster UUID and hosts to register.\n+    input: BulkRegisterSecondaryHostsInput!): BulkRegisterSecondaryHostsReply!\n+\n   # Bulk tier existing snapshots to cold storage\n   # \n   # Supported in v6.0+\n@@ -37073,6 +37078,19 @@ type BulkRegisterHostReply {\n   # Total list responses.\n   total: Long\n }\n+# Request message for bulk registration of secondary hosts.\n+input BulkRegisterSecondaryHostsInput {\n+  # List of hosts to register as secondary hosts.\n+  hosts: [SecondaryRegisterHostInput!]!\n+\n+  # UUID of the secondary cluster where hosts will be registered.\n+  secondaryClusterUuid: String!\n+}\n+# Response message for bulk registration of secondary hosts.\n+type BulkRegisterSecondaryHostsReply {\n+  # Results for each host that was processed.\n+  hostResults: [HostSecondaryRegistrationResult!]!\n+}\n # Validation status of the bulk threat hunt request.\n enum BulkThreatHuntValidationStatus {\n   # Validation failed because the number of separate hunts that will be\n@@ -69730,6 +69748,17 @@ enum HostRoot {\n   # Windows Host Root.\n   WINDOWS_HOST_ROOT\n }\n+# Result for a single host registration.\n+type HostSecondaryRegistrationResult {\n+  # Error message if registration failed.\n+  errorMessage: String!\n+\n+  # Host details of secondary registration if registration was successful.\n+  hostDetail: HostDetail\n+\n+  # The host FID that was processed.\n+  primaryHostFid: String!\n+}\n # Host share type.\n type HostShare implements CdmHierarchyObject & HierarchyObject & PhysicalHostDescendantType & PhysicalHostPhysicalChildType {\n   # Organizations to which this hierarchy object belongs.\n@@ -118916,6 +118945,17 @@ type SearchResponseListResponse {\n   # Total list responses.\n   total: Long\n }\n+# Host details for secondary registration.\n+input SecondaryRegisterHostInput {\n+  # The host FID (unique identifier).\n+  hostFid: String!\n+\n+  # Operating system type of the host.\n+  osType: HostRegisterOsType\n+\n+  # UUID of the primary cluster where the host currently resides.\n+  primaryClusterUuid: String!\n+}\n type SecurityGroup {\n   id: String!\n   name: String!"
        },
        {
          "filename": "polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql",
          "status": "modified",
          "additions": 40,
          "deletions": 0,
          "patch": "@@ -10142,6 +10142,11 @@ type Mutation {\n     # Input for V1BulkRegisterHostAsync.\n     input: BulkRegisterHostAsyncInput!): BulkRegisterHostAsyncReply!\n \n+  # BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n+  bulkRegisterSecondaryHosts(\n+    # The request containing secondary cluster UUID and hosts to register.\n+    input: BulkRegisterSecondaryHostsInput!): BulkRegisterSecondaryHostsReply!\n+\n   # Bulk tier existing snapshots to cold storage\n   # \n   # Supported in v6.0+\n@@ -37073,6 +37078,19 @@ type BulkRegisterHostReply {\n   # Total list responses.\n   total: Long\n }\n+# Request message for bulk registration of secondary hosts.\n+input BulkRegisterSecondaryHostsInput {\n+  # List of hosts to register as secondary hosts.\n+  hosts: [SecondaryRegisterHostInput!]!\n+\n+  # UUID of the secondary cluster where hosts will be registered.\n+  secondaryClusterUuid: String!\n+}\n+# Response message for bulk registration of secondary hosts.\n+type BulkRegisterSecondaryHostsReply {\n+  # Results for each host that was processed.\n+  hostResults: [HostSecondaryRegistrationResult!]!\n+}\n # Validation status of the bulk threat hunt request.\n enum BulkThreatHuntValidationStatus {\n   # Validation failed because the number of separate hunts that will be\n@@ -69730,6 +69748,17 @@ enum HostRoot {\n   # Windows Host Root.\n   WINDOWS_HOST_ROOT\n }\n+# Result for a single host registration.\n+type HostSecondaryRegistrationResult {\n+  # Error message if registration failed.\n+  errorMessage: String!\n+\n+  # Host details of secondary registration if registration was successful.\n+  hostDetail: HostDetail\n+\n+  # The host FID that was processed.\n+  primaryHostFid: String!\n+}\n # Host share type.\n type HostShare implements CdmHierarchyObject , HierarchyObject , PhysicalHostDescendantType , PhysicalHostPhysicalChildType {\n   # Organizations to which this hierarchy object belongs.\n@@ -118916,6 +118945,17 @@ type SearchResponseListResponse {\n   # Total list responses.\n   total: Long\n }\n+# Host details for secondary registration.\n+input SecondaryRegisterHostInput {\n+  # The host FID (unique identifier).\n+  hostFid: String!\n+\n+  # Operating system type of the host.\n+  osType: HostRegisterOsType\n+\n+  # UUID of the primary cluster where the host currently resides.\n+  primaryClusterUuid: String!\n+}\n type SecurityGroup {\n   id: String!\n   name: String!"
        },
        {
          "filename": "polaris/src/rubrik/api-server/test/app/services/physicalhost/rbac/BUILD.bazel",
          "status": "added",
          "additions": 17,
          "deletions": 0,
          "patch": "@@ -0,0 +1,17 @@\n+rkscala_test(\n+    name = \"physicalhost_rbac_test\",\n+    srcs = glob([\"*.scala\"]),\n+    jvm_flags = [\n+        \"-Dconfig.resource=functional/application.conf\",\n+    ],\n+    deps = [\n+        \"//rubrik/api-server:app_lib\",\n+        \"//rubrik/api-server:external_library_deps\",\n+        \"//rubrik/api-server:proto_deps\",\n+        \"//rubrik/api-server/app/services/physicalhost:physicalhost_proto\",\n+        \"//rubrik/api-server/app/services/physicalhost/rbac\",\n+        \"//rubrik/api-server/testing/common\",\n+        \"//rubrik/common-scala\",\n+        \"//rubrik/scala_thirdparty/junit\",\n+    ],\n+)"
        },
        {
          "filename": "polaris/src/rubrik/api-server/test/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImplTest.scala",
          "status": "added",
          "additions": 230,
          "deletions": 0,
          "patch": "@@ -0,0 +1,230 @@\n+package services.physicalhost.rbac\n+\n+import authzservice.authzservice.InventorySubHierarchyRootEnum.LINUX_HOST_ROOT\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister.HostRegisterOsType\n+import dal.grpc.UnifiedFeatureFlagService\n+import java.util.UUID\n+import models.graphql.AttributedFeatureFlagName\n+import models.graphql.FeatureFlagAttribute\n+import org.junit.Test\n+import org.mockito.ArgumentMatchers\n+import org.mockito.ArgumentMatchers.any\n+import org.mockito.Mockito.when\n+import physicalhost.physicalhost.BulkRegisterSecondaryHostsReq\n+import physicalhost.physicalhost.SecondaryRegisterHostInput\n+import security.UserContext\n+import security.rbac.Operation.AddInventory\n+import security.rbac.Operation.Ctx\n+import security.rbac.Operation.ManageDataSource\n+import testing.common.RbacOperationTester\n+import testing.common.RbacTestHelper\n+import testing.common.RubrikUnitSuite\n+import testing.common.UserTestHelper\n+import testing.common.UserTestHelper.UserWrapper\n+\n+class PhysicalHostRbacPoliciesImplTest extends RubrikUnitSuite {\n+\n+  private case class Deps(\n+    tester: RbacOperationTester,\n+    rbacHelper: RbacTestHelper,\n+    localUser: UserWrapper,\n+    policies: PhysicalHostRbacPoliciesImpl,\n+    uffs: UnifiedFeatureFlagService,\n+  ) {}\n+\n+  private def init(): Deps = {\n+    val tester = RbacOperationTester()\n+    val userHelper = UserTestHelper(tester.fus, tester.authz, tester.ams)\n+    val rbacHelper = RbacTestHelper(tester.authz, tester.qauthSvc)\n+\n+    val uffs = mock[UnifiedFeatureFlagService]\n+    val policies = new PhysicalHostRbacPoliciesImpl(uffs)\n+\n+    val localUser = userHelper.createLocalUser()\n+    Deps(\n+      tester,\n+      rbacHelper,\n+      localUser,\n+      policies,\n+      uffs,\n+    )\n+  }\n+\n+  @Test\n+  def testRbacPolicyForBulkRegisterSecondaryHosts(): Unit = {\n+    val deps = init()\n+    val endUser = deps.localUser.user()\n+\n+    // Test data - matching the exact structure from v1 tests\n+    val secondaryClusterUuid = UUID.randomUUID.toString\n+    val primaryClusterUuid1 = UUID.randomUUID.toString\n+    val primaryClusterUuid2 = UUID.randomUUID.toString\n+    val hostFid1 = UUID.randomUUID.toString\n+    val hostFid2 = UUID.randomUUID.toString\n+    val hostFid3 = UUID.randomUUID.toString\n+\n+    // Enable feature flag\n+    when(\n+      deps.uffs.isFeatureFlagTrue(\n+        any[UserContext],\n+        ArgumentMatchers.eq(\n+          AttributedFeatureFlagName.REGISTER_HOST_OS_TYPE_ENABLED.toString\n+        ),\n+        any[Seq[FeatureFlagAttribute]]\n+      )\n+    ).thenReturn(true)\n+\n+    val hosts =\n+      Seq(\n+        SecondaryRegisterHostInput()\n+          .withHostFid(hostFid1)\n+          .withPrimaryClusterUuid(primaryClusterUuid1)\n+          .withOsType(HostRegisterOsType.HOST_REGISTER_OS_TYPE_LINUX),\n+        SecondaryRegisterHostInput()\n+          .withHostFid(hostFid2)\n+          .withPrimaryClusterUuid(primaryClusterUuid1)\n+          .withOsType(HostRegisterOsType.HOST_REGISTER_OS_TYPE_LINUX),\n+        SecondaryRegisterHostInput()\n+          .withHostFid(hostFid3)\n+          .withPrimaryClusterUuid(primaryClusterUuid2)\n+          .withOsType(HostRegisterOsType.HOST_REGISTER_OS_TYPE_LINUX)\n+      )\n+\n+    val reqFn: Ctx => BulkRegisterSecondaryHostsReq =\n+      _ =>\n+        BulkRegisterSecondaryHostsReq()\n+          .withSecondaryClusterUuid(secondaryClusterUuid)\n+          .withHosts(hosts)\n+\n+    // Test 1: No access without any permissions\n+    deps.rbacHelper.runWithAuthorization(\n+      endUser,\n+      List.empty,\n+      List.empty\n+    ) {\n+      deps.tester.assertNoAccess(\n+        user = endUser,\n+        rbacPolicy = deps.policies.bulkRegisterSecondaryHosts(reqFn)\n+      )\n+    }\n+\n+    // Test 2: No access with only ManageDataSource on secondary cluster\n+    // (missing permissions on primary cluster)\n+    deps.rbacHelper.runWithAuthorization(\n+      endUser,\n+      List(ManageDataSource),\n+      List(LINUX_HOST_ROOT.name),\n+      clusterIdsOpt = Some(List(secondaryClusterUuid))\n+    ) {\n+      deps.tester.assertNoAccess(\n+        user = endUser,\n+        rbacPolicy = deps.policies.bulkRegisterSecondaryHosts(reqFn)\n+      )\n+    }\n+\n+    // Test 3: No access with only AddInventory on secondary cluster\n+    // (missing permissions on primary cluster)\n+    deps.rbacHelper.runWithAuthorization(\n+      endUser,\n+      List(AddInventory),\n+      List(LINUX_HOST_ROOT.name),\n+      clusterIdsOpt = Some(List(secondaryClusterUuid))\n+    ) {\n+      deps.tester.assertNoAccess(\n+        user = endUser,\n+        rbacPolicy = deps.policies.bulkRegisterSecondaryHosts(reqFn)\n+      )\n+    }\n+\n+    // Test 4: No access with partial primary cluster permissions\n+    // (missing permission on the third host)\n+    deps.rbacHelper.runWithAuthorization(\n+      endUser,\n+      List(ManageDataSource, AddInventory),\n+      List(LINUX_HOST_ROOT.name, hostFid1, hostFid2), // Missing hostFid3\n+      clusterIdsOpt =\n+        Some(\n+          List(secondaryClusterUuid, primaryClusterUuid1, primaryClusterUuid2)\n+        )\n+    ) {\n+      deps.tester.assertNoAccess(\n+        user = endUser,\n+        rbacPolicy = deps.policies.bulkRegisterSecondaryHosts(reqFn)\n+      )\n+    }\n+\n+    // Test 5: Has access with all required permissions\n+    deps.rbacHelper.runWithAuthorization(\n+      endUser,\n+      List(ManageDataSource, AddInventory),\n+      List(LINUX_HOST_ROOT.name, hostFid1, hostFid2, hostFid3),\n+      clusterIdsOpt =\n+        Some(\n+          List(secondaryClusterUuid, primaryClusterUuid1, primaryClusterUuid2)\n+        )\n+    ) {\n+      deps.tester.assertHasAccess(\n+        user = endUser,\n+        rbacPolicy = deps.policies.bulkRegisterSecondaryHosts(reqFn)\n+      )\n+    }\n+\n+    // Test 6: Test with empty hosts list (should succeed with minimal\n+    // permissions)\n+    deps.rbacHelper.runWithAuthorization(\n+      endUser,\n+      List(ManageDataSource, AddInventory),\n+      List(LINUX_HOST_ROOT.name),\n+      clusterIdsOpt = Some(List(secondaryClusterUuid))\n+    ) {\n+      deps.tester.assertHasAccess(\n+        user = endUser,\n+        rbacPolicy =\n+          deps.policies.bulkRegisterSecondaryHosts(\n+            reqFn.andThen(_.withHosts(Seq.empty))\n+          )\n+      )\n+    }\n+\n+    // Test 7: Test with single host (simpler case)\n+    val singleHost = Seq(hosts.head)\n+    deps.rbacHelper.runWithAuthorization(\n+      endUser,\n+      List(ManageDataSource, AddInventory),\n+      List(LINUX_HOST_ROOT.name, hostFid1),\n+      clusterIdsOpt = Some(List(secondaryClusterUuid, primaryClusterUuid1))\n+    ) {\n+      deps.tester.assertHasAccess(\n+        user = endUser,\n+        rbacPolicy =\n+          deps.policies.bulkRegisterSecondaryHosts(\n+            reqFn.andThen(_.withHosts(singleHost))\n+          )\n+      )\n+    }\n+\n+    // Test 8: AddInventory on secondary cluster and ManageDataSource on\n+    // primary cluster\n+    deps.rbacHelper.runWithAuthorization(\n+      endUser,\n+      List(AddInventory),\n+      List(LINUX_HOST_ROOT.name),\n+      clusterIdsOpt = Some(List(secondaryClusterUuid))\n+    ) {\n+      deps.rbacHelper.runWithAuthorization(\n+        endUser,\n+        List(ManageDataSource),\n+        List(hostFid1),\n+        clusterIdsOpt = Some(List(primaryClusterUuid1))\n+      ) {\n+        deps.tester.assertHasAccess(\n+          user = endUser,\n+          rbacPolicy =\n+            deps.policies.bulkRegisterSecondaryHosts(\n+              reqFn.andThen(_.withHosts(singleHost))\n+            )\n+        )\n+      }\n+    }\n+  }\n+}"
        },
        {
          "filename": "polaris/src/rubrik/global-api/schema/schema.go",
          "status": "modified",
          "additions": 24,
          "deletions": 1,
          "patch": "@@ -11167,6 +11167,12 @@ type AzureAdOnPremSyncStatus string\n \n type CdmDataGuardType string\n \n+type SecondaryRegisterHostInput struct {\n+\tHostFid            string              `json:\"hostFid\"`\n+\tOsType             *HostRegisterOsType `json:\"osType\"`\n+\tPrimaryClusterUuid string              `json:\"primaryClusterUuid\"`\n+}\n+\n type SourceDataFiltersInput struct {\n \tExtensionWhitelist     []string                     `json:\"extensionWhitelist\"`\n \tModifiedTimeRange      *ChatbotTimeRangeFilterInput `json:\"modifiedTimeRange\"`\n@@ -35272,6 +35278,11 @@ type SnappableInfoType struct {\n \tRecoveryPoint *int64  `json:\"recoveryPoint\"`\n }\n \n+type BulkRegisterSecondaryHostsInput struct {\n+\tHosts                []SecondaryRegisterHostInput `json:\"hosts\"`\n+\tSecondaryClusterUuid string                       `json:\"secondaryClusterUuid\"`\n+}\n+\n type TprRequestSummaryEdge struct {\n \t__typename string            `json:\"__typename\"`\n \tCursor     string            `json:\"cursor\"`\n@@ -44482,6 +44493,13 @@ type SalesforcePermissionNode struct {\n \tSalesforcePermission *SalesforcePermission `json:\"salesforcePermission\"`\n }\n \n+type HostSecondaryRegistrationResult struct {\n+\t__typename     string      `json:\"__typename\"`\n+\tErrorMessage   string      `json:\"errorMessage\"`\n+\tHostDetail     *HostDetail `json:\"hostDetail\"`\n+\tPrimaryHostFid string      `json:\"primaryHostFid\"`\n+}\n+\n type MetadataOneof struct {\n \tHuntId             *string `json:\"huntId\"`\n \tIsThreatMonitoring *bool   `json:\"isThreatMonitoring\"`\n@@ -54075,7 +54093,7 @@ type Mutation struct {\n \tBulkRefreshHosts                                       BulkRefreshHostsReply                                `json:\"bulkRefreshHosts\"`\n \tBulkRegisterHost                                       BulkRegisterHostReply                                `json:\"bulkRegisterHost\"`\n \tBulkRegisterHostAsync                                  BulkRegisterHostAsyncReply                           `json:\"bulkRegisterHostAsync\"`\n-\tBulkRegisterSecondaryHosts                             *Void                                                `json:\"bulkRegisterSecondaryHosts\"`\n+\tBulkRegisterSecondaryHosts                             BulkRegisterSecondaryHostsReply                      `json:\"bulkRegisterSecondaryHosts\"`\n \tBulkRestoreM365BackupStorageObjects                    BulkRestoreM365BackupStorageObjectsReply             `json:\"bulkRestoreM365BackupStorageObjects\"`\n \tBulkRotateClusterEncryptionKey                         BulkRotateClusterEncryptionKeyReply                  `json:\"bulkRotateClusterEncryptionKey\"`\n \tBulkTierExistingSnapshots                              AsyncRequestStatus                                   `json:\"bulkTierExistingSnapshots\"`\n@@ -67472,6 +67490,11 @@ type M365BackupStorageLicenseUsage struct {\n \tOrgConsumptionsEntry []M365BackupStorageOrgLicenseUsage  `json:\"orgConsumptionsEntry\"`\n }\n \n+type BulkRegisterSecondaryHostsReply struct {\n+\t__typename  string                            `json:\"__typename\"`\n+\tHostResults []HostSecondaryRegistrationResult `json:\"hostResults\"`\n+}\n+\n type LinuxRbsBulkInstallReply struct {\n \t__typename string               `json:\"__typename\"`\n \tOutput     *BulkRbsInstallReply `json:\"output\"`"
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/proto/BUILD.bazel",
          "status": "modified",
          "additions": 2,
          "deletions": 0,
          "patch": "@@ -5,6 +5,7 @@ proto_library(\n     visibility = [\"//visibility:public\"],\n     deps = [\n         \"//rubrik/api-server/app/v2/proto:api_proto\",\n+        \"//rubrik/cdm-rest-service/proto/types:types_proto\",\n         \"//rubrik/common-go/api/context/proto:proto_proto\",\n         \"//rubrik/scalapb/proto:scalapb_proto\",\n     ],\n@@ -21,6 +22,7 @@ go_library(\n     visibility = [\"//visibility:public\"],\n     deps = [\n         \"//rubrik/api-server/app/v2/proto:go_default_library\",\n+        \"//rubrik/cdm-rest-service/proto/types:go_default_library\",\n         \"//rubrik/common-go/api/context/proto:go_default_library\",\n         \"//rubrik/scalapb/proto:go_default_library\",\n         \"//rubrik/vendor/github.com/stretchr/testify/mock:go_default_library\","
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/proto/physicalhost.pb.go",
          "status": "modified",
          "additions": 291,
          "deletions": 53,
          "patch": "@@ -18,6 +18,7 @@ import (\n \tprotoimpl \"google.golang.org/protobuf/runtime/protoimpl\"\n \n \t_ \"rubrik/api-server/app/v2/proto\"\n+\ttypes \"rubrik/cdm-rest-service/proto/types\"\n \tproto \"rubrik/common-go/api/context/proto\"\n \t_ \"rubrik/scalapb/proto\"\n )\n@@ -127,19 +128,90 @@ func (x *EchoReply) GetReply() string {\n \treturn \"\"\n }\n \n+// Host details for secondary registration.\n+type SecondaryRegisterHostInput struct {\n+\tstate         protoimpl.MessageState\n+\tsizeCache     protoimpl.SizeCache\n+\tunknownFields protoimpl.UnknownFields\n+\n+\t// The host FID (unique identifier).\n+\tHostFid string `protobuf:\"bytes,1,opt,name=host_fid,json=hostFid,proto3\" json:\"host_fid,omitempty\"`\n+\t// UUID of the primary cluster where the host currently resides.\n+\tPrimaryClusterUuid string `protobuf:\"bytes,2,opt,name=primary_cluster_uuid,json=primaryClusterUuid,proto3\" json:\"primary_cluster_uuid,omitempty\"`\n+\t// Operating system type of the host.\n+\tOsType types.HostRegister_HostRegisterOsType `protobuf:\"varint,3,opt,name=os_type,json=osType,proto3,enum=cdmrestservice.HostRegister_HostRegisterOsType\" json:\"os_type,omitempty\"`\n+}\n+\n+func (x *SecondaryRegisterHostInput) Reset() {\n+\t*x = SecondaryRegisterHostInput{}\n+\tif protoimpl.UnsafeEnabled {\n+\t\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[2]\n+\t\tms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))\n+\t\tms.StoreMessageInfo(mi)\n+\t}\n+}\n+\n+func (x *SecondaryRegisterHostInput) String() string {\n+\treturn protoimpl.X.MessageStringOf(x)\n+}\n+\n+func (*SecondaryRegisterHostInput) ProtoMessage() {}\n+\n+func (x *SecondaryRegisterHostInput) ProtoReflect() protoreflect.Message {\n+\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[2]\n+\tif protoimpl.UnsafeEnabled && x != nil {\n+\t\tms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))\n+\t\tif ms.LoadMessageInfo() == nil {\n+\t\t\tms.StoreMessageInfo(mi)\n+\t\t}\n+\t\treturn ms\n+\t}\n+\treturn mi.MessageOf(x)\n+}\n+\n+// Deprecated: Use SecondaryRegisterHostInput.ProtoReflect.Descriptor instead.\n+func (*SecondaryRegisterHostInput) Descriptor() ([]byte, []int) {\n+\treturn file_rubrik_physicalhost_proto_physicalhost_proto_rawDescGZIP(), []int{2}\n+}\n+\n+func (x *SecondaryRegisterHostInput) GetHostFid() string {\n+\tif x != nil {\n+\t\treturn x.HostFid\n+\t}\n+\treturn \"\"\n+}\n+\n+func (x *SecondaryRegisterHostInput) GetPrimaryClusterUuid() string {\n+\tif x != nil {\n+\t\treturn x.PrimaryClusterUuid\n+\t}\n+\treturn \"\"\n+}\n+\n+func (x *SecondaryRegisterHostInput) GetOsType() types.HostRegister_HostRegisterOsType {\n+\tif x != nil {\n+\t\treturn x.OsType\n+\t}\n+\treturn types.HostRegister_HostRegisterOsType(0)\n+}\n+\n // Request message for bulk registration of secondary hosts.\n type BulkRegisterSecondaryHostsReq struct {\n \tstate         protoimpl.MessageState\n \tsizeCache     protoimpl.SizeCache\n \tunknownFields protoimpl.UnknownFields\n \n \tReqCtx *proto.RequestContext `protobuf:\"bytes,1,opt,name=req_ctx,json=reqCtx,proto3\" json:\"req_ctx,omitempty\"`\n+\t// UUID of the secondary cluster where hosts will be registered.\n+\tSecondaryClusterUuid string `protobuf:\"bytes,2,opt,name=secondary_cluster_uuid,json=secondaryClusterUuid,proto3\" json:\"secondary_cluster_uuid,omitempty\"`\n+\t// List of hosts to register as secondary hosts.\n+\tHosts []*SecondaryRegisterHostInput `protobuf:\"bytes,3,rep,name=hosts,proto3\" json:\"hosts,omitempty\"`\n }\n \n func (x *BulkRegisterSecondaryHostsReq) Reset() {\n \t*x = BulkRegisterSecondaryHostsReq{}\n \tif protoimpl.UnsafeEnabled {\n-\t\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[2]\n+\t\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[3]\n \t\tms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))\n \t\tms.StoreMessageInfo(mi)\n \t}\n@@ -152,7 +224,7 @@ func (x *BulkRegisterSecondaryHostsReq) String() string {\n func (*BulkRegisterSecondaryHostsReq) ProtoMessage() {}\n \n func (x *BulkRegisterSecondaryHostsReq) ProtoReflect() protoreflect.Message {\n-\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[2]\n+\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[3]\n \tif protoimpl.UnsafeEnabled && x != nil {\n \t\tms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))\n \t\tif ms.LoadMessageInfo() == nil {\n@@ -165,7 +237,7 @@ func (x *BulkRegisterSecondaryHostsReq) ProtoReflect() protoreflect.Message {\n \n // Deprecated: Use BulkRegisterSecondaryHostsReq.ProtoReflect.Descriptor instead.\n func (*BulkRegisterSecondaryHostsReq) Descriptor() ([]byte, []int) {\n-\treturn file_rubrik_physicalhost_proto_physicalhost_proto_rawDescGZIP(), []int{2}\n+\treturn file_rubrik_physicalhost_proto_physicalhost_proto_rawDescGZIP(), []int{3}\n }\n \n func (x *BulkRegisterSecondaryHostsReq) GetReqCtx() *proto.RequestContext {\n@@ -175,17 +247,101 @@ func (x *BulkRegisterSecondaryHostsReq) GetReqCtx() *proto.RequestContext {\n \treturn nil\n }\n \n+func (x *BulkRegisterSecondaryHostsReq) GetSecondaryClusterUuid() string {\n+\tif x != nil {\n+\t\treturn x.SecondaryClusterUuid\n+\t}\n+\treturn \"\"\n+}\n+\n+func (x *BulkRegisterSecondaryHostsReq) GetHosts() []*SecondaryRegisterHostInput {\n+\tif x != nil {\n+\t\treturn x.Hosts\n+\t}\n+\treturn nil\n+}\n+\n+// Result for a single host registration.\n+type HostSecondaryRegistrationResult struct {\n+\tstate         protoimpl.MessageState\n+\tsizeCache     protoimpl.SizeCache\n+\tunknownFields protoimpl.UnknownFields\n+\n+\t// The host FID that was processed.\n+\tPrimaryHostFid string `protobuf:\"bytes,1,opt,name=primary_host_fid,json=primaryHostFid,proto3\" json:\"primary_host_fid,omitempty\"`\n+\t// Error message if registration failed.\n+\tErrorMessage string `protobuf:\"bytes,2,opt,name=error_message,json=errorMessage,proto3\" json:\"error_message,omitempty\"`\n+\t// Host details of secondary registration if registration was successful.\n+\tHostDetail *types.HostDetail `protobuf:\"bytes,3,opt,name=host_detail,json=hostDetail,proto3\" json:\"host_detail,omitempty\"`\n+}\n+\n+func (x *HostSecondaryRegistrationResult) Reset() {\n+\t*x = HostSecondaryRegistrationResult{}\n+\tif protoimpl.UnsafeEnabled {\n+\t\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[4]\n+\t\tms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))\n+\t\tms.StoreMessageInfo(mi)\n+\t}\n+}\n+\n+func (x *HostSecondaryRegistrationResult) String() string {\n+\treturn protoimpl.X.MessageStringOf(x)\n+}\n+\n+func (*HostSecondaryRegistrationResult) ProtoMessage() {}\n+\n+func (x *HostSecondaryRegistrationResult) ProtoReflect() protoreflect.Message {\n+\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[4]\n+\tif protoimpl.UnsafeEnabled && x != nil {\n+\t\tms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))\n+\t\tif ms.LoadMessageInfo() == nil {\n+\t\t\tms.StoreMessageInfo(mi)\n+\t\t}\n+\t\treturn ms\n+\t}\n+\treturn mi.MessageOf(x)\n+}\n+\n+// Deprecated: Use HostSecondaryRegistrationResult.ProtoReflect.Descriptor instead.\n+func (*HostSecondaryRegistrationResult) Descriptor() ([]byte, []int) {\n+\treturn file_rubrik_physicalhost_proto_physicalhost_proto_rawDescGZIP(), []int{4}\n+}\n+\n+func (x *HostSecondaryRegistrationResult) GetPrimaryHostFid() string {\n+\tif x != nil {\n+\t\treturn x.PrimaryHostFid\n+\t}\n+\treturn \"\"\n+}\n+\n+func (x *HostSecondaryRegistrationResult) GetErrorMessage() string {\n+\tif x != nil {\n+\t\treturn x.ErrorMessage\n+\t}\n+\treturn \"\"\n+}\n+\n+func (x *HostSecondaryRegistrationResult) GetHostDetail() *types.HostDetail {\n+\tif x != nil {\n+\t\treturn x.HostDetail\n+\t}\n+\treturn nil\n+}\n+\n // Response message for bulk registration of secondary hosts.\n type BulkRegisterSecondaryHostsReply struct {\n \tstate         protoimpl.MessageState\n \tsizeCache     protoimpl.SizeCache\n \tunknownFields protoimpl.UnknownFields\n+\n+\t// Results for each host that was processed.\n+\tHostResults []*HostSecondaryRegistrationResult `protobuf:\"bytes,1,rep,name=host_results,json=hostResults,proto3\" json:\"host_results,omitempty\"`\n }\n \n func (x *BulkRegisterSecondaryHostsReply) Reset() {\n \t*x = BulkRegisterSecondaryHostsReply{}\n \tif protoimpl.UnsafeEnabled {\n-\t\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[3]\n+\t\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[5]\n \t\tms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))\n \t\tms.StoreMessageInfo(mi)\n \t}\n@@ -198,7 +354,7 @@ func (x *BulkRegisterSecondaryHostsReply) String() string {\n func (*BulkRegisterSecondaryHostsReply) ProtoMessage() {}\n \n func (x *BulkRegisterSecondaryHostsReply) ProtoReflect() protoreflect.Message {\n-\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[3]\n+\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[5]\n \tif protoimpl.UnsafeEnabled && x != nil {\n \t\tms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))\n \t\tif ms.LoadMessageInfo() == nil {\n@@ -211,7 +367,14 @@ func (x *BulkRegisterSecondaryHostsReply) ProtoReflect() protoreflect.Message {\n \n // Deprecated: Use BulkRegisterSecondaryHostsReply.ProtoReflect.Descriptor instead.\n func (*BulkRegisterSecondaryHostsReply) Descriptor() ([]byte, []int) {\n-\treturn file_rubrik_physicalhost_proto_physicalhost_proto_rawDescGZIP(), []int{3}\n+\treturn file_rubrik_physicalhost_proto_physicalhost_proto_rawDescGZIP(), []int{5}\n+}\n+\n+func (x *BulkRegisterSecondaryHostsReply) GetHostResults() []*HostSecondaryRegistrationResult {\n+\tif x != nil {\n+\t\treturn x.HostResults\n+\t}\n+\treturn nil\n }\n \n var File_rubrik_physicalhost_proto_physicalhost_proto protoreflect.FileDescriptor\n@@ -228,39 +391,80 @@ var file_rubrik_physicalhost_proto_physicalhost_proto_rawDesc = []byte{\n \t0x72, 0x2f, 0x61, 0x70, 0x70, 0x2f, 0x76, 0x32, 0x2f, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x2f, 0x61,\n \t0x70, 0x69, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x1a, 0x22, 0x72, 0x75, 0x62, 0x72, 0x69, 0x6b,\n \t0x2f, 0x73, 0x63, 0x61, 0x6c, 0x61, 0x70, 0x62, 0x2f, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x2f, 0x73,\n-\t0x63, 0x61, 0x6c, 0x61, 0x70, 0x62, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x22, 0x1d, 0x0a, 0x07,\n+\t0x63, 0x61, 0x6c, 0x61, 0x70, 0x62, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x1a, 0x3e, 0x72, 0x75,\n+\t0x62, 0x72, 0x69, 0x6b, 0x2f, 0x63, 0x64, 0x6d, 0x2d, 0x72, 0x65, 0x73, 0x74, 0x2d, 0x73, 0x65,\n+\t0x72, 0x76, 0x69, 0x63, 0x65, 0x2f, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x2f, 0x74, 0x79, 0x70, 0x65,\n+\t0x73, 0x2f, 0x63, 0x64, 0x6d, 0x72, 0x65, 0x73, 0x74, 0x73, 0x65, 0x72, 0x76, 0x69, 0x63, 0x65,\n+\t0x5f, 0x74, 0x79, 0x70, 0x65, 0x73, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x22, 0x1d, 0x0a, 0x07,\n \t0x45, 0x63, 0x68, 0x6f, 0x52, 0x65, 0x71, 0x12, 0x12, 0x0a, 0x04, 0x61, 0x72, 0x67, 0x31, 0x18,\n \t0x01, 0x20, 0x01, 0x28, 0x09, 0x52, 0x04, 0x61, 0x72, 0x67, 0x31, 0x22, 0x21, 0x0a, 0x09, 0x45,\n \t0x63, 0x68, 0x6f, 0x52, 0x65, 0x70, 0x6c, 0x79, 0x12, 0x14, 0x0a, 0x05, 0x72, 0x65, 0x70, 0x6c,\n-\t0x79, 0x18, 0x01, 0x20, 0x01, 0x28, 0x09, 0x52, 0x05, 0x72, 0x65, 0x70, 0x6c, 0x79, 0x22, 0x51,\n-\t0x0a, 0x1d, 0x42, 0x75, 0x6c, 0x6b, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x53, 0x65,\n-\t0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x48, 0x6f, 0x73, 0x74, 0x73, 0x52, 0x65, 0x71, 0x12,\n-\t0x30, 0x0a, 0x07, 0x72, 0x65, 0x71, 0x5f, 0x63, 0x74, 0x78, 0x18, 0x01, 0x20, 0x01, 0x28, 0x0b,\n-\t0x32, 0x17, 0x2e, 0x63, 0x6f, 0x6e, 0x74, 0x65, 0x78, 0x74, 0x2e, 0x52, 0x65, 0x71, 0x75, 0x65,\n-\t0x73, 0x74, 0x43, 0x6f, 0x6e, 0x74, 0x65, 0x78, 0x74, 0x52, 0x06, 0x72, 0x65, 0x71, 0x43, 0x74,\n-\t0x78, 0x22, 0x21, 0x0a, 0x1f, 0x42, 0x75, 0x6c, 0x6b, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65,\n-\t0x72, 0x53, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x48, 0x6f, 0x73, 0x74, 0x73, 0x52,\n-\t0x65, 0x70, 0x6c, 0x79, 0x32, 0x96, 0x02, 0x0a, 0x0c, 0x50, 0x68, 0x79, 0x73, 0x69, 0x63, 0x61,\n-\t0x6c, 0x48, 0x6f, 0x73, 0x74, 0x12, 0xa2, 0x01, 0x0a, 0x1a, 0x42, 0x75, 0x6c, 0x6b, 0x52, 0x65,\n+\t0x79, 0x18, 0x01, 0x20, 0x01, 0x28, 0x09, 0x52, 0x05, 0x72, 0x65, 0x70, 0x6c, 0x79, 0x22, 0xc7,\n+\t0x01, 0x0a, 0x1a, 0x53, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x52, 0x65, 0x67, 0x69,\n+\t0x73, 0x74, 0x65, 0x72, 0x48, 0x6f, 0x73, 0x74, 0x49, 0x6e, 0x70, 0x75, 0x74, 0x12, 0x23, 0x0a,\n+\t0x08, 0x68, 0x6f, 0x73, 0x74, 0x5f, 0x66, 0x69, 0x64, 0x18, 0x01, 0x20, 0x01, 0x28, 0x09, 0x42,\n+\t0x08, 0x92, 0xa2, 0xb9, 0xb8, 0x04, 0x02, 0x10, 0x01, 0x52, 0x07, 0x68, 0x6f, 0x73, 0x74, 0x46,\n+\t0x69, 0x64, 0x12, 0x3a, 0x0a, 0x14, 0x70, 0x72, 0x69, 0x6d, 0x61, 0x72, 0x79, 0x5f, 0x63, 0x6c,\n+\t0x75, 0x73, 0x74, 0x65, 0x72, 0x5f, 0x75, 0x75, 0x69, 0x64, 0x18, 0x02, 0x20, 0x01, 0x28, 0x09,\n+\t0x42, 0x08, 0x92, 0xa2, 0xb9, 0xb8, 0x04, 0x02, 0x10, 0x01, 0x52, 0x12, 0x70, 0x72, 0x69, 0x6d,\n+\t0x61, 0x72, 0x79, 0x43, 0x6c, 0x75, 0x73, 0x74, 0x65, 0x72, 0x55, 0x75, 0x69, 0x64, 0x12, 0x48,\n+\t0x0a, 0x07, 0x6f, 0x73, 0x5f, 0x74, 0x79, 0x70, 0x65, 0x18, 0x03, 0x20, 0x01, 0x28, 0x0e, 0x32,\n+\t0x2f, 0x2e, 0x63, 0x64, 0x6d, 0x72, 0x65, 0x73, 0x74, 0x73, 0x65, 0x72, 0x76, 0x69, 0x63, 0x65,\n+\t0x2e, 0x48, 0x6f, 0x73, 0x74, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x2e, 0x48, 0x6f,\n+\t0x73, 0x74, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x4f, 0x73, 0x54, 0x79, 0x70, 0x65,\n+\t0x52, 0x06, 0x6f, 0x73, 0x54, 0x79, 0x70, 0x65, 0x22, 0xdb, 0x01, 0x0a, 0x1d, 0x42, 0x75, 0x6c,\n+\t0x6b, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x53, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61,\n+\t0x72, 0x79, 0x48, 0x6f, 0x73, 0x74, 0x73, 0x52, 0x65, 0x71, 0x12, 0x30, 0x0a, 0x07, 0x72, 0x65,\n+\t0x71, 0x5f, 0x63, 0x74, 0x78, 0x18, 0x01, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x17, 0x2e, 0x63, 0x6f,\n+\t0x6e, 0x74, 0x65, 0x78, 0x74, 0x2e, 0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x43, 0x6f, 0x6e,\n+\t0x74, 0x65, 0x78, 0x74, 0x52, 0x06, 0x72, 0x65, 0x71, 0x43, 0x74, 0x78, 0x12, 0x3e, 0x0a, 0x16,\n+\t0x73, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x5f, 0x63, 0x6c, 0x75, 0x73, 0x74, 0x65,\n+\t0x72, 0x5f, 0x75, 0x75, 0x69, 0x64, 0x18, 0x02, 0x20, 0x01, 0x28, 0x09, 0x42, 0x08, 0x92, 0xa2,\n+\t0xb9, 0xb8, 0x04, 0x02, 0x10, 0x01, 0x52, 0x14, 0x73, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72,\n+\t0x79, 0x43, 0x6c, 0x75, 0x73, 0x74, 0x65, 0x72, 0x55, 0x75, 0x69, 0x64, 0x12, 0x48, 0x0a, 0x05,\n+\t0x68, 0x6f, 0x73, 0x74, 0x73, 0x18, 0x03, 0x20, 0x03, 0x28, 0x0b, 0x32, 0x28, 0x2e, 0x70, 0x68,\n+\t0x79, 0x73, 0x69, 0x63, 0x61, 0x6c, 0x68, 0x6f, 0x73, 0x74, 0x2e, 0x53, 0x65, 0x63, 0x6f, 0x6e,\n+\t0x64, 0x61, 0x72, 0x79, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x48, 0x6f, 0x73, 0x74,\n+\t0x49, 0x6e, 0x70, 0x75, 0x74, 0x42, 0x08, 0x92, 0xa2, 0xb9, 0xb8, 0x04, 0x02, 0x10, 0x01, 0x52,\n+\t0x05, 0x68, 0x6f, 0x73, 0x74, 0x73, 0x22, 0xad, 0x01, 0x0a, 0x1f, 0x48, 0x6f, 0x73, 0x74, 0x53,\n+\t0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x72, 0x61,\n+\t0x74, 0x69, 0x6f, 0x6e, 0x52, 0x65, 0x73, 0x75, 0x6c, 0x74, 0x12, 0x28, 0x0a, 0x10, 0x70, 0x72,\n+\t0x69, 0x6d, 0x61, 0x72, 0x79, 0x5f, 0x68, 0x6f, 0x73, 0x74, 0x5f, 0x66, 0x69, 0x64, 0x18, 0x01,\n+\t0x20, 0x01, 0x28, 0x09, 0x52, 0x0e, 0x70, 0x72, 0x69, 0x6d, 0x61, 0x72, 0x79, 0x48, 0x6f, 0x73,\n+\t0x74, 0x46, 0x69, 0x64, 0x12, 0x23, 0x0a, 0x0d, 0x65, 0x72, 0x72, 0x6f, 0x72, 0x5f, 0x6d, 0x65,\n+\t0x73, 0x73, 0x61, 0x67, 0x65, 0x18, 0x02, 0x20, 0x01, 0x28, 0x09, 0x52, 0x0c, 0x65, 0x72, 0x72,\n+\t0x6f, 0x72, 0x4d, 0x65, 0x73, 0x73, 0x61, 0x67, 0x65, 0x12, 0x3b, 0x0a, 0x0b, 0x68, 0x6f, 0x73,\n+\t0x74, 0x5f, 0x64, 0x65, 0x74, 0x61, 0x69, 0x6c, 0x18, 0x03, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x1a,\n+\t0x2e, 0x63, 0x64, 0x6d, 0x72, 0x65, 0x73, 0x74, 0x73, 0x65, 0x72, 0x76, 0x69, 0x63, 0x65, 0x2e,\n+\t0x48, 0x6f, 0x73, 0x74, 0x44, 0x65, 0x74, 0x61, 0x69, 0x6c, 0x52, 0x0a, 0x68, 0x6f, 0x73, 0x74,\n+\t0x44, 0x65, 0x74, 0x61, 0x69, 0x6c, 0x22, 0x73, 0x0a, 0x1f, 0x42, 0x75, 0x6c, 0x6b, 0x52, 0x65,\n \t0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x53, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x48,\n-\t0x6f, 0x73, 0x74, 0x73, 0x12, 0x2b, 0x2e, 0x70, 0x68, 0x79, 0x73, 0x69, 0x63, 0x61, 0x6c, 0x68,\n-\t0x6f, 0x73, 0x74, 0x2e, 0x42, 0x75, 0x6c, 0x6b, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72,\n-\t0x53, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x48, 0x6f, 0x73, 0x74, 0x73, 0x52, 0x65,\n-\t0x71, 0x1a, 0x2d, 0x2e, 0x70, 0x68, 0x79, 0x73, 0x69, 0x63, 0x61, 0x6c, 0x68, 0x6f, 0x73, 0x74,\n-\t0x2e, 0x42, 0x75, 0x6c, 0x6b, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x53, 0x65, 0x63,\n-\t0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x48, 0x6f, 0x73, 0x74, 0x73, 0x52, 0x65, 0x70, 0x6c, 0x79,\n-\t0x22, 0x28, 0xba, 0xce, 0x95, 0xf1, 0x06, 0x22, 0x08, 0x03, 0x12, 0x1a, 0x62, 0x75, 0x6c, 0x6b,\n-\t0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x53, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72,\n-\t0x79, 0x48, 0x6f, 0x73, 0x74, 0x73, 0x2a, 0x02, 0x08, 0x01, 0x12, 0x38, 0x0a, 0x04, 0x45, 0x63,\n-\t0x68, 0x6f, 0x12, 0x15, 0x2e, 0x70, 0x68, 0x79, 0x73, 0x69, 0x63, 0x61, 0x6c, 0x68, 0x6f, 0x73,\n-\t0x74, 0x2e, 0x45, 0x63, 0x68, 0x6f, 0x52, 0x65, 0x71, 0x1a, 0x17, 0x2e, 0x70, 0x68, 0x79, 0x73,\n-\t0x69, 0x63, 0x61, 0x6c, 0x68, 0x6f, 0x73, 0x74, 0x2e, 0x45, 0x63, 0x68, 0x6f, 0x52, 0x65, 0x70,\n-\t0x6c, 0x79, 0x22, 0x00, 0x1a, 0x27, 0xc2, 0xce, 0x95, 0xf1, 0x06, 0x21, 0x0a, 0x1f, 0x0a, 0x03,\n-\t0x52, 0x42, 0x53, 0x12, 0x0e, 0x49, 0x6e, 0x66, 0x69, 0x6e, 0x69, 0x74, 0x79, 0x20, 0x2d, 0x20,\n-\t0x52, 0x42, 0x53, 0x1a, 0x08, 0x23, 0x72, 0x62, 0x61, 0x2d, 0x64, 0x65, 0x76, 0x42, 0x20, 0xe2,\n-\t0x3f, 0x02, 0x68, 0x01, 0x5a, 0x19, 0x72, 0x75, 0x62, 0x72, 0x69, 0x6b, 0x2f, 0x70, 0x68, 0x79,\n-\t0x73, 0x69, 0x63, 0x61, 0x6c, 0x68, 0x6f, 0x73, 0x74, 0x2f, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x62,\n-\t0x06, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x33,\n+\t0x6f, 0x73, 0x74, 0x73, 0x52, 0x65, 0x70, 0x6c, 0x79, 0x12, 0x50, 0x0a, 0x0c, 0x68, 0x6f, 0x73,\n+\t0x74, 0x5f, 0x72, 0x65, 0x73, 0x75, 0x6c, 0x74, 0x73, 0x18, 0x01, 0x20, 0x03, 0x28, 0x0b, 0x32,\n+\t0x2d, 0x2e, 0x70, 0x68, 0x79, 0x73, 0x69, 0x63, 0x61, 0x6c, 0x68, 0x6f, 0x73, 0x74, 0x2e, 0x48,\n+\t0x6f, 0x73, 0x74, 0x53, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x52, 0x65, 0x67, 0x69,\n+\t0x73, 0x74, 0x72, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x52, 0x65, 0x73, 0x75, 0x6c, 0x74, 0x52, 0x0b,\n+\t0x68, 0x6f, 0x73, 0x74, 0x52, 0x65, 0x73, 0x75, 0x6c, 0x74, 0x73, 0x32, 0x92, 0x02, 0x0a, 0x0c,\n+\t0x50, 0x68, 0x79, 0x73, 0x69, 0x63, 0x61, 0x6c, 0x48, 0x6f, 0x73, 0x74, 0x12, 0x9e, 0x01, 0x0a,\n+\t0x1a, 0x42, 0x75, 0x6c, 0x6b, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x53, 0x65, 0x63,\n+\t0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x48, 0x6f, 0x73, 0x74, 0x73, 0x12, 0x2b, 0x2e, 0x70, 0x68,\n+\t0x79, 0x73, 0x69, 0x63, 0x61, 0x6c, 0x68, 0x6f, 0x73, 0x74, 0x2e, 0x42, 0x75, 0x6c, 0x6b, 0x52,\n+\t0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x53, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79,\n+\t0x48, 0x6f, 0x73, 0x74, 0x73, 0x52, 0x65, 0x71, 0x1a, 0x2d, 0x2e, 0x70, 0x68, 0x79, 0x73, 0x69,\n+\t0x63, 0x61, 0x6c, 0x68, 0x6f, 0x73, 0x74, 0x2e, 0x42, 0x75, 0x6c, 0x6b, 0x52, 0x65, 0x67, 0x69,\n+\t0x73, 0x74, 0x65, 0x72, 0x53, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x48, 0x6f, 0x73,\n+\t0x74, 0x73, 0x52, 0x65, 0x70, 0x6c, 0x79, 0x22, 0x24, 0xba, 0xce, 0x95, 0xf1, 0x06, 0x1e, 0x08,\n+\t0x03, 0x12, 0x1a, 0x62, 0x75, 0x6c, 0x6b, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x53,\n+\t0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x48, 0x6f, 0x73, 0x74, 0x73, 0x12, 0x38, 0x0a,\n+\t0x04, 0x45, 0x63, 0x68, 0x6f, 0x12, 0x15, 0x2e, 0x70, 0x68, 0x79, 0x73, 0x69, 0x63, 0x61, 0x6c,\n+\t0x68, 0x6f, 0x73, 0x74, 0x2e, 0x45, 0x63, 0x68, 0x6f, 0x52, 0x65, 0x71, 0x1a, 0x17, 0x2e, 0x70,\n+\t0x68, 0x79, 0x73, 0x69, 0x63, 0x61, 0x6c, 0x68, 0x6f, 0x73, 0x74, 0x2e, 0x45, 0x63, 0x68, 0x6f,\n+\t0x52, 0x65, 0x70, 0x6c, 0x79, 0x22, 0x00, 0x1a, 0x27, 0xc2, 0xce, 0x95, 0xf1, 0x06, 0x21, 0x0a,\n+\t0x1f, 0x0a, 0x03, 0x52, 0x42, 0x53, 0x12, 0x0e, 0x49, 0x6e, 0x66, 0x69, 0x6e, 0x69, 0x74, 0x79,\n+\t0x20, 0x2d, 0x20, 0x52, 0x42, 0x53, 0x1a, 0x08, 0x23, 0x72, 0x62, 0x61, 0x2d, 0x64, 0x65, 0x76,\n+\t0x42, 0x20, 0xe2, 0x3f, 0x02, 0x68, 0x01, 0x5a, 0x19, 0x72, 0x75, 0x62, 0x72, 0x69, 0x6b, 0x2f,\n+\t0x70, 0x68, 0x79, 0x73, 0x69, 0x63, 0x61, 0x6c, 0x68, 0x6f, 0x73, 0x74, 0x2f, 0x70, 0x72, 0x6f,\n+\t0x74, 0x6f, 0x62, 0x06, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x33,\n }\n \n var (\n@@ -275,25 +479,33 @@ func file_rubrik_physicalhost_proto_physicalhost_proto_rawDescGZIP() []byte {\n \treturn file_rubrik_physicalhost_proto_physicalhost_proto_rawDescData\n }\n \n-var file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes = make([]protoimpl.MessageInfo, 4)\n+var file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes = make([]protoimpl.MessageInfo, 6)\n var file_rubrik_physicalhost_proto_physicalhost_proto_goTypes = []interface{}{\n-\t(*EchoReq)(nil),                         // 0: physicalhost.EchoReq\n-\t(*EchoReply)(nil),                       // 1: physicalhost.EchoReply\n-\t(*BulkRegisterSecondaryHostsReq)(nil),   // 2: physicalhost.BulkRegisterSecondaryHostsReq\n-\t(*BulkRegisterSecondaryHostsReply)(nil), // 3: physicalhost.BulkRegisterSecondaryHostsReply\n-\t(*proto.RequestContext)(nil),            // 4: context.RequestContext\n+\t(*EchoReq)(nil),                            // 0: physicalhost.EchoReq\n+\t(*EchoReply)(nil),                          // 1: physicalhost.EchoReply\n+\t(*SecondaryRegisterHostInput)(nil),         // 2: physicalhost.SecondaryRegisterHostInput\n+\t(*BulkRegisterSecondaryHostsReq)(nil),      // 3: physicalhost.BulkRegisterSecondaryHostsReq\n+\t(*HostSecondaryRegistrationResult)(nil),    // 4: physicalhost.HostSecondaryRegistrationResult\n+\t(*BulkRegisterSecondaryHostsReply)(nil),    // 5: physicalhost.BulkRegisterSecondaryHostsReply\n+\t(types.HostRegister_HostRegisterOsType)(0), // 6: cdmrestservice.HostRegister.HostRegisterOsType\n+\t(*proto.RequestContext)(nil),               // 7: context.RequestContext\n+\t(*types.HostDetail)(nil),                   // 8: cdmrestservice.HostDetail\n }\n var file_rubrik_physicalhost_proto_physicalhost_proto_depIdxs = []int32{\n-\t4, // 0: physicalhost.BulkRegisterSecondaryHostsReq.req_ctx:type_name -> context.RequestContext\n-\t2, // 1: physicalhost.PhysicalHost.BulkRegisterSecondaryHosts:input_type -> physicalhost.BulkRegisterSecondaryHostsReq\n-\t0, // 2: physicalhost.PhysicalHost.Echo:input_type -> physicalhost.EchoReq\n-\t3, // 3: physicalhost.PhysicalHost.BulkRegisterSecondaryHosts:output_type -> physicalhost.BulkRegisterSecondaryHostsReply\n-\t1, // 4: physicalhost.PhysicalHost.Echo:output_type -> physicalhost.EchoReply\n-\t3, // [3:5] is the sub-list for method output_type\n-\t1, // [1:3] is the sub-list for method input_type\n-\t1, // [1:1] is the sub-list for extension type_name\n-\t1, // [1:1] is the sub-list for extension extendee\n-\t0, // [0:1] is the sub-list for field type_name\n+\t6, // 0: physicalhost.SecondaryRegisterHostInput.os_type:type_name -> cdmrestservice.HostRegister.HostRegisterOsType\n+\t7, // 1: physicalhost.BulkRegisterSecondaryHostsReq.req_ctx:type_name -> context.RequestContext\n+\t2, // 2: physicalhost.BulkRegisterSecondaryHostsReq.hosts:type_name -> physicalhost.SecondaryRegisterHostInput\n+\t8, // 3: physicalhost.HostSecondaryRegistrationResult.host_detail:type_name -> cdmrestservice.HostDetail\n+\t4, // 4: physicalhost.BulkRegisterSecondaryHostsReply.host_results:type_name -> physicalhost.HostSecondaryRegistrationResult\n+\t3, // 5: physicalhost.PhysicalHost.BulkRegisterSecondaryHosts:input_type -> physicalhost.BulkRegisterSecondaryHostsReq\n+\t0, // 6: physicalhost.PhysicalHost.Echo:input_type -> physicalhost.EchoReq\n+\t5, // 7: physicalhost.PhysicalHost.BulkRegisterSecondaryHosts:output_type -> physicalhost.BulkRegisterSecondaryHostsReply\n+\t1, // 8: physicalhost.PhysicalHost.Echo:output_type -> physicalhost.EchoReply\n+\t7, // [7:9] is the sub-list for method output_type\n+\t5, // [5:7] is the sub-list for method input_type\n+\t5, // [5:5] is the sub-list for extension type_name\n+\t5, // [5:5] is the sub-list for extension extendee\n+\t0, // [0:5] is the sub-list for field type_name\n }\n \n func init() { file_rubrik_physicalhost_proto_physicalhost_proto_init() }\n@@ -327,7 +539,7 @@ func file_rubrik_physicalhost_proto_physicalhost_proto_init() {\n \t\t\t}\n \t\t}\n \t\tfile_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[2].Exporter = func(v interface{}, i int) interface{} {\n-\t\t\tswitch v := v.(*BulkRegisterSecondaryHostsReq); i {\n+\t\t\tswitch v := v.(*SecondaryRegisterHostInput); i {\n \t\t\tcase 0:\n \t\t\t\treturn &v.state\n \t\t\tcase 1:\n@@ -339,6 +551,30 @@ func file_rubrik_physicalhost_proto_physicalhost_proto_init() {\n \t\t\t}\n \t\t}\n \t\tfile_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[3].Exporter = func(v interface{}, i int) interface{} {\n+\t\t\tswitch v := v.(*BulkRegisterSecondaryHostsReq); i {\n+\t\t\tcase 0:\n+\t\t\t\treturn &v.state\n+\t\t\tcase 1:\n+\t\t\t\treturn &v.sizeCache\n+\t\t\tcase 2:\n+\t\t\t\treturn &v.unknownFields\n+\t\t\tdefault:\n+\t\t\t\treturn nil\n+\t\t\t}\n+\t\t}\n+\t\tfile_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[4].Exporter = func(v interface{}, i int) interface{} {\n+\t\t\tswitch v := v.(*HostSecondaryRegistrationResult); i {\n+\t\t\tcase 0:\n+\t\t\t\treturn &v.state\n+\t\t\tcase 1:\n+\t\t\t\treturn &v.sizeCache\n+\t\t\tcase 2:\n+\t\t\t\treturn &v.unknownFields\n+\t\t\tdefault:\n+\t\t\t\treturn nil\n+\t\t\t}\n+\t\t}\n+\t\tfile_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[5].Exporter = func(v interface{}, i int) interface{} {\n \t\t\tswitch v := v.(*BulkRegisterSecondaryHostsReply); i {\n \t\t\tcase 0:\n \t\t\t\treturn &v.state\n@@ -357,7 +593,7 @@ func file_rubrik_physicalhost_proto_physicalhost_proto_init() {\n \t\t\tGoPackagePath: reflect.TypeOf(x{}).PkgPath(),\n \t\t\tRawDescriptor: file_rubrik_physicalhost_proto_physicalhost_proto_rawDesc,\n \t\t\tNumEnums:      0,\n-\t\t\tNumMessages:   4,\n+\t\t\tNumMessages:   6,\n \t\t\tNumExtensions: 0,\n \t\t\tNumServices:   1,\n \t\t},\n@@ -384,6 +620,7 @@ const _ = grpc.SupportPackageIsVersion6\n // For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.\n type PhysicalHostClient interface {\n \t// BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n+\t// @param input The request containing secondary cluster UUID and hosts to register.\n \tBulkRegisterSecondaryHosts(ctx context.Context, in *BulkRegisterSecondaryHostsReq, opts ...grpc.CallOption) (*BulkRegisterSecondaryHostsReply, error)\n \t// Echo performs a simple echo operation for testing connectivity and service health.\n \t// This is primarily used for service validation and debugging purposes.\n@@ -419,6 +656,7 @@ func (c *physicalHostClient) Echo(ctx context.Context, in *EchoReq, opts ...grpc\n // PhysicalHostServer is the server API for PhysicalHost service.\n type PhysicalHostServer interface {\n \t// BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n+\t// @param input The request containing secondary cluster UUID and hosts to register.\n \tBulkRegisterSecondaryHosts(context.Context, *BulkRegisterSecondaryHostsReq) (*BulkRegisterSecondaryHostsReply, error)\n \t// Echo performs a simple echo operation for testing connectivity and service health.\n \t// This is primarily used for service validation and debugging purposes."
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/proto/physicalhost.proto",
          "status": "modified",
          "additions": 34,
          "deletions": 5,
          "patch": "@@ -6,6 +6,7 @@ option go_package = \"rubrik/physicalhost/proto\";\n import \"rubrik/common-go/api/context/proto/context.proto\";\n import \"rubrik/api-server/app/v2/proto/api.proto\";\n import \"rubrik/scalapb/proto/scalapb.proto\";\n+import \"rubrik/cdm-rest-service/proto/types/cdmrestservice_types.proto\";\n \n option (scalapb.options) = {\n   retain_source_code_info: true\n@@ -23,16 +24,12 @@ service PhysicalHost {\n     }\n   };\n \n-  // TODO(SPARK-572184): Implement BulkRegisterSecondaryHosts\n-\n   // BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n+  // @param input The request containing secondary cluster UUID and hosts to register.\n   rpc BulkRegisterSecondaryHosts (BulkRegisterSecondaryHostsReq) returns (BulkRegisterSecondaryHostsReply) {\n     option (api.graphql_method) = {\n       type: MUTATION\n       name: \"bulkRegisterSecondaryHosts\"\n-      tags: [\n-        { type: HIDDEN }\n-      ]\n     };\n   }\n \n@@ -53,11 +50,43 @@ message EchoReply {\n   string reply = 1;\n }\n \n+// Host details for secondary registration.\n+message SecondaryRegisterHostInput {\n+  // The host FID (unique identifier).\n+  string host_fid = 1 [(api.graphql_field).requiredness = REQUIRED];\n+\n+  // UUID of the primary cluster where the host currently resides.\n+  string primary_cluster_uuid = 2 [(api.graphql_field).requiredness = REQUIRED];\n+\n+  // Operating system type of the host.\n+  cdmrestservice.HostRegister.HostRegisterOsType os_type = 3;\n+}\n+\n // Request message for bulk registration of secondary hosts.\n message BulkRegisterSecondaryHostsReq {\n   context.RequestContext req_ctx = 1;\n+\n+  // UUID of the secondary cluster where hosts will be registered.\n+  string secondary_cluster_uuid = 2 [(api.graphql_field).requiredness = REQUIRED];\n+\n+  // List of hosts to register as secondary hosts.\n+  repeated SecondaryRegisterHostInput hosts = 3 [(api.graphql_field).requiredness = REQUIRED];\n+}\n+\n+// Result for a single host registration.\n+message HostSecondaryRegistrationResult {\n+  // The host FID that was processed.\n+  string primary_host_fid = 1;\n+\n+  // Error message if registration failed.\n+  string error_message = 2;\n+\n+  // Host details of secondary registration if registration was successful.\n+  cdmrestservice.HostDetail host_detail = 3;\n }\n \n // Response message for bulk registration of secondary hosts.\n message BulkRegisterSecondaryHostsReply {\n+  // Results for each host that was processed.\n+  repeated HostSecondaryRegistrationResult host_results = 1;\n }"
        },
        {
          "filename": "polaris/src/rubrik/sdk_internal/grpc/physicalhost_pb2.py",
          "status": "modified",
          "additions": 151,
          "deletions": 13,
          "patch": "@@ -14,6 +14,7 @@\n import rubrik.sdk_internal.grpc.context_pb2 as rubrik_dot_common__go_dot_api_dot_context_dot_proto_dot_context__pb2\n import rubrik.sdk_internal.grpc.api_pb2 as rubrik_dot_api__server_dot_app_dot_v2_dot_proto_dot_api__pb2\n import rubrik.sdk_internal.grpc.scalapb_pb2 as rubrik_dot_scalapb_dot_proto_dot_scalapb__pb2\n+import rubrik.sdk_internal.grpc.cdmrestservice_types_pb2 as rubrik_dot_cdm__rest__service_dot_proto_dot_types_dot_cdmrestservice__types__pb2\n \n \n PROTO_SRC = \"src/rubrik/physicalhost/proto/physicalhost.proto\"\n@@ -23,9 +24,9 @@\n   syntax='proto3',\n   serialized_options=b'Z\\031rubrik/physicalhost/proto\\342?\\002h\\001',\n   create_key=_descriptor._internal_create_key,\n-  serialized_pb=b'\\n\\x12physicalhost.proto\\x12\\x0cphysicalhost\\x1a\\x30rubrik/common-go/api/context/proto/context.proto\\x1a(rubrik/api-server/app/v2/proto/api.proto\\x1a\\\"rubrik/scalapb/proto/scalapb.proto\\\"\\x17\\n\\x07\\x45\\x63hoReq\\x12\\x0c\\n\\x04\\x61rg1\\x18\\x01 \\x01(\\t\\\"\\x1a\\n\\tEchoReply\\x12\\r\\n\\x05reply\\x18\\x01 \\x01(\\t\\\"I\\n\\x1d\\x42ulkRegisterSecondaryHostsReq\\x12(\\n\\x07req_ctx\\x18\\x01 \\x01(\\x0b\\x32\\x17.context.RequestContext\\\"!\\n\\x1f\\x42ulkRegisterSecondaryHostsReply2\\x96\\x02\\n\\x0cPhysicalHost\\x12\\xa2\\x01\\n\\x1a\\x42ulkRegisterSecondaryHosts\\x12+.physicalhost.BulkRegisterSecondaryHostsReq\\x1a-.physicalhost.BulkRegisterSecondaryHostsReply\\\"(\\xba\\xce\\x95\\xf1\\x06\\\"\\x08\\x03\\x12\\x1a\\x62ulkRegisterSecondaryHosts*\\x02\\x08\\x01\\x12\\x38\\n\\x04\\x45\\x63ho\\x12\\x15.physicalhost.EchoReq\\x1a\\x17.physicalhost.EchoReply\\\"\\x00\\x1a\\'\\xc2\\xce\\x95\\xf1\\x06!\\n\\x1f\\n\\x03RBS\\x12\\x0eInfinity - RBS\\x1a\\x08#rba-devB Z\\x19rubrik/physicalhost/proto\\xe2?\\x02h\\x01\\x62\\x06proto3'\n+  serialized_pb=b'\\n\\x12physicalhost.proto\\x12\\x0cphysicalhost\\x1a\\x30rubrik/common-go/api/context/proto/context.proto\\x1a(rubrik/api-server/app/v2/proto/api.proto\\x1a\\\"rubrik/scalapb/proto/scalapb.proto\\x1a>rubrik/cdm-rest-service/proto/types/cdmrestservice_types.proto\\\"\\x17\\n\\x07\\x45\\x63hoReq\\x12\\x0c\\n\\x04\\x61rg1\\x18\\x01 \\x01(\\t\\\"\\x1a\\n\\tEchoReply\\x12\\r\\n\\x05reply\\x18\\x01 \\x01(\\t\\\"\\xa2\\x01\\n\\x1aSecondaryRegisterHostInput\\x12\\x1a\\n\\x08host_fid\\x18\\x01 \\x01(\\tB\\x08\\x92\\xa2\\xb9\\xb8\\x04\\x02\\x10\\x01\\x12&\\n\\x14primary_cluster_uuid\\x18\\x02 \\x01(\\tB\\x08\\x92\\xa2\\xb9\\xb8\\x04\\x02\\x10\\x01\\x12@\\n\\x07os_type\\x18\\x03 \\x01(\\x0e\\x32/.cdmrestservice.HostRegister.HostRegisterOsType\\\"\\xb6\\x01\\n\\x1d\\x42ulkRegisterSecondaryHostsReq\\x12(\\n\\x07req_ctx\\x18\\x01 \\x01(\\x0b\\x32\\x17.context.RequestContext\\x12(\\n\\x16secondary_cluster_uuid\\x18\\x02 \\x01(\\tB\\x08\\x92\\xa2\\xb9\\xb8\\x04\\x02\\x10\\x01\\x12\\x41\\n\\x05hosts\\x18\\x03 \\x03(\\x0b\\x32(.physicalhost.SecondaryRegisterHostInputB\\x08\\x92\\xa2\\xb9\\xb8\\x04\\x02\\x10\\x01\\\"\\x83\\x01\\n\\x1fHostSecondaryRegistrationResult\\x12\\x18\\n\\x10primary_host_fid\\x18\\x01 \\x01(\\t\\x12\\x15\\n\\rerror_message\\x18\\x02 \\x01(\\t\\x12/\\n\\x0bhost_detail\\x18\\x03 \\x01(\\x0b\\x32\\x1a.cdmrestservice.HostDetail\\\"f\\n\\x1f\\x42ulkRegisterSecondaryHostsReply\\x12\\x43\\n\\x0chost_results\\x18\\x01 \\x03(\\x0b\\x32-.physicalhost.HostSecondaryRegistrationResult2\\x92\\x02\\n\\x0cPhysicalHost\\x12\\x9e\\x01\\n\\x1a\\x42ulkRegisterSecondaryHosts\\x12+.physicalhost.BulkRegisterSecondaryHostsReq\\x1a-.physicalhost.BulkRegisterSecondaryHostsReply\\\"$\\xba\\xce\\x95\\xf1\\x06\\x1e\\x08\\x03\\x12\\x1a\\x62ulkRegisterSecondaryHosts\\x12\\x38\\n\\x04\\x45\\x63ho\\x12\\x15.physicalhost.EchoReq\\x1a\\x17.physicalhost.EchoReply\\\"\\x00\\x1a\\'\\xc2\\xce\\x95\\xf1\\x06!\\n\\x1f\\n\\x03RBS\\x12\\x0eInfinity - RBS\\x1a\\x08#rba-devB Z\\x19rubrik/physicalhost/proto\\xe2?\\x02h\\x01\\x62\\x06proto3'\n   ,\n-  dependencies=[rubrik_dot_common__go_dot_api_dot_context_dot_proto_dot_context__pb2.DESCRIPTOR,rubrik_dot_api__server_dot_app_dot_v2_dot_proto_dot_api__pb2.DESCRIPTOR,rubrik_dot_scalapb_dot_proto_dot_scalapb__pb2.DESCRIPTOR,])\n+  dependencies=[rubrik_dot_common__go_dot_api_dot_context_dot_proto_dot_context__pb2.DESCRIPTOR,rubrik_dot_api__server_dot_app_dot_v2_dot_proto_dot_api__pb2.DESCRIPTOR,rubrik_dot_scalapb_dot_proto_dot_scalapb__pb2.DESCRIPTOR,rubrik_dot_cdm__rest__service_dot_proto_dot_types_dot_cdmrestservice__types__pb2.DESCRIPTOR,])\n \n \n \n@@ -57,8 +58,8 @@\n   extension_ranges=[],\n   oneofs=[\n   ],\n-  serialized_start=164,\n-  serialized_end=187,\n+  serialized_start=228,\n+  serialized_end=251,\n )\n \n \n@@ -89,8 +90,54 @@\n   extension_ranges=[],\n   oneofs=[\n   ],\n-  serialized_start=189,\n-  serialized_end=215,\n+  serialized_start=253,\n+  serialized_end=279,\n+)\n+\n+\n+_SECONDARYREGISTERHOSTINPUT = _descriptor.Descriptor(\n+  name='SecondaryRegisterHostInput',\n+  full_name='physicalhost.SecondaryRegisterHostInput',\n+  filename=None,\n+  file=DESCRIPTOR,\n+  containing_type=None,\n+  create_key=_descriptor._internal_create_key,\n+  fields=[\n+    _descriptor.FieldDescriptor(\n+      name='host_fid', full_name='physicalhost.SecondaryRegisterHostInput.host_fid', index=0,\n+      number=1, type=9, cpp_type=9, label=1,\n+      has_default_value=False, default_value=b\"\".decode('utf-8'),\n+      message_type=None, enum_type=None, containing_type=None,\n+      is_extension=False, extension_scope=None,\n+      serialized_options=b'\\222\\242\\271\\270\\004\\002\\020\\001', file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n+    _descriptor.FieldDescriptor(\n+      name='primary_cluster_uuid', full_name='physicalhost.SecondaryRegisterHostInput.primary_cluster_uuid', index=1,\n+      number=2, type=9, cpp_type=9, label=1,\n+      has_default_value=False, default_value=b\"\".decode('utf-8'),\n+      message_type=None, enum_type=None, containing_type=None,\n+      is_extension=False, extension_scope=None,\n+      serialized_options=b'\\222\\242\\271\\270\\004\\002\\020\\001', file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n+    _descriptor.FieldDescriptor(\n+      name='os_type', full_name='physicalhost.SecondaryRegisterHostInput.os_type', index=2,\n+      number=3, type=14, cpp_type=8, label=1,\n+      has_default_value=False, default_value=0,\n+      message_type=None, enum_type=None, containing_type=None,\n+      is_extension=False, extension_scope=None,\n+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n+  ],\n+  extensions=[\n+  ],\n+  nested_types=[],\n+  enum_types=[\n+  ],\n+  serialized_options=None,\n+  is_extendable=False,\n+  syntax='proto3',\n+  extension_ranges=[],\n+  oneofs=[\n+  ],\n+  serialized_start=282,\n+  serialized_end=444,\n )\n \n \n@@ -109,6 +156,66 @@\n       message_type=None, enum_type=None, containing_type=None,\n       is_extension=False, extension_scope=None,\n       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n+    _descriptor.FieldDescriptor(\n+      name='secondary_cluster_uuid', full_name='physicalhost.BulkRegisterSecondaryHostsReq.secondary_cluster_uuid', index=1,\n+      number=2, type=9, cpp_type=9, label=1,\n+      has_default_value=False, default_value=b\"\".decode('utf-8'),\n+      message_type=None, enum_type=None, containing_type=None,\n+      is_extension=False, extension_scope=None,\n+      serialized_options=b'\\222\\242\\271\\270\\004\\002\\020\\001', file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n+    _descriptor.FieldDescriptor(\n+      name='hosts', full_name='physicalhost.BulkRegisterSecondaryHostsReq.hosts', index=2,\n+      number=3, type=11, cpp_type=10, label=3,\n+      has_default_value=False, default_value=[],\n+      message_type=None, enum_type=None, containing_type=None,\n+      is_extension=False, extension_scope=None,\n+      serialized_options=b'\\222\\242\\271\\270\\004\\002\\020\\001', file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n+  ],\n+  extensions=[\n+  ],\n+  nested_types=[],\n+  enum_types=[\n+  ],\n+  serialized_options=None,\n+  is_extendable=False,\n+  syntax='proto3',\n+  extension_ranges=[],\n+  oneofs=[\n+  ],\n+  serialized_start=447,\n+  serialized_end=629,\n+)\n+\n+\n+_HOSTSECONDARYREGISTRATIONRESULT = _descriptor.Descriptor(\n+  name='HostSecondaryRegistrationResult',\n+  full_name='physicalhost.HostSecondaryRegistrationResult',\n+  filename=None,\n+  file=DESCRIPTOR,\n+  containing_type=None,\n+  create_key=_descriptor._internal_create_key,\n+  fields=[\n+    _descriptor.FieldDescriptor(\n+      name='primary_host_fid', full_name='physicalhost.HostSecondaryRegistrationResult.primary_host_fid', index=0,\n+      number=1, type=9, cpp_type=9, label=1,\n+      has_default_value=False, default_value=b\"\".decode('utf-8'),\n+      message_type=None, enum_type=None, containing_type=None,\n+      is_extension=False, extension_scope=None,\n+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n+    _descriptor.FieldDescriptor(\n+      name='error_message', full_name='physicalhost.HostSecondaryRegistrationResult.error_message', index=1,\n+      number=2, type=9, cpp_type=9, label=1,\n+      has_default_value=False, default_value=b\"\".decode('utf-8'),\n+      message_type=None, enum_type=None, containing_type=None,\n+      is_extension=False, extension_scope=None,\n+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n+    _descriptor.FieldDescriptor(\n+      name='host_detail', full_name='physicalhost.HostSecondaryRegistrationResult.host_detail', index=2,\n+      number=3, type=11, cpp_type=10, label=1,\n+      has_default_value=False, default_value=None,\n+      message_type=None, enum_type=None, containing_type=None,\n+      is_extension=False, extension_scope=None,\n+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n   ],\n   extensions=[\n   ],\n@@ -121,8 +228,8 @@\n   extension_ranges=[],\n   oneofs=[\n   ],\n-  serialized_start=217,\n-  serialized_end=290,\n+  serialized_start=632,\n+  serialized_end=763,\n )\n \n \n@@ -134,6 +241,13 @@\n   containing_type=None,\n   create_key=_descriptor._internal_create_key,\n   fields=[\n+    _descriptor.FieldDescriptor(\n+      name='host_results', full_name='physicalhost.BulkRegisterSecondaryHostsReply.host_results', index=0,\n+      number=1, type=11, cpp_type=10, label=3,\n+      has_default_value=False, default_value=[],\n+      message_type=None, enum_type=None, containing_type=None,\n+      is_extension=False, extension_scope=None,\n+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n   ],\n   extensions=[\n   ],\n@@ -146,14 +260,20 @@\n   extension_ranges=[],\n   oneofs=[\n   ],\n-  serialized_start=292,\n-  serialized_end=325,\n+  serialized_start=765,\n+  serialized_end=867,\n )\n \n+_SECONDARYREGISTERHOSTINPUT.fields_by_name['os_type'].enum_type = rubrik_dot_cdm__rest__service_dot_proto_dot_types_dot_cdmrestservice__types__pb2._HOSTREGISTER_HOSTREGISTEROSTYPE\n _BULKREGISTERSECONDARYHOSTSREQ.fields_by_name['req_ctx'].message_type = rubrik_dot_common__go_dot_api_dot_context_dot_proto_dot_context__pb2._REQUESTCONTEXT\n+_BULKREGISTERSECONDARYHOSTSREQ.fields_by_name['hosts'].message_type = _SECONDARYREGISTERHOSTINPUT\n+_HOSTSECONDARYREGISTRATIONRESULT.fields_by_name['host_detail'].message_type = rubrik_dot_cdm__rest__service_dot_proto_dot_types_dot_cdmrestservice__types__pb2._HOSTDETAIL\n+_BULKREGISTERSECONDARYHOSTSREPLY.fields_by_name['host_results'].message_type = _HOSTSECONDARYREGISTRATIONRESULT\n DESCRIPTOR.message_types_by_name['EchoReq'] = _ECHOREQ\n DESCRIPTOR.message_types_by_name['EchoReply'] = _ECHOREPLY\n+DESCRIPTOR.message_types_by_name['SecondaryRegisterHostInput'] = _SECONDARYREGISTERHOSTINPUT\n DESCRIPTOR.message_types_by_name['BulkRegisterSecondaryHostsReq'] = _BULKREGISTERSECONDARYHOSTSREQ\n+DESCRIPTOR.message_types_by_name['HostSecondaryRegistrationResult'] = _HOSTSECONDARYREGISTRATIONRESULT\n DESCRIPTOR.message_types_by_name['BulkRegisterSecondaryHostsReply'] = _BULKREGISTERSECONDARYHOSTSREPLY\n _sym_db.RegisterFileDescriptor(DESCRIPTOR)\n \n@@ -171,13 +291,27 @@\n   })\n _sym_db.RegisterMessage(EchoReply)\n \n+SecondaryRegisterHostInput = _reflection.GeneratedProtocolMessageType('SecondaryRegisterHostInput', (_message.Message,), {\n+  'DESCRIPTOR' : _SECONDARYREGISTERHOSTINPUT,\n+  '__module__' : 'physicalhost_pb2'\n+  # @@protoc_insertion_point(class_scope:physicalhost.SecondaryRegisterHostInput)\n+  })\n+_sym_db.RegisterMessage(SecondaryRegisterHostInput)\n+\n BulkRegisterSecondaryHostsReq = _reflection.GeneratedProtocolMessageType('BulkRegisterSecondaryHostsReq', (_message.Message,), {\n   'DESCRIPTOR' : _BULKREGISTERSECONDARYHOSTSREQ,\n   '__module__' : 'physicalhost_pb2'\n   # @@protoc_insertion_point(class_scope:physicalhost.BulkRegisterSecondaryHostsReq)\n   })\n _sym_db.RegisterMessage(BulkRegisterSecondaryHostsReq)\n \n+HostSecondaryRegistrationResult = _reflection.GeneratedProtocolMessageType('HostSecondaryRegistrationResult', (_message.Message,), {\n+  'DESCRIPTOR' : _HOSTSECONDARYREGISTRATIONRESULT,\n+  '__module__' : 'physicalhost_pb2'\n+  # @@protoc_insertion_point(class_scope:physicalhost.HostSecondaryRegistrationResult)\n+  })\n+_sym_db.RegisterMessage(HostSecondaryRegistrationResult)\n+\n BulkRegisterSecondaryHostsReply = _reflection.GeneratedProtocolMessageType('BulkRegisterSecondaryHostsReply', (_message.Message,), {\n   'DESCRIPTOR' : _BULKREGISTERSECONDARYHOSTSREPLY,\n   '__module__' : 'physicalhost_pb2'\n@@ -187,6 +321,10 @@\n \n \n DESCRIPTOR._options = None\n+_SECONDARYREGISTERHOSTINPUT.fields_by_name['host_fid']._options = None\n+_SECONDARYREGISTERHOSTINPUT.fields_by_name['primary_cluster_uuid']._options = None\n+_BULKREGISTERSECONDARYHOSTSREQ.fields_by_name['secondary_cluster_uuid']._options = None\n+_BULKREGISTERSECONDARYHOSTSREQ.fields_by_name['hosts']._options = None\n \n _PHYSICALHOST = _descriptor.ServiceDescriptor(\n   name='PhysicalHost',\n@@ -195,8 +333,8 @@\n   index=0,\n   serialized_options=b'\\302\\316\\225\\361\\006!\\n\\037\\n\\003RBS\\022\\016Infinity - RBS\\032\\010#rba-dev',\n   create_key=_descriptor._internal_create_key,\n-  serialized_start=328,\n-  serialized_end=606,\n+  serialized_start=870,\n+  serialized_end=1144,\n   methods=[\n   _descriptor.MethodDescriptor(\n     name='BulkRegisterSecondaryHosts',\n@@ -205,7 +343,7 @@\n     containing_service=None,\n     input_type=_BULKREGISTERSECONDARYHOSTSREQ,\n     output_type=_BULKREGISTERSECONDARYHOSTSREPLY,\n-    serialized_options=b'\\272\\316\\225\\361\\006\\\"\\010\\003\\022\\032bulkRegisterSecondaryHosts*\\002\\010\\001',\n+    serialized_options=b'\\272\\316\\225\\361\\006\\036\\010\\003\\022\\032bulkRegisterSecondaryHosts',\n     create_key=_descriptor._internal_create_key,\n   ),\n   _descriptor.MethodDescriptor("
        },
        {
          "filename": "polaris/src/rubrik/sdk_internal/grpc/physicalhost_pb2_grpc.py",
          "status": "modified",
          "additions": 2,
          "deletions": 3,
          "patch": "@@ -36,9 +36,8 @@ class PhysicalHostServicer(object):\n     \"\"\"\n \n     def BulkRegisterSecondaryHosts(self, request, context):\n-        \"\"\"TODO(SPARK-572184): Implement BulkRegisterSecondaryHosts\n-\n-        BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n+        \"\"\"BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n+        @param input The request containing secondary cluster UUID and hosts to register.\n         \"\"\"\n         context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n         context.set_details('Method not implemented!')"
        },
        {
          "filename": "polaris/yodalibs/generated/gql_inputs.py",
          "status": "modified",
          "additions": 13,
          "deletions": 0,
          "patch": "@@ -2838,6 +2838,12 @@ class BulkRegisterHostInput:\n     clusterUuid: str\n     hosts: List['HostRegisterInput']\n \n+@dataclass_json\n+@dataclass\n+class BulkRegisterSecondaryHostsInput:\n+    hosts: List['SecondaryRegisterHostInput']\n+    secondaryClusterUuid: str\n+\n @dataclass_json\n @dataclass\n class BulkRestoreM365BackupStorageObjectsInput:\n@@ -15808,6 +15814,13 @@ class SearchVectorDBInput:\n     query: str\n     topK: Optional[int] = None\n \n+@dataclass_json\n+@dataclass\n+class SecondaryRegisterHostInput:\n+    hostFid: str\n+    primaryClusterUuid: str\n+    osType: Optional['HostRegisterOsType'] = None\n+\n @dataclass_json\n @dataclass\n class SecureAuthAzureKeyVaultDetails:"
        }
      ],
      "statistics": {
        "commits": 6,
        "files_changed": 14,
        "additions": 1114,
        "deletions": 80,
        "total_comments": 45
      }
    },
    "processed_data": {
      "source": "github",
      "link": "https://github.com/scaledata/sdmain/pull/97449",
      "timestamp": "2025-09-02 06:40:19",
      "title": "PR #97449: Add RBAC test for the bulk secondary register host",
      "long_summary": "Modified 10 files. (+212/-10 lines). - tests\n\nKey changes:\n\u2022 polaris/src/rubrik/api-server/app/services/physicalhost/rbac/BUILD.bazel: Added dependencies on proto_deps and common-scala to the rkscala_library build target\n\u2022 polaris/src/rubrik/sdk_internal/grpc/physicalhost_pb2_grpc.py: Modified BulkRegisterSecondaryHosts docstring to remove TODO and add parameter description\n\u2022 polaris/src/rubrik/api-server/test/app/services/physicalhost/rbac/BUILD.bazel: Added Bazel build rule to define Scala test target for physicalhost RBAC service\n\nAuthor: moht-agrawal-rubrik, State: open, Reviewers: 3",
      "action_items": [
        "Clarify which output is being referenced in Comment 2 regarding the proto schema and comments.",
        "Confirm if the string_to_uuid transform should be applied in the schema and update the implementation if necessary.",
        "Address the question in Comment 4 about the necessity of calling the fetcher for the RBAC check.",
        "Remove explicit passing of \"UNSPECIFIED\" for HostRegisterOsType if it is not required, as noted in Comment 5.",
        "Consider providing benchmarking data or further justification for the current implementation's performance, as discussed in Comment 6."
      ],
      "score": 0.4524559321047854
    }
  },
  {
    "source": "github",
    "candidate_id": "github_pr_97821",
    "raw_data": {
      "pr_title": "Send audits for failed secondary host registration",
      "pr_summary": "## Summary:\n- Added new audit for failed secondary host registration.\r\n- Added an audit sender to the physicalhost service.\r\n- Sending audits for failed secondary host registration.\r\n\r\nRef: https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/442826876/Sending+Polaris+Event+Audit\n\n## Test Plan:\nManual testing and UTs\r\n\r\n### Manual testing plan:\r\n\r\n<img width=\"1407\" height=\"358\" alt=\"image\" src=\"https://github.com/user-attachments/assets/10ee8da2-a30c-43d9-95ca-7d7b97f6d515\" />\n\n## JIRA Issues:\nSPARK-572184\n\n## Revert Plan:\n## PR Stack:\nStack from arc wrapper with help from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):\n* __->__ #97821\n* #97551\n* #97450\n* #97449\n",
      "pr_url": "https://github.com/scaledata/sdmain/pull/97821",
      "metadata": {
        "number": 97821,
        "state": "open",
        "author": "moht-agrawal-rubrik",
        "created_at": "2025-09-03T06:09:01Z",
        "updated_at": "2025-09-09T18:40:07Z",
        "merged_at": null,
        "base_branch": "gh/moht-agrawal-rubrik/17/head",
        "head_branch": "gh/moht-agrawal-rubrik/18/head",
        "labels": [],
        "assignees": [
          "jordanbarkley",
          "Nagavenimythri",
          "Arqum212",
          "sreshth-dev"
        ],
        "reviewers": [
          "Nagavenimythri",
          "Arqum212"
        ]
      },
      "comments": {
        "global_comments": [
          {
            "type": "discussion",
            "author": "rogers-sail-information[bot]",
            "created_at": "2025-09-03T06:09:33Z",
            "body": "<!-- rogers sail info comment -->\n## Sail Request\n\n> Rogers will automatically update this comment to reflect the current sail status of your PR when you begin a sail request.",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#issuecomment-3247811330"
          },
          {
            "type": "discussion",
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-04T07:47:16Z",
            "body": "_:hourglass: Your RR [scaledata/sdmain/97821](https://github.com/scaledata/sdmain/pull/97821) has not been reviewed within the SLO. Resigning the following blocking reviewers:_\n * @scaledata/rba-shadow\n * @scaledata/rba-rba-reviews",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#issuecomment-3252358761"
          },
          {
            "type": "discussion",
            "author": "rubrik-alfred[bot]",
            "created_at": "2025-09-09T18:40:07Z",
            "body": "## :man_in_tuxedo: Alfred Comments\n<input type='hidden' commit='61598da389fa54cfafb0039eb098df35b95fe4fa' global='true'/>\n<!--Header_Done-->\n\nThese changes might require a full GCP upgrade to validate. Refer to [this](https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2672918625/Platform+Infra+Reviews) for more context \nRun `arc sail --additional_tests canary-pipeline`if some of the following is True:\n* Some change other than memory, CPU, replicas etc\n* The changed service is a third-party service\n* The changed service was not deployed on GCP. (If done, include in test plan).Requires review from #platform_polaris-platform-infra-reviews.\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/sdk_internal/services/gps/datacenter/physicalhost_service.py</code></li>\n</ul>\n</details>\n\n\n------\n\nTouching Polaris deployment scripts requires review from #platform_polaris-platform-infra-reviews.\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/sdk_internal/services/gps/datacenter/physicalhost_service.py</code></li>\n</ul>\n</details>\n\n\n------\n\nMake sure you check these lines.\n\n<details><summary>Click here to view the Inline Comments</summary><ul><li><a href=\"https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455741\">https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455741</a></li></ul></details>\n\n------\n\nPlease follow [Sending Polaris Event/Audit](https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/442826876/Sending+Polaris+Event+Audit) if adding a new event/audit. Changes to user visible audits, events and notifications should be reviewed by #rsc_documentation_rsc_doc_diff_reviews. \n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/common-go/audits/templates/cdm-host.yml</code></li>\n</ul>\n</details>\n\n\n------\n\n Looks like you are modifying Polaris Events related code. This needs review by #polaris_events_watchers-events-reviews.     \n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/common-go/audits/templates/cdm-host.yml</code></li>\n</ul>\n</details>\n\n\n------\n\nTriggering the detect-changed-services pipeline. If your PR is raised against a Polaris release branch, this pipeline will leave a comment with a list of the services that will be affected by the changes in your PR.\n\n\nThe following jobs are triggered:\n\n\n- [detect-changed-services](https://polaris-builds.stark.rubrik.com/job/detect-changed-services)\n\n\n<details>\n<summary>Click here to view the file paths triggering these jobs</summary>\n<ul>\n<li><code>polaris/src/rubrik/common-go/audits/templates/cdm-host.yml</code></li>\n<li><code>polaris/src/rubrik/physicalhost/cmd/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/physicalhost/cmd/flags.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/cmd/run.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration_test.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/service.go</code></li>\n<li><code>polaris/src/rubrik/sdk_internal/services/gps/datacenter/physicalhost_service.py</code></li>\n</ul>\n</details>\n\n\n------\n\nMake sure you check these lines.\n\n<details><summary>Click here to view the Inline Comments</summary><ul><li><a href=\"https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455666\">https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455666</a></li></ul></details>\n\n------\n\nChanges in RBA code require review from #rba_rba-reviews. For guidelines, please check [RBA Code Review Checklist](https://rubrik.atlassian.net/wiki/spaces/EN/pages/3835331585/RBA+Code+Review+Checklist).\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/common-go/audits/templates/cdm-host.yml</code></li>\n<li><code>polaris/src/rubrik/physicalhost/cmd/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/physicalhost/cmd/flags.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/cmd/run.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration_test.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/service.go</code></li>\n<li><code>polaris/src/rubrik/sdk_internal/services/gps/datacenter/physicalhost_service.py</code></li>\n</ul>\n</details>\n\n\n------\n\nMake sure you check these lines.\n\n<details><summary>Click here to view the Inline Comments</summary><ul><li><a href=\"https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455695\">https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455695</a></li>\n<li><a href=\"https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455718\">https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455718</a></li></ul></details>\n\n------\n\nMake sure you check these lines.\n\n<details><summary>Click here to view the Inline Comments</summary><ul><li><a href=\"https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455771\">https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455771</a></li></ul></details>\n\n------\n\nChanges to user facing polaris documentation require review from #rsc_documentation_rsc_doc_diff_reviews.\n\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/common-go/audits/templates/cdm-host.yml</code></li>\n</ul>\n</details>\n\n\n------\n\n<!--Footer_Start-->\n\n",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#issuecomment-3271866430"
          },
          {
            "type": "review_summary",
            "author": "sreshth-dev",
            "created_at": "2025-09-03T09:57:08Z",
            "body": "lgtm",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#pullrequestreview-3179889138"
          }
        ],
        "inline_comments": [
          {
            "author": "rubrik-alfred[bot]",
            "created_at": "2025-09-03T06:10:00Z",
            "body": "Please refer to  [wiki](https://rubrik.atlassian.net/wiki/spaces/EVENT/pages/4230217894/Events+Review+Guidelines+2x025#Should-I-Include-an-Email-Notification?) for guidance on if an event should be emailable or not.\n\n\n<details><summary>Associated Global Comment</summary>\n\n------\n\nMake sure you check these lines.</details>",
            "file_path": "polaris/src/rubrik/common-go/audits/templates/cdm-host.yml",
            "line_number": 122,
            "diff_hunk": "@@ -112,6 +112,21 @@\n     syslog_facility: RubrikEvent\n     syslog_severity: Info\n \n+- name: RegisterSecondaryHostFailure\n+  message:\n+    v1:\n+      audit_msg: >\n+        ${username} failed to register host '${hostName}' as secondary. Reason: ${reason}.\n+      email_subject: >\n+        ${username} failed to register host '${hostName}' as secondary\n+  status: Failure",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2317861137"
          },
          {
            "author": "rubrik-alfred[bot]",
            "created_at": "2025-09-03T06:10:03Z",
            "body": "Looks like you're adding or modifying an event message. Please follow the guildlines for writing message in  [wiki](https://rubrik.atlassian.net/wiki/spaces/EVENT/pages/4230217894/Events+Review+Guidelines+2x025#Writing-Event-Messages)\n\n\n<details><summary>Associated Global Comment</summary>\n\n------\n\nMake sure you check these lines.</details>",
            "file_path": "polaris/src/rubrik/common-go/audits/templates/cdm-host.yml",
            "line_number": 116,
            "diff_hunk": "@@ -112,6 +112,21 @@\n     syslog_facility: RubrikEvent\n     syslog_severity: Info\n \n+- name: RegisterSecondaryHostFailure\n+  message:",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2317861252"
          },
          {
            "author": "moht-agrawal-rubrik",
            "created_at": "2025-09-03T06:11:06Z",
            "body": "primary host registration audit is emailable, hence added the same for secondary host registrationl",
            "file_path": "polaris/src/rubrik/common-go/audits/templates/cdm-host.yml",
            "line_number": 122,
            "diff_hunk": "@@ -112,6 +112,21 @@\n     syslog_facility: RubrikEvent\n     syslog_severity: Info\n \n+- name: RegisterSecondaryHostFailure\n+  message:\n+    v1:\n+      audit_msg: >\n+        ${username} failed to register host '${hostName}' as secondary. Reason: ${reason}.\n+      email_subject: >\n+        ${username} failed to register host '${hostName}' as secondary\n+  status: Failure",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2317862844"
          },
          {
            "author": "moht-agrawal-rubrik",
            "created_at": "2025-09-03T06:12:03Z",
            "body": "creating a new audit, didn't modify any existing one.",
            "file_path": "polaris/src/rubrik/common-go/audits/templates/cdm-host.yml",
            "line_number": 116,
            "diff_hunk": "@@ -112,6 +112,21 @@\n     syslog_facility: RubrikEvent\n     syslog_severity: Info\n \n+- name: RegisterSecondaryHostFailure\n+  message:",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2317864442"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T07:15:13Z",
            "body": "<h2>GOLANG USE RUBRIK ERRORS PACKAGE</h2>\n\n**Refactor `newAuditSender` to use `rubrik/common-go/errors` for error construction, ensuring consistency and compliance with review guidelines.**\n\n```diff\n-\t\treturn auditslib.NewAuditSender(mqFactory)\n+\t\treturn errors.Wrap(auditslib.NewAuditSender(mqFactory), \"Failed to create AuditSender\")\n\n```\n<details ><summary>More details here</summary><br>The `newAuditSender` function constructs errors using a standard approach. However, as per the review guidelines, errors should be constructed using the `rubrik/common-go/errors` package. If `auditslib.NewAuditSender` internally raises errors using standard packages, consider refactoring to use the `rubrik/common-go/errors` package for consistency and compliance.  \n\n```diff\n-\t\treturn auditslib.NewAuditSender(mqFactory)\n+\t\treturn errors.Wrap(auditslib.NewAuditSender(mqFactory), \"Failed to create AuditSender\")\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 3 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go</code>\n<ul><li>126 to 128</li><li>698 to 720</li></ul>\n<code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration_test.go</code>\n<ul><li>1830 to 1831</li></ul></details>\n<h2></h2>\n<!-- rule:GOLANG_USE_RUBRIK_ERRORS_PACKAGE -->\n\n\n:page_facing_up: **Source Document**\n_Edith Review Rule: GOLANG_USE_RUBRIK_ERRORS_PACKAGE_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"GOLANG_USE_RUBRIK_ERRORS_PACKAGE\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go\": [[126, 128], [698, 719], [719, 720]], \"polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration_test.go\": [[1830, 1831]]}} -->\n",
            "file_path": "polaris/src/rubrik/physicalhost/cmd/run.go",
            "line_number": 123,
            "diff_hunk": "@@ -109,3 +111,13 @@ func newCDMRestServiceClient(\n \t}\n \treturn crs.NewCDMRestServiceClient(crsConn)\n }\n+\n+func newMQFactory(ctx context.Context, conf *config) *mq.MessageQueueFactory {\n+\tmqFactory := mq.CreateMessageQueueFactory(ctx, conf.messageQueueConfig)\n+\treturn mqFactory\n+}\n+\n+func newAuditSender(ctx context.Context, conf *config) auditslib.AuditSender {\n+\tmqFactory := newMQFactory(ctx, conf)\n+\treturn auditslib.NewAuditSender(mqFactory)\n+}",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2317996432"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T07:15:15Z",
            "body": "<h2>GOLANG PROPAGATE ERRORS TO CALLER</h2>\n\n**Wrap `mq.ParseMessageQueueConfig(ctx)` errors with context and ensure stack trace capture. Update error handling accordingly.**\n\n```diff\n-        conf.messageQueueConfig = mq.ParseMessageQueueConfig(ctx)\n+        mqConfig, err := mq.ParseMessageQueueConfig(ctx)\n+        if err != nil {\n+            return nil, errors.Wrap(err, \"Failed to parse message queue configuration\")\n+        }\n+        conf.messageQueueConfig = mqConfig\n\n```\n<details ><summary>More details here</summary><br>The function `mq.ParseMessageQueueConfig(ctx)` potentially calls a third-party library. If it returns an error, it should be wrapped to provide additional context and ensure the stack trace is captured. Update this line to handle errors correctly.  \n\n```diff\n-        conf.messageQueueConfig = mq.ParseMessageQueueConfig(ctx)\n+        mqConfig, err := mq.ParseMessageQueueConfig(ctx)\n+        if err != nil {\n+            return nil, errors.Wrap(err, \"Failed to parse message queue configuration\")\n+        }\n+        conf.messageQueueConfig = mqConfig\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 7 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/physicalhost/cmd/run.go</code>\n<ul><li>114 to 118</li><li>119 to 123</li></ul>\n<code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go</code>\n<ul><li>120 to 124</li><li>708 to 715</li></ul>\n<code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration_test.go</code>\n<ul><li>1702</li><li>1837 to 1843</li><li>2235 to 2236</li></ul></details>\n<h2></h2>\n<!-- rule:GOLANG_PROPAGATE_ERRORS_TO_CALLER -->\n\n\n:page_facing_up: **Source Document**\n_Edith Review Rule: GOLANG_PROPAGATE_ERRORS_TO_CALLER_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"GOLANG_PROPAGATE_ERRORS_TO_CALLER\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/physicalhost/cmd/run.go\": [[114, 118], [119, 123]], \"polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go\": [[120, 124], [708, 715]], \"polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration_test.go\": [[1702, 1702], [1837, 1843], [2235, 2236]]}} -->\n",
            "file_path": "polaris/src/rubrik/physicalhost/cmd/flags.go",
            "line_number": 44,
            "diff_hunk": "@@ -37,5 +41,7 @@ func parseArgs(\n \n \tflaggy.Parse()\n \n+\tconf.messageQueueConfig = mq.ParseMessageQueueConfig(ctx)",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2317996523"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T07:15:18Z",
            "body": "<h2>GOLANG SEQUENTIAL RPC CALLS</h2>\n\n**Implement a batched approach for `auditSender.Send(ctx, audit)` to avoid RPC calls inside the loop.**\n\n```diff\n-\t\tfor _, host := range req.Hosts {\n-\t\t\tif hostResults[host.HostFid] != nil {\n-\t\t\t\t...\n-\t\t\t\terr := auditSender.Send(ctx, audit)\n-\t\t\t\tif err != nil {\n-\t\t\t\t\t...\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n\n+\t\tbatchedAudits := make([]auditslib.Audit, 0)\n+\t\tfor _, host := range req.Hosts {\n+\t\t\tif hostResults[host.HostFid] != nil {\n+\t\t\t\t...\n+\t\t\t\taudit := auditslib.NewRegisterSecondaryHostFailureAudit(\n+\t\t\t\t\tcommonFields,\n+\t\t\t\t\tauditslib.RegisterSecondaryHostFailureMessageVars{\n+\t\t\t\t\t\tUsername: req.ReqCtx.GetUsername(),\n+\t\t\t\t\t\tHostName: hostName,\n+\t\t\t\t\t\tReason:   hostResults[host.HostFid].Error(),\n+\t\t\t\t\t},\n+\t\t\t\t)\n+\t\t\t\tbatchedAudits = append(batchedAudits, audit)\n+\t\t\t}\n+\t\t}\n+\t\terr := auditSender.SendBatch(ctx, batchedAudits)\n+\t\tif err != nil {\n+\t\t\tlog.Errorf(ctx, \"Failed to send batched audits: %v\", err)\n+\t\t\treturn err\n+\t\t}\n\n```\n<details ><summary>More details here</summary><br>This code sequentially calls `auditSender.Send(ctx, audit)` inside the loop for each host that failed registration. This violates the guideline to avoid calling RPCs inside a loop when a batched alternative is available. Consider implementing a batched approach to send audits for multiple hosts in a single call.\n\n```diff\n-\t\tfor _, host := range req.Hosts {\n-\t\t\tif hostResults[host.HostFid] != nil {\n-\t\t\t\t...\n-\t\t\t\terr := auditSender.Send(ctx, audit)\n-\t\t\t\tif err != nil {\n-\t\t\t\t\t...\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n\n+\t\tbatchedAudits := make([]auditslib.Audit, 0)\n+\t\tfor _, host := range req.Hosts {\n+\t\t\tif hostResults[host.HostFid] != nil {\n+\t\t\t\t...\n+\t\t\t\taudit := auditslib.NewRegisterSecondaryHostFailureAudit(\n+\t\t\t\t\tcommonFields,\n+\t\t\t\t\tauditslib.RegisterSecondaryHostFailureMessageVars{\n+\t\t\t\t\t\tUsername: req.ReqCtx.GetUsername(),\n+\t\t\t\t\t\tHostName: hostName,\n+\t\t\t\t\t\tReason:   hostResults[host.HostFid].Error(),\n+\t\t\t\t\t},\n+\t\t\t\t)\n+\t\t\t\tbatchedAudits = append(batchedAudits, audit)\n+\t\t\t}\n+\t\t}\n+\t\terr := auditSender.SendBatch(ctx, batchedAudits)\n+\t\tif err != nil {\n+\t\t\tlog.Errorf(ctx, \"Failed to send batched audits: %v\", err)\n+\t\t\treturn err\n+\t\t}\n```\n</details><h2></h2>\n<!-- rule:GOLANG_SEQUENTIAL_RPC_CALLS -->\n\n\n:page_facing_up: **Source Document**\n_Edith Review Rule: GOLANG_SEQUENTIAL_RPC_CALLS_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"GOLANG_SEQUENTIAL_RPC_CALLS\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"not_distilled\", \"other_locations\": {}} -->\n",
            "file_path": "polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go",
            "line_number": 718,
            "diff_hunk": "@@ -663,3 +672,49 @@ func runHostDiagnosis(\n \n \treturn diagnosisResults\n }\n+\n+func sendAuditsForFailedHosts(\n+\tctx context.Context,\n+\treq *proto.BulkRegisterSecondaryHostsReq,\n+\thostResults map[string]error,\n+\thostFidToCdmHost map[string]*aspb.CdmPhysicalHost,\n+\tauditSender auditslib.AuditSender,\n+) error {\n+\tauditErrors := make([]error, 0)\n+\tfor _, host := range req.Hosts {\n+\t\tif hostResults[host.HostFid] != nil {\n+\t\t\thostName := \"unknown\"\n+\t\t\tif cdmHost, exists := hostFidToCdmHost[host.HostFid]; exists {\n+\t\t\t\thostName = cdmHost.GetName()\n+\t\t\t}\n+\t\t\tcommonFields := auditslib.CommonAuditFields{\n+\t\t\t\tAccountName: req.ReqCtx.AuthzCtx.Account,\n+\t\t\t\tUserID:      req.ReqCtx.GetUserId(),\n+\t\t\t\tUserName:    req.ReqCtx.GetUsername(),\n+\t\t\t\tObjectID:    host.HostFid,\n+\t\t\t\tObjectName:  hostName,\n+\t\t\t\tObjectType:  adm.PolarisAuditObjectType_HOST,\n+\t\t\t}\n+\n+\t\t\taudit := auditslib.NewRegisterSecondaryHostFailureAudit(\n+\t\t\t\tcommonFields,\n+\t\t\t\tauditslib.RegisterSecondaryHostFailureMessageVars{\n+\t\t\t\t\tUsername: req.ReqCtx.GetUsername(),\n+\t\t\t\t\tHostName: hostName,\n+\t\t\t\t\tReason:   hostResults[host.HostFid].Error(),\n+\t\t\t\t},\n+\t\t\t)\n+\t\t\terr := auditSender.Send(ctx, audit)\n+\t\t\tif err != nil {\n+\t\t\t\tlog.Errorf(\n+\t\t\t\t\tctx,\n+\t\t\t\t\t\"Failed to send audit for host %s: %v\",\n+\t\t\t\t\thost.HostFid,\n+\t\t\t\t\terr,\n+\t\t\t\t)\n+\t\t\t\tauditErrors = append(auditErrors, err)\n+\t\t\t}\n+\t\t}\n+\t}",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2317996596"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T07:15:20Z",
            "body": "<h2>GOLANG DO NOT LOG ERRORS WHEN PROPAGATING</h2>\n\n**Remove `log.Errorf` to comply with `GOLANG_DO_NOT_LOG_ERRORS_WHEN_PROPAGATING_ACTION`; return the error without logging.**\n\n```diff\n-        log.Errorf(ctx, \"Certificate transfer failed to all the hosts: %v\", err)\n         return err\n\n```\n<details ><summary>More details here</summary><br>Logging the error with `log.Errorf` when the error is already propagated upward violates the guideline `GOLANG_DO_NOT_LOG_ERRORS_WHEN_PROPAGATING_ACTION`. This is redundant since errors should only be logged when the execution thread terminates. Remove the logging statement and ensure the error is only returned.\n\n```diff\n-        log.Errorf(ctx, \"Certificate transfer failed to all the hosts: %v\", err)\n         return err\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration_test.go</code>\n<ul><li>1837 to 1843</li></ul></details>\n<h2></h2>\n<!-- rule:GOLANG_DO_NOT_LOG_ERRORS_WHEN_PROPAGATING -->\n\n\n:page_facing_up: **Source Document**\n_Edith Review Rule: GOLANG_DO_NOT_LOG_ERRORS_WHEN_PROPAGATING_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"GOLANG_DO_NOT_LOG_ERRORS_WHEN_PROPAGATING\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration_test.go\": [[1837, 1843]]}} -->\n",
            "file_path": "polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go",
            "line_number": 128,
            "diff_hunk": "@@ -114,6 +116,13 @@ func processBulkRegistration(\n \t\t}\n \t}\n \n+\t// Send audits for hosts that failed before reaching the bulk registration API\n+\t// The V1BulkRegisterHostAsyncRPC API sends its own audits.\n+\t_ = sendAuditsForFailedHosts(\n+\t\tctx, req, hostResults, hostFidToCdmHost,\n+\t\tauditSender,\n+\t)\n+\n \tif len(hostRegisters) == 0 {\n \t\t// Certificate transfer failed to all the hosts\n \t\tlog.Errorf(",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2317996688"
          },
          {
            "author": "sreshth-dev",
            "created_at": "2025-09-03T08:09:47Z",
            "body": "Please add \r\n```\r\nenv_vars = super().env(realm, deployment, config)\r\n```\r\nAnd then append your envs",
            "file_path": "polaris/src/rubrik/sdk_internal/services/gps/datacenter/physicalhost_service.py",
            "line_number": 56,
            "diff_hunk": "@@ -45,3 +45,14 @@ def capabilities(self, dependencies: Capabilities) -> Sequence[Capability]:\n             dependencies.access('cdm-rest-service', Scope.rw),\n             dependencies.access('forever-uuid-service', Scope.rw),\n         ]\n+\n+    def env(\n+        self,\n+        realm: 'Realm',\n+        deployment: 'Deployment',\n+        config: 'ConfigSet',\n+    ) -> Mapping[str, str]:\n+        \"\"\"Environment variables for the service.\"\"\"\n+        return {",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2318144006"
          },
          {
            "author": "moht-agrawal-rubrik",
            "created_at": "2025-09-03T09:19:09Z",
            "body": "Thanks, made the changes.",
            "file_path": "polaris/src/rubrik/sdk_internal/services/gps/datacenter/physicalhost_service.py",
            "line_number": 56,
            "diff_hunk": "@@ -45,3 +45,14 @@ def capabilities(self, dependencies: Capabilities) -> Sequence[Capability]:\n             dependencies.access('cdm-rest-service', Scope.rw),\n             dependencies.access('forever-uuid-service', Scope.rw),\n         ]\n+\n+    def env(\n+        self,\n+        realm: 'Realm',\n+        deployment: 'Deployment',\n+        config: 'ConfigSet',\n+    ) -> Mapping[str, str]:\n+        \"\"\"Environment variables for the service.\"\"\"\n+        return {",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2318346326"
          },
          {
            "author": "Arqum212",
            "created_at": "2025-09-04T08:59:24Z",
            "body": "@moht-agrawal-rubrik Do we send a mail and audit for per host failure in primary registration?",
            "file_path": "polaris/src/rubrik/common-go/audits/templates/cdm-host.yml",
            "line_number": 122,
            "diff_hunk": "@@ -112,6 +112,21 @@\n     syslog_facility: RubrikEvent\n     syslog_severity: Info\n \n+- name: RegisterSecondaryHostFailure\n+  message:\n+    v1:\n+      audit_msg: >\n+        ${username} failed to register host '${hostName}' as secondary. Reason: ${reason}.\n+      email_subject: >\n+        ${username} failed to register host '${hostName}' as secondary\n+  status: Failure",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2321342488"
          },
          {
            "author": "moht-agrawal-rubrik",
            "created_at": "2025-09-04T09:06:34Z",
            "body": "@Arqum212 From the code it looks like that (not able to test it if it works or not).\r\n\r\n```\r\n- name: RegisterHostFailure\r\n  message:\r\n    v1: >\r\n      ${username} failed to register host '${hostName}'. Reason: ${reason}.\r\n    v2:\r\n      audit_msg: >\r\n        ${username} failed to register host '${hostName}'. Reason: ${reason}.\r\n      email_subject: >\r\n        DONT SEND\r\n    v3:\r\n      audit_msg: >\r\n        ${username} failed to register host '${hostName}'. Reason: ${reason}.\r\n      email_subject: >\r\n        ${username} failed to register host '${hostName}'\r\n  status: Failure\r\n  severity: Info\r\n  type: Configuration\r\n  emailable: true\r\n  syslog:\r\n    syslog_facility: RubrikEvent\r\n    syslog_severity: Info\r\n```\r\nVersion v3 will be used for sending audits.",
            "file_path": "polaris/src/rubrik/common-go/audits/templates/cdm-host.yml",
            "line_number": 122,
            "diff_hunk": "@@ -112,6 +112,21 @@\n     syslog_facility: RubrikEvent\n     syslog_severity: Info\n \n+- name: RegisterSecondaryHostFailure\n+  message:\n+    v1:\n+      audit_msg: >\n+        ${username} failed to register host '${hostName}' as secondary. Reason: ${reason}.\n+      email_subject: >\n+        ${username} failed to register host '${hostName}' as secondary\n+  status: Failure",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2321360380"
          },
          {
            "author": "rubrik-alfred[bot]",
            "created_at": "2025-09-09T18:40:00Z",
            "body": "ObjectID and ObjectType control RBAC for events. Please ensure these fields are set as described in in  [wiki](https://rubrik.atlassian.net/wiki/spaces/EVENT/pages/4230217894/Events+Review+Guidelines+2x025#Object-ID%2C-ObjectType%2C-and-RBAC)\n\n\n<details><summary>Associated Global Comment</summary>\n\n------\n\nMake sure you check these lines.</details>",
            "file_path": "polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go",
            "line_number": 690,
            "diff_hunk": "@@ -663,3 +672,49 @@ func runHostDiagnosis(\n \n \treturn diagnosisResults\n }\n+\n+func sendAuditsForFailedHosts(\n+\tctx context.Context,\n+\treq *proto.BulkRegisterSecondaryHostsReq,\n+\thostResults map[string]error,\n+\thostFidToCdmHost map[string]*aspb.CdmPhysicalHost,\n+\tauditSender auditslib.AuditSender,\n+) error {\n+\tauditErrors := make([]error, 0)\n+\tfor _, host := range req.Hosts {\n+\t\tif hostResults[host.HostFid] != nil {\n+\t\t\thostName := \"unknown\"\n+\t\t\tif cdmHost, exists := hostFidToCdmHost[host.HostFid]; exists {\n+\t\t\t\thostName = cdmHost.GetName()\n+\t\t\t}\n+\t\t\tcommonFields := auditslib.CommonAuditFields{",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455666"
          },
          {
            "author": "rubrik-alfred[bot]",
            "created_at": "2025-09-09T18:40:01Z",
            "body": "Please refer to  [wiki](https://rubrik.atlassian.net/wiki/spaces/EVENT/pages/4230217894/Events+Review+Guidelines+2x025#Should-I-Include-an-Email-Notification?) for guidance on if an event should be emailable or not.\n\n\n<details><summary>Associated Global Comment</summary>\n\n------\n\nMake sure you check these lines.</details>",
            "file_path": "polaris/src/rubrik/common-go/audits/templates/cdm-host.yml",
            "line_number": 122,
            "diff_hunk": "@@ -112,6 +112,21 @@\n     syslog_facility: RubrikEvent\n     syslog_severity: Info\n \n+- name: RegisterSecondaryHostFailure\n+  message:\n+    v1:\n+      audit_msg: >\n+        ${username} failed to register host '${hostName}' as secondary. Reason: ${reason}.\n+      email_subject: >\n+        ${username} failed to register host '${hostName}' as secondary\n+  status: Failure",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455695"
          },
          {
            "author": "rubrik-alfred[bot]",
            "created_at": "2025-09-09T18:40:02Z",
            "body": "Please refer to  [wiki](https://rubrik.atlassian.net/wiki/spaces/EVENT/pages/4230217894/Events+Review+Guidelines+2x025#Should-I-Include-an-Email-Notification?) for guidance on if an event should be emailable or not.\n\n\n<details><summary>Associated Global Comment</summary>\n\n------\n\nMake sure you check these lines.</details>",
            "file_path": "polaris/src/rubrik/common-go/audits/templates/cdm-host.yml",
            "line_number": 125,
            "diff_hunk": "@@ -112,6 +112,21 @@\n     syslog_facility: RubrikEvent\n     syslog_severity: Info\n \n+- name: RegisterSecondaryHostFailure\n+  message:\n+    v1:\n+      audit_msg: >\n+        ${username} failed to register host '${hostName}' as secondary. Reason: ${reason}.\n+      email_subject: >\n+        ${username} failed to register host '${hostName}' as secondary\n+  status: Failure\n+  severity: Info\n+  type: Configuration\n+  emailable: true",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455718"
          },
          {
            "author": "rubrik-alfred[bot]",
            "created_at": "2025-09-09T18:40:03Z",
            "body": "Sending events/audits requires review from #polaris_events_watchers-events-reviews. There is a hard limit of 500 events per event series. Please check that you are not potentially sending more than this. For example, be sure you are not sending running events continuously in a loop while waiting certain tasks to complete. Another example, if your job operates over a large number of objects at once which all share a single event series, be sure to take steps to limit the number of events sent to the series.\n\n\n<details><summary>Associated Global Comment</summary>\n\n------\n\nMake sure you check these lines.</details>",
            "file_path": "polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go",
            "line_number": 707,
            "diff_hunk": "@@ -663,3 +672,49 @@ func runHostDiagnosis(\n \n \treturn diagnosisResults\n }\n+\n+func sendAuditsForFailedHosts(\n+\tctx context.Context,\n+\treq *proto.BulkRegisterSecondaryHostsReq,\n+\thostResults map[string]error,\n+\thostFidToCdmHost map[string]*aspb.CdmPhysicalHost,\n+\tauditSender auditslib.AuditSender,\n+) error {\n+\tauditErrors := make([]error, 0)\n+\tfor _, host := range req.Hosts {\n+\t\tif hostResults[host.HostFid] != nil {\n+\t\t\thostName := \"unknown\"\n+\t\t\tif cdmHost, exists := hostFidToCdmHost[host.HostFid]; exists {\n+\t\t\t\thostName = cdmHost.GetName()\n+\t\t\t}\n+\t\t\tcommonFields := auditslib.CommonAuditFields{\n+\t\t\t\tAccountName: req.ReqCtx.AuthzCtx.Account,\n+\t\t\t\tUserID:      req.ReqCtx.GetUserId(),\n+\t\t\t\tUserName:    req.ReqCtx.GetUsername(),\n+\t\t\t\tObjectID:    host.HostFid,\n+\t\t\t\tObjectName:  hostName,\n+\t\t\t\tObjectType:  adm.PolarisAuditObjectType_HOST,\n+\t\t\t}\n+\n+\t\t\taudit := auditslib.NewRegisterSecondaryHostFailureAudit(\n+\t\t\t\tcommonFields,\n+\t\t\t\tauditslib.RegisterSecondaryHostFailureMessageVars{\n+\t\t\t\t\tUsername: req.ReqCtx.GetUsername(),\n+\t\t\t\t\tHostName: hostName,\n+\t\t\t\t\tReason:   hostResults[host.HostFid].Error(),\n+\t\t\t\t},\n+\t\t\t)\n+\t\t\terr := auditSender.Send(ctx, audit)",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455741"
          },
          {
            "author": "rubrik-alfred[bot]",
            "created_at": "2025-09-09T18:40:04Z",
            "body": "Looks like you're adding or modifying an event message. Please follow the guildlines for writing message in  [wiki](https://rubrik.atlassian.net/wiki/spaces/EVENT/pages/4230217894/Events+Review+Guidelines+2x025#Writing-Event-Messages)\n\n\n<details><summary>Associated Global Comment</summary>\n\n------\n\nMake sure you check these lines.</details>",
            "file_path": "polaris/src/rubrik/common-go/audits/templates/cdm-host.yml",
            "line_number": 116,
            "diff_hunk": "@@ -112,6 +112,21 @@\n     syslog_facility: RubrikEvent\n     syslog_severity: Info\n \n+- name: RegisterSecondaryHostFailure\n+  message:",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455771"
          }
        ]
      },
      "files_changed": [
        {
          "filename": "polaris/src/rubrik/common-go/audits/templates/cdm-host.yml",
          "status": "modified",
          "additions": 15,
          "deletions": 0,
          "patch": "@@ -112,6 +112,21 @@\n     syslog_facility: RubrikEvent\n     syslog_severity: Info\n \n+- name: RegisterSecondaryHostFailure\n+  message:\n+    v1:\n+      audit_msg: >\n+        ${username} failed to register host '${hostName}' as secondary. Reason: ${reason}.\n+      email_subject: >\n+        ${username} failed to register host '${hostName}' as secondary\n+  status: Failure\n+  severity: Info\n+  type: Configuration\n+  emailable: true\n+  syslog:\n+    syslog_facility: RubrikEvent\n+    syslog_severity: Info\n+\n - name: DeleteHostStarted\n   message:\n     v1: >"
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/cmd/BUILD.bazel",
          "status": "modified",
          "additions": 2,
          "deletions": 0,
          "patch": "@@ -10,9 +10,11 @@ go_library(\n     deps = [\n         \"//rubrik/authz-service/proto:go_default_library\",\n         \"//rubrik/cdm-rest-service/proto:go_default_library\",\n+        \"//rubrik/common-go/audits:go_default_library\",\n         \"//rubrik/common-go/dual:go_default_library\",\n         \"//rubrik/common-go/flaggy:go_default_library\",\n         \"//rubrik/common-go/log:go_default_library\",\n+        \"//rubrik/common-go/message-queue:go_default_library\",\n         \"//rubrik/common-go/service:go_default_library\",\n         \"//rubrik/physicalhost/proto:go_default_library\",\n         \"//rubrik/physicalhost/svc:go_default_library\","
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/cmd/flags.go",
          "status": "modified",
          "additions": 6,
          "deletions": 0,
          "patch": "@@ -5,6 +5,7 @@ import (\n \n \t\"rubrik/common-go/dual\"\n \t\"rubrik/common-go/flaggy\"\n+\tmq \"rubrik/common-go/message-queue\"\n )\n \n // config stores the configuration loaded from flags and the environment.\n@@ -20,6 +21,9 @@ type config struct {\n \n \t// our settings\n \tgrpcPort dual.ServerPort\n+\n+\t// message queue configuration\n+\tmessageQueueConfig mq.MessageQueueConfig\n }\n \n // parseArgs loads configuration values from flags and the environment.\n@@ -37,5 +41,7 @@ func parseArgs(\n \n \tflaggy.Parse()\n \n+\tconf.messageQueueConfig = mq.ParseMessageQueueConfig(ctx)\n+\n \treturn &conf\n }"
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/cmd/run.go",
          "status": "modified",
          "additions": 15,
          "deletions": 3,
          "patch": "@@ -10,11 +10,12 @@ import (\n \n \tauthz \"rubrik/authz-service/proto\"\n \tcrs \"rubrik/cdm-rest-service/proto\"\n-\t\"rubrik/physicalhost/proto\"\n-\t\"rubrik/physicalhost/svc\"\n-\n+\tauditslib \"rubrik/common-go/audits\"\n \t\"rubrik/common-go/log\"\n+\tmq \"rubrik/common-go/message-queue\"\n \t\"rubrik/common-go/service\"\n+\t\"rubrik/physicalhost/proto\"\n+\t\"rubrik/physicalhost/svc\"\n )\n \n // Main is the beginning and end of life for PhysicalHostService.\n@@ -64,6 +65,7 @@ func buildService(\n \treturn svc.NewPhysicalHostService(\n \t\tnewCDMRestServiceClient(ctx, conf),\n \t\tnewAuthzClient(ctx, conf),\n+\t\tnewAuditSender(ctx, conf),\n \t)\n }\n \n@@ -109,3 +111,13 @@ func newCDMRestServiceClient(\n \t}\n \treturn crs.NewCDMRestServiceClient(crsConn)\n }\n+\n+func newMQFactory(ctx context.Context, conf *config) *mq.MessageQueueFactory {\n+\tmqFactory := mq.CreateMessageQueueFactory(ctx, conf.messageQueueConfig)\n+\treturn mqFactory\n+}\n+\n+func newAuditSender(ctx context.Context, conf *config) auditslib.AuditSender {\n+\tmqFactory := newMQFactory(ctx, conf)\n+\treturn auditslib.NewAuditSender(mqFactory)\n+}"
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/svc/BUILD.bazel",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -11,8 +11,10 @@ go_library(\n         \"//rubrik/authz-service/proto:go_default_library\",\n         \"//rubrik/cdm-rest-service/proto:go_default_library\",\n         \"//rubrik/cdm-rest-service/proto/types:go_default_library\",\n+        \"//rubrik/common-go/audits:go_default_library\",\n         \"//rubrik/common-go/authz/proto:go_default_library\",\n         \"//rubrik/common-go/log:go_default_library\",\n+        \"//rubrik/common-go/message-queue/audits/proto:go_default_library\",\n         \"//rubrik/physicalhost/errors:go_default_library\",\n         \"//rubrik/physicalhost/proto:go_default_library\",\n         \"//rubrik/vendor/github.com/golang/protobuf/ptypes/wrappers:go_default_library\",\n@@ -33,7 +35,6 @@ go_test(\n         \"//rubrik/common-go/api/context/proto:go_default_library\",\n         \"//rubrik/common-go/authz/proto:go_default_library\",\n         \"//rubrik/physicalhost/proto:go_default_library\",\n-        \"//rubrik/vendor/github.com/golang/protobuf/ptypes/wrappers:go_default_library\",\n         \"//rubrik/vendor/github.com/stretchr/testify/assert:go_default_library\",\n         \"//rubrik/vendor/github.com/stretchr/testify/mock:go_default_library\",\n         \"//rubrik/vendor/github.com/stretchr/testify/require:go_default_library\","
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go",
          "status": "modified",
          "additions": 57,
          "deletions": 2,
          "patch": "@@ -16,8 +16,10 @@ import (\n \tauthzclient \"rubrik/authz-service/proto\"\n \tcrs \"rubrik/cdm-rest-service/proto\"\n \tcrstypes \"rubrik/cdm-rest-service/proto/types\"\n+\tauditslib \"rubrik/common-go/audits\"\n \tacpb \"rubrik/common-go/authz/proto\"\n \t\"rubrik/common-go/log\"\n+\tadm \"rubrik/common-go/message-queue/audits/proto\"\n \t\"rubrik/physicalhost/proto\"\n )\n \n@@ -62,7 +64,7 @@ func (service *PhysicalHostService) BulkRegisterSecondaryHosts(\n \t\treq,\n \t\thostFidToCdmPhysicalHost,\n \t\tservice.crsClient,\n-\t\tservice.authzClient,\n+\t\tservice.auditSender,\n \t)\n }\n \n@@ -72,7 +74,7 @@ func processBulkRegistration(\n \treq *proto.BulkRegisterSecondaryHostsReq,\n \thostFidToCdmHost map[string]*aspb.CdmPhysicalHost,\n \tcrsClient crs.CDMRestServiceClient,\n-\tauthzClient authzclient.AuthzClient,\n+\tauditSender auditslib.AuditSender,\n ) (*proto.BulkRegisterSecondaryHostsReply, error) {\n \tlog.Infof(\n \t\tctx, \"Starting bulk secondary host registration for %d hosts on cluster %s\",\n@@ -114,6 +116,13 @@ func processBulkRegistration(\n \t\t}\n \t}\n \n+\t// Send audits for hosts that failed before reaching the bulk registration API\n+\t// The V1BulkRegisterHostAsyncRPC API sends its own audits.\n+\t_ = sendAuditsForFailedHosts(\n+\t\tctx, req, hostResults, hostFidToCdmHost,\n+\t\tauditSender,\n+\t)\n+\n \tif len(hostRegisters) == 0 {\n \t\t// Certificate transfer failed to all the hosts\n \t\tlog.Errorf(\n@@ -663,3 +672,49 @@ func runHostDiagnosis(\n \n \treturn diagnosisResults\n }\n+\n+func sendAuditsForFailedHosts(\n+\tctx context.Context,\n+\treq *proto.BulkRegisterSecondaryHostsReq,\n+\thostResults map[string]error,\n+\thostFidToCdmHost map[string]*aspb.CdmPhysicalHost,\n+\tauditSender auditslib.AuditSender,\n+) error {\n+\tauditErrors := make([]error, 0)\n+\tfor _, host := range req.Hosts {\n+\t\tif hostResults[host.HostFid] != nil {\n+\t\t\thostName := \"unknown\"\n+\t\t\tif cdmHost, exists := hostFidToCdmHost[host.HostFid]; exists {\n+\t\t\t\thostName = cdmHost.GetName()\n+\t\t\t}\n+\t\t\tcommonFields := auditslib.CommonAuditFields{\n+\t\t\t\tAccountName: req.ReqCtx.AuthzCtx.Account,\n+\t\t\t\tUserID:      req.ReqCtx.GetUserId(),\n+\t\t\t\tUserName:    req.ReqCtx.GetUsername(),\n+\t\t\t\tObjectID:    host.HostFid,\n+\t\t\t\tObjectName:  hostName,\n+\t\t\t\tObjectType:  adm.PolarisAuditObjectType_HOST,\n+\t\t\t}\n+\n+\t\t\taudit := auditslib.NewRegisterSecondaryHostFailureAudit(\n+\t\t\t\tcommonFields,\n+\t\t\t\tauditslib.RegisterSecondaryHostFailureMessageVars{\n+\t\t\t\t\tUsername: req.ReqCtx.GetUsername(),\n+\t\t\t\t\tHostName: hostName,\n+\t\t\t\t\tReason:   hostResults[host.HostFid].Error(),\n+\t\t\t\t},\n+\t\t\t)\n+\t\t\terr := auditSender.Send(ctx, audit)\n+\t\t\tif err != nil {\n+\t\t\t\tlog.Errorf(\n+\t\t\t\t\tctx,\n+\t\t\t\t\t\"Failed to send audit for host %s: %v\",\n+\t\t\t\t\thost.HostFid,\n+\t\t\t\t\terr,\n+\t\t\t\t)\n+\t\t\t\tauditErrors = append(auditErrors, err)\n+\t\t\t}\n+\t\t}\n+\t}\n+\treturn errors.Join(auditErrors...)\n+}"
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration_test.go",
          "status": "modified",
          "additions": 16,
          "deletions": 2,
          "patch": "@@ -16,6 +16,7 @@ import (\n \tcrs \"rubrik/cdm-rest-service/proto\"\n \tcrstypes \"rubrik/cdm-rest-service/proto/types\"\n \tcontextproto \"rubrik/common-go/api/context/proto\"\n+\tauditslib \"rubrik/common-go/audits\"\n \tacpb \"rubrik/common-go/authz/proto\"\n \tauthzcommon \"rubrik/common-go/authz/proto\"\n \t\"rubrik/physicalhost/proto\"\n@@ -1693,14 +1694,18 @@ func TestProcessBulkRegistration(t *testing.T) {\n \t\tt.Run(tt.name, func(t *testing.T) {\n \t\t\tmockCRS := &crs.MockCDMRestServiceClient{}\n \t\t\tmockAuthz := &authz.MockAuthzClient{}\n+\t\t\tmockAuditSender := &auditslib.MockAuditSender{}\n \t\t\ttt.setupMocks(mockCRS, mockAuthz)\n \n+\t\t\t// Mock audit sender to accept any audit calls\n+\t\t\tmockAuditSender.On(\"Send\", mock.Anything, mock.Anything).Return(nil)\n+\n \t\t\tresult, err := processBulkRegistration(\n \t\t\t\tctx,\n \t\t\t\ttt.request,\n \t\t\t\ttt.hostFidToCdmHost,\n \t\t\t\tmockCRS,\n-\t\t\t\tmockAuthz,\n+\t\t\t\tmockAuditSender,\n \t\t\t)\n \n \t\t\tif tt.expectError {\n@@ -1825,12 +1830,16 @@ func TestProcessBulkRegistrationBulkAPIFailure(t *testing.T) {\n \t\terrors.New(\"bulk registration service unavailable\"),\n \t)\n \n+\t// Mock audit sender\n+\tmockAuditSender := &auditslib.MockAuditSender{}\n+\tmockAuditSender.On(\"Send\", mock.Anything, mock.Anything).Return(nil)\n+\n \tresult, err := processBulkRegistration(\n \t\tctx,\n \t\trequest,\n \t\thostFidToCdmHost,\n \t\tmockCRS,\n-\t\tmockAuthz,\n+\t\tmockAuditSender,\n \t)\n \n \t// Function should return error\n@@ -2213,10 +2222,15 @@ func TestBulkRegisterSecondaryHostsPartialSuccess(t *testing.T) {\n \t\tItems: []*crstypes.HostDetail{},\n \t}, nil)\n \n+\t// Create mock audit sender\n+\tmockAuditSender := &auditslib.MockAuditSender{}\n+\tmockAuditSender.On(\"Send\", mock.Anything, mock.Anything).Return(nil)\n+\n \t// Create service instance\n \tservice := &PhysicalHostService{\n \t\tcrsClient:   mockCRS,\n \t\tauthzClient: mockAuthz,\n+\t\tauditSender: mockAuditSender,\n \t}\n \n \tresult, err := service.BulkRegisterSecondaryHosts(ctx, request)"
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/svc/service.go",
          "status": "modified",
          "additions": 4,
          "deletions": 0,
          "patch": "@@ -9,6 +9,7 @@ import (\n \n \tauthzclient \"rubrik/authz-service/proto\"\n \tcrs \"rubrik/cdm-rest-service/proto\"\n+\tauditslib \"rubrik/common-go/audits\"\n \tphysicalhosterrors \"rubrik/physicalhost/errors\"\n \t\"rubrik/physicalhost/proto\"\n )\n@@ -17,16 +18,19 @@ import (\n type PhysicalHostService struct {\n \tcrsClient   crs.CDMRestServiceClient\n \tauthzClient authzclient.AuthzClient\n+\tauditSender auditslib.AuditSender\n }\n \n // NewPhysicalHostService constructs a new PhysicalHostService.\n func NewPhysicalHostService(\n \tcrsClient crs.CDMRestServiceClient,\n \tauthzClient authzclient.AuthzClient,\n+\tauditSender auditslib.AuditSender,\n ) (*PhysicalHostService, error) {\n \tservice := &PhysicalHostService{\n \t\tcrsClient:   crsClient,\n \t\tauthzClient: authzClient,\n+\t\tauditSender: auditSender,\n \t}\n \n \treturn service, nil"
        },
        {
          "filename": "polaris/src/rubrik/sdk_internal/services/gps/datacenter/physicalhost_service.py",
          "status": "modified",
          "additions": 16,
          "deletions": 1,
          "patch": "@@ -1,6 +1,6 @@\n \"\"\"Physical Host Service\"\"\"\n \n-from typing import Sequence, Set\n+from typing import Mapping, Sequence, Set\n \n from rubrik.sdk_internal.security.capabilities import Capabilities, Capability\n from rubrik.sdk_internal.security.scopes import Scope\n@@ -45,3 +45,18 @@ def capabilities(self, dependencies: Capabilities) -> Sequence[Capability]:\n             dependencies.access('cdm-rest-service', Scope.rw),\n             dependencies.access('forever-uuid-service', Scope.rw),\n         ]\n+\n+    def env(\n+        self,\n+        realm: 'Realm',\n+        deployment: 'Deployment',\n+        config: 'ConfigSet',\n+    ) -> Mapping[str, str]:\n+        \"\"\"Environment variables for the service.\"\"\"\n+        env_vars = super().env(realm, deployment, config)\n+        env_vars.update(\n+            {\n+                'MESSAGE_QUEUE_PREFIX': deployment.name,\n+            }\n+        )\n+        return env_vars"
        }
      ],
      "statistics": {
        "commits": 7,
        "files_changed": 9,
        "additions": 133,
        "deletions": 9,
        "total_comments": 21
      }
    },
    "processed_data": {
      "source": "github",
      "link": "https://github.com/scaledata/sdmain/pull/97821",
      "timestamp": "2025-09-03 06:09:01",
      "title": "PR #97821: Send audits for failed secondary host registration",
      "long_summary": "Modified 9 files. (+133/-9 lines). - config\n\nKey changes:\n\u2022 polaris/src/rubrik/common-go/audits/templates/cdm-host.yml: Added RegisterSecondaryHostFailure audit event template with message, status, severity, and syslog details.\n\u2022 polaris/src/rubrik/physicalhost/cmd/flags.go: Added message queue configuration to config struct and initialized it in parseArgs function\n\u2022 polaris/src/rubrik/physicalhost/cmd/BUILD.bazel: Added dependencies on audits and message-queue libraries to the go_library target\n\nAuthor: moht-agrawal-rubrik, State: open, Reviewers: 2",
      "action_items": [
        "Refactor physicalhost_service.py to use `env_vars = super().env(realm, deployment, config)` and append additional environment variables as suggested.",
        "Respond to Arqum212's question regarding whether a mail and audit are sent for each host failure in primary registration, clarifying the current behavior and confirming if it matches the intended functionality."
      ],
      "score": 0.41142411176571153
    }
  }
]