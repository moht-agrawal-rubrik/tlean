[
  {
    "source": "github",
    "candidate_id": "github_pr_97449",
    "raw_data": {
      "pr_title": "Add RBAC test for the bulk secondary register host",
      "pr_summary": "## Summary:\n- Added rbac check for bulk secondary register api.\r\n- Created request and response message protos for the same.\r\n\r\nRBAC Design:\r\nhttps://docs.google.com/document/d/1PfqHPiWWrg6N2iZ3pvJ1Boub6fBDY56Vxj1mp_ydrhQ/edit?tab=t.0#heading=h.udxd12mbwnoc\r\n\r\nMCR Design:\r\nhttps://docs.google.com/document/d/1AlLURIn1x6pgJ6YFT655KJy15EHmtXDgEDdGDnKa-7c/edit?tab=t.0#heading=h.9b8h6v6gn4me\n\n## Test Plan:\nUnit tests\n\n## JIRA Issues:\nSPARK-572184\n\n## Revert Plan:\n## PR Stack:\nStack from arc wrapper with help from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):\n* #97821\n* #97551\n* #97450\n* __->__ #97449\n",
      "pr_url": "https://github.com/scaledata/sdmain/pull/97449",
      "metadata": {
        "number": 97449,
        "state": "open",
        "author": "moht-agrawal-rubrik",
        "created_at": "2025-09-02T06:40:19Z",
        "updated_at": "2025-09-10T03:01:13Z",
        "merged_at": null,
        "base_branch": "master",
        "head_branch": "gh/moht-agrawal-rubrik/15/head",
        "labels": [
          "SAILING"
        ],
        "assignees": [
          "punosp",
          "avinashb-17",
          "mthilesh-karnati",
          "ramanguleria",
          "Nagavenimythri",
          "Arqum212"
        ],
        "reviewers": [
          "ilya-netchitailo",
          "ramanguleria",
          "Nagavenimythri"
        ]
      },
      "comments": {
        "global_comments": [
          {
            "type": "discussion",
            "author": "rogers-sail-information[bot]",
            "created_at": "2025-09-02T06:40:44Z",
            "body": "<!-- rogers sail info comment -->\n## Sail Information: ([badmnr-reyoxj4](https://rogers.rubrik.com/api/sail_requests/badmnr-reyoxj4/))\n\n\n\n\n\n> \n> [!NOTE]\n> CI is currently running. You'll receive updates as each step completes.\n> \n> <sub><b>Sail Status:</b> \u231bSAILING</sub>\n\n\n\n\n\n\n#### \u26f5 Sail Steps\n\n<table>\n  <thead>\n    <tr>\n      <th>Jobs</th>\n      <th>Time Created</th>\n      <th>Status</th>\n      <th>Message</th>\n    </tr>\n  </thead>\n  <tbody>\n  \n  <tr>\n    <td><a href=\"https://arc-reactor.stark.rubrik.com/job/ARC_Expedited_Build_CDM_Colo_BB/54188\">ARC_Expedited_Build_CDM_Colo_BB</a></td>\n    <td>2025-09-09 18:43 UTC</td>\n    <td>\u2705 <a href=\"https://rogers.rubrik.com/api/jenkins_job_steps/74ppt6-cxt3gcc/\">SUCCEEDED</a></td>\n    <td></td>\n  </tr>\n  \n  <tr>\n    <td><a href=\"https://arc-reactor.stark.rubrik.com/job/ARC_Jedi_Build_Colo/41289\">ARC_Jedi_Build_Colo</a></td>\n    <td>2025-09-09 18:43 UTC</td>\n    <td>\u2705 <a href=\"https://rogers.rubrik.com/api/jenkins_job_steps/m425wd-qvrmzww/\">SUCCEEDED</a></td>\n    <td></td>\n  </tr>\n  \n  <tr>\n    <td><a href=\"https://polaris-arc-reactor.stark.rubrik.com/job/ARC_Build_Polaris/457078/display/redirect\">ARC_Build_Polaris</a></td>\n    <td>2025-09-09 18:43 UTC</td>\n    <td>\u2705 <a href=\"https://rogers.rubrik.com/api/jenkins_job_steps/fuiaws-kuwdtne/\">SUCCEEDED</a></td>\n    <td></td>\n  </tr>\n  \n  <tr>\n    <td><a href=\"https://polaris-arc-reactor.stark.rubrik.com/job/ARC_Land_Polaris\">ARC_Land_Polaris</a></td>\n    <td>2025-09-09 18:43 UTC</td>\n    <td>\u26aa <a href=\"https://rogers.rubrik.com/api/jenkins_job_steps/ercce7-kuzjj32/\">QUEUED</a></td>\n    <td>PR97449 for sail Sail(sid=7tqvqj-thxbqai) has failed required check run Pull Request Approval Status with status `completed` and conclusion `failure`.  See https://github.com/scaledata/sdmain/runs/49989653408 for more details. Keeping the step queued.</td>\n  </tr>\n  \n  </tbody>\n</table>\n\n\n\n---\n\n<sub>\n<b><a href=\"https://github.com/scaledata/sdmain/runs/49976342891\">Previous Sail Requests (4)</a></b> | <b>Last Updated:</b> 2025-09-10 03:00 UTC<br><br>\n</sub>\n\n\n\n\n",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3243991227"
          },
          {
            "type": "discussion",
            "author": "SD-111029",
            "created_at": "2025-09-02T06:56:07Z",
            "body": "\nBackward compatibility guidelines: https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2269250186\n\n```\nBACKWARD COMPATIBILITY CHECK REPORT\n\n=========================================================\nPROTOBUF REPORT (#polaris-backward-compatibility-reviews)\n=========================================================\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:70:/message::BulkRegisterSecondaryHostsReq/field::2 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:73:/message::BulkRegisterSecondaryHostsReq/field::3 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:91:/message::BulkRegisterSecondaryHostsReply/field::1 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n==================================\nFEATURE FLAG REPORT (#sre-reviews)\n==================================\nLooks good. No feature flags removed.\n\n```\n",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3244030318"
          },
          {
            "type": "discussion",
            "author": "polaris-jenkins-sails[bot]",
            "created_at": "2025-09-03T03:16:02Z",
            "body": "<h2>Coverage Report</h2> <table> <tr><th>PR/PRs</th><th>Upstream</th> <th>Diff (delta)</th><th>New (# new lines)</th> <th>Passed</th><th>Notes</th></tr><tr> <td><b>PR97449</b></td><td>N/A</td><td>N/A (0)</td><td><a href='https://vision.stark.rubrik.com/component_measures?id=polaris-test&metric=new_lines_to_cover&branch=PR97449&view=list'>0</a></td><td>:white_check_mark:</td><td></td> </tr> </table><b> NOTE: </b><i>If you encounter any issues with the coverage calculation or reporting, please reach out to us on #stark-dev-experience. <b>Coverage bot will be approved during sail before land stage if your PR met the coverage criteria<b/>.</i><br/><br/><p><a href='https://polaris-arc-reactor.stark.rubrik.com/job/polaris_diff_coverage/434313/'>Jenkins Build Link</a></p>",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3247542036"
          },
          {
            "type": "discussion",
            "author": "polaris-jenkins-sails[bot]",
            "created_at": "2025-09-03T05:05:19Z",
            "body": "<h2>Coverage Report</h2> <table> <tr><th>PR/PRs</th><th>Upstream</th> <th>Diff (delta)</th><th>New (# new lines)</th> <th>Passed</th><th>Notes</th></tr><tr> <td><b>PR97449</b></td><td>N/A</td><td>N/A (0)</td><td><a href='https://vision.stark.rubrik.com/component_measures?id=polaris-test&metric=new_lines_to_cover&branch=PR97449&view=list'>0</a></td><td>:white_check_mark:</td><td></td> </tr> </table><b> NOTE: </b><i>If you encounter any issues with the coverage calculation or reporting, please reach out to us on #stark-dev-experience. <b>Coverage bot will be approved during sail before land stage if your PR met the coverage criteria<b/>.</i><br/><br/><p><a href='https://polaris-arc-reactor.stark.rubrik.com/job/polaris_diff_coverage/434335/'>Jenkins Build Link</a></p>",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3247698930"
          },
          {
            "type": "discussion",
            "author": "SD-111029",
            "created_at": "2025-09-03T11:33:50Z",
            "body": "\nBackward compatibility guidelines: https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2269250186\n\n```\nBACKWARD COMPATIBILITY CHECK REPORT\n\n=========================================================\nPROTOBUF REPORT (#polaris-backward-compatibility-reviews)\n=========================================================\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:70:/message::BulkRegisterSecondaryHostsReq/field::2 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:73:/message::BulkRegisterSecondaryHostsReq/field::3 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:91:/message::BulkRegisterSecondaryHostsReply/field::1 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n==================================\nFEATURE FLAG REPORT (#sre-reviews)\n==================================\nLooks good. No feature flags removed.\n\n```\n",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3248860365"
          },
          {
            "type": "discussion",
            "author": "SD-111029",
            "created_at": "2025-09-03T11:56:08Z",
            "body": "\nBackward compatibility guidelines: https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2269250186\n\n```\nBACKWARD COMPATIBILITY CHECK REPORT\n\n=========================================================\nPROTOBUF REPORT (#polaris-backward-compatibility-reviews)\n=========================================================\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:70:/message::BulkRegisterSecondaryHostsReq/field::2 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:73:/message::BulkRegisterSecondaryHostsReq/field::3 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:91:/message::BulkRegisterSecondaryHostsReply/field::1 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n==================================\nFEATURE FLAG REPORT (#sre-reviews)\n==================================\nLooks good. No feature flags removed.\n\n```\n",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3248938866"
          },
          {
            "type": "discussion",
            "author": "polaris-jenkins-sails[bot]",
            "created_at": "2025-09-03T12:09:59Z",
            "body": "<h2>Coverage Report</h2> <table> <tr><th>PR/PRs</th><th>Upstream</th> <th>Diff (delta)</th><th>New (# new lines)</th> <th>Passed</th><th>Notes</th></tr><tr> <td><b>PR97449</b></td><td>N/A</td><td>N/A (0)</td><td><a href='https://vision.stark.rubrik.com/component_measures?id=polaris-test&metric=new_lines_to_cover&branch=PR97449&view=list'>0</a></td><td>:white_check_mark:</td><td></td> </tr> </table><b> NOTE: </b><i>If you encounter any issues with the coverage calculation or reporting, please reach out to us on #stark-dev-experience. <b>Coverage bot will be approved during sail before land stage if your PR met the coverage criteria<b/>.</i><br/><br/><p><a href='https://polaris-arc-reactor.stark.rubrik.com/job/polaris_diff_coverage/434464/'>Jenkins Build Link</a></p>",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3248984548"
          },
          {
            "type": "discussion",
            "author": "SD-111029",
            "created_at": "2025-09-03T12:39:11Z",
            "body": "\nBackward compatibility guidelines: https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2269250186\n\n```\nBACKWARD COMPATIBILITY CHECK REPORT\n\n=========================================================\nPROTOBUF REPORT (#polaris-backward-compatibility-reviews)\n=========================================================\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:70:/message::BulkRegisterSecondaryHostsReq/field::2 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:73:/message::BulkRegisterSecondaryHostsReq/field::3 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:91:/message::BulkRegisterSecondaryHostsReply/field::1 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n==================================\nFEATURE FLAG REPORT (#sre-reviews)\n==================================\nLooks good. No feature flags removed.\n\n```\n",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3249083207"
          },
          {
            "type": "discussion",
            "author": "SD-111029",
            "created_at": "2025-09-03T13:11:07Z",
            "body": "\nBackward compatibility guidelines: https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2269250186\n\n```\nBACKWARD COMPATIBILITY CHECK REPORT\n\n=========================================================\nPROTOBUF REPORT (#polaris-backward-compatibility-reviews)\n=========================================================\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:70:/message::BulkRegisterSecondaryHostsReq/field::2 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:73:/message::BulkRegisterSecondaryHostsReq/field::3 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n\nINFO\tpolaris/src/rubrik/physicalhost/proto/physicalhost.proto:91:/message::BulkRegisterSecondaryHostsReply/field::1 Client/server may not be able to use this field immediately.\n\tField added. It may not be available for use by client or server in the same release. For details, refer to backward compatibility guidelines.\n==================================\nFEATURE FLAG REPORT (#sre-reviews)\n==================================\nLooks good. No feature flags removed.\n\n```\n",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3249198343"
          },
          {
            "type": "discussion",
            "author": "polaris-jenkins-sails[bot]",
            "created_at": "2025-09-03T13:21:27Z",
            "body": "<h2>Coverage Report</h2> <table> <tr><th>PR/PRs</th><th>Upstream</th> <th>Diff (delta)</th><th>New (# new lines)</th> <th>Passed</th><th>Notes</th></tr><tr> <td><b>PR97449</b></td><td>N/A</td><td>N/A (0)</td><td><a href='https://vision.stark.rubrik.com/component_measures?id=polaris-test&metric=new_lines_to_cover&branch=PR97449&view=list'>0</a></td><td>:white_check_mark:</td><td></td> </tr> </table><b> NOTE: </b><i>If you encounter any issues with the coverage calculation or reporting, please reach out to us on #stark-dev-experience. <b>Coverage bot will be approved during sail before land stage if your PR met the coverage criteria<b/>.</i><br/><br/><p><a href='https://polaris-arc-reactor.stark.rubrik.com/job/polaris_diff_coverage/434481/'>Jenkins Build Link</a></p>",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3249238893"
          },
          {
            "type": "discussion",
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-04T07:16:24Z",
            "body": "_:hourglass: Your RR [scaledata/sdmain/97449](https://github.com/scaledata/sdmain/pull/97449) has not been reviewed within the SLO. Resigning the following blocking reviewers:_\n * @scaledata/polaris-backward-compatibility-polaris-backward-compatibility-reviews",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3252256819"
          },
          {
            "type": "discussion",
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-04T07:46:58Z",
            "body": "_:hourglass: Your RR [scaledata/sdmain/97449](https://github.com/scaledata/sdmain/pull/97449) has not been reviewed within the SLO. Resigning the following blocking reviewers:_\n * @scaledata/rba-shadow\n * @scaledata/rba-rba-reviews",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3252357693"
          },
          {
            "type": "discussion",
            "author": "moht-agrawal-rubrik",
            "created_at": "2025-09-04T10:46:22Z",
            "body": "> not from security perspective but from performance perspective futures should be better ? WDYT ?\r\n\r\n@punosp\r\nI think we are fine with this implementation also. Realistically, the majority of time will be spent by the CDM (The API is implemented in the next stacked diff). Even if we optimise this with multi-threading, the overall gains in the API will not be much. Though, can't say much without benchmarking it with different number of hosts.",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3253066605"
          },
          {
            "type": "discussion",
            "author": "rubrik-alfred[bot]",
            "created_at": "2025-09-09T18:39:41Z",
            "body": "## :man_in_tuxedo: Alfred Comments\n<input type='hidden' commit='019d1b3aafd388520f2d4f17bccf712a22da0f00' global='true'/>\n<!--Header_Done-->\n\nChanges on RBAC policies or `CustomRbacCheck` should be reviewed by #security-leads_security-leads-code-review according to [RSC RBAC Policy review guideline](https://rubrik.atlassian.net/wiki/spaces/EN/pages/2812282937/How+to+Review+RSC+RBAC+Policy).\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala</code></li>\n<li><code>polaris/src/rubrik/api-server/test/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImplTest.scala</code></li>\n</ul>\n</details>\n\n\n------\n\nAll changes to the API server and associated files have to be reviewed by Polaris API team #gql-sdmain_get_reviews_on_gql-sdmain.      \n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code></li>\n</ul>\n</details>\n\n\n------\n\nAll changes to public GraphQL API have to be reviewed by Polaris Documentation team #rsc_documentation_rsc_doc_diff_reviews.      \n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql</code></li>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql</code></li>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code></li>\n</ul>\n</details>\n\n\n------\n\nTriggering the GqlSchema_Check job.\n\n\nThe following jobs are triggered:\n\n\n- [GqlSchema_Check](https://polaris-builds.stark.rubrik.com/job/GqlSchema_Check)\n\n\n<details>\n<summary>Click here to view the file paths triggering these jobs</summary>\n<ul>\n<li><code>polaris/src/rubrik/api-server/app/services/physicalhost/rbac/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala</code></li>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql</code></li>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql</code></li>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code></li>\n<li><code>polaris/src/rubrik/api-server/test/app/services/physicalhost/rbac/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/api-server/test/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImplTest.scala</code></li>\n<li><code>polaris/src/rubrik/physicalhost/proto/physicalhost.proto</code></li>\n</ul>\n</details>\n\n\n------\n\nBelow coding pattern require review from #rsc-perf-anti-pattern-reviews.\n\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala</code></li>\n</ul>\n</details>\n\n\n------\n\nTriggering the detect-changed-services pipeline. If your PR is raised against a Polaris release branch, this pipeline will leave a comment with a list of the services that will be affected by the changes in your PR.\n\n\nThe following jobs are triggered:\n\n\n- [detect-changed-services](https://polaris-builds.stark.rubrik.com/job/detect-changed-services)\n\n\n<details>\n<summary>Click here to view the file paths triggering these jobs</summary>\n<ul>\n<li><code>polaris/src/rubrik/api-server/app/services/physicalhost/rbac/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala</code></li>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql</code></li>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql</code></li>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code></li>\n<li><code>polaris/src/rubrik/api-server/test/app/services/physicalhost/rbac/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/api-server/test/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImplTest.scala</code></li>\n<li><code>polaris/src/rubrik/global-api/schema/schema.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/proto/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/physicalhost/proto/physicalhost.proto</code></li>\n<li><code>polaris/yodalibs/generated/gql_inputs.py</code></li>\n</ul>\n</details>\n\n\n------\n\nPolaris Backward Compatibility changes will be reviewed by Edith Automated Review.\n\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/physicalhost/proto/physicalhost.proto</code></li>\n</ul>\n</details>\n\n\n------\n\nChanges in dlc related files require review from #polaris-dlc-reviewers_get_review_on_dlc-review. Please refer [wiki](https://rubrik.atlassian.net/wiki/spaces/EN/pages/2859927199/DLC+Code+Review+Guidelines) for guidlines.\n\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql</code></li>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql</code></li>\n<li><code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code></li>\n</ul>\n</details>\n\n\n------\n\nChanges within polaris/src/rubrik/ need review by polaris_code_coverage_reviewer:. Please see [Code Coverage @Rubrik](https://docs.google.com/document/d/17OJ1OUG77mMJEhgXQMZYIvT17dLbOMUZkSvrsuvQdjY/edit?usp=sharing)\n\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/global-api/schema/schema.go</code></li>\n</ul>\n</details>\n\n\n------\n\nDuring the upgrade, this code will be talking to services from the release currently in production. That means to avoid outages, we should be backwards compatible to the previous release.\n\nhttps://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2269250186/Polaris+Version+Compatibility+Guidelines\n\nThe following jobs is triggered [backward-compatibility-check](https://polaris-builds.stark.rubrik.com/job/backward-compatibility-check/).\nPlease make sure to check the status of the job.\n\n\n------\n\nChanges in RBA code require review from #rba_rba-reviews. For guidelines, please check [RBA Code Review Checklist](https://rubrik.atlassian.net/wiki/spaces/EN/pages/3835331585/RBA+Code+Review+Checklist).\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/api-server/app/services/physicalhost/rbac/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala</code></li>\n<li><code>polaris/src/rubrik/api-server/test/app/services/physicalhost/rbac/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/api-server/test/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImplTest.scala</code></li>\n<li><code>polaris/src/rubrik/physicalhost/proto/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/physicalhost/proto/physicalhost.proto</code></li>\n</ul>\n</details>\n\n\n------\n\n<!--Footer_Start-->\n\n",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3271865285"
          },
          {
            "type": "discussion",
            "author": "polaris-jenkins-sails[bot]",
            "created_at": "2025-09-09T19:01:00Z",
            "body": "<h2>Coverage Report</h2> <table> <tr><th>PR/PRs</th><th>Upstream</th> <th>Diff (delta)</th><th>New (# new lines)</th> <th>Passed</th><th>Notes</th></tr><tr> <td><b>PR97449</b></td><td>N/A</td><td>N/A (0)</td><td><a href='https://vision.stark.rubrik.com/component_measures?id=polaris-test&metric=new_lines_to_cover&branch=PR97449&view=list'>0</a></td><td>:white_check_mark:</td><td></td> </tr> </table><b> NOTE: </b><i>If you encounter any issues with the coverage calculation or reporting, please reach out to us on #stark-dev-experience. <b>Coverage bot will be approved during sail before land stage if your PR met the coverage criteria<b/>.</i><br/><br/><p><a href='https://polaris-arc-reactor.stark.rubrik.com/job/polaris_diff_coverage/435986/'>Jenkins Build Link</a></p>",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#issuecomment-3271930173"
          }
        ],
        "inline_comments": [
          {
            "author": "moht-agrawal-rubrik",
            "created_at": "2025-09-02T06:50:14Z",
            "body": "borrowing this from the api-v1 implementation.\r\nref: `polaris/src/rubrik/api-server/app/apps/physicalhost/schema/rbac/PhysicalHostRbacPolicies.scala`",
            "file_path": "polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala",
            "line_number": 40,
            "diff_hunk": "@@ -1,17 +1,243 @@\n package services.physicalhost.rbac\n \n+import authzservice.authzservice.InventorySubHierarchyRootEnum.LINUX_HOST_ROOT\n+import authzservice.authzservice.InventorySubHierarchyRootEnum.WINDOWS_HOST_ROOT\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister.HostRegisterOsType\n+import dal.grpc.UnifiedFeatureFlagService\n+import javax.inject.Inject\n+import models.graphql.AttributedFeatureFlagName\n+import models.graphql.FeatureFlagAttribute\n+import models.graphql.FlagAttribute\n import physicalhost.physicalhost.BulkRegisterSecondaryHostsReq\n import sangria.schema.Context\n import security.UserContext\n-import security.rbac.AdminOrOwnerAccessForDev\n+import security.rbac.And\n+import security.rbac.CustomRbacCheck\n+import security.rbac.CustomRbacCheckResult\n+import security.rbac.MoreRbacChecksNeeded\n+import security.rbac.Operation.AddInventory\n+import security.rbac.Operation.Ctx\n+import security.rbac.Operation.ManageDataSource\n+import security.rbac.Or\n+import security.rbac.RbacCheck\n import security.rbac.RbacPolicy\n \n-class PhysicalHostRbacPoliciesImpl extends PhysicalHostRbacPolicies {\n+class PhysicalHostRbacPoliciesImpl @Inject() (\n+  uffs: UnifiedFeatureFlagService\n+) extends PhysicalHostRbacPolicies {\n   // Add your custom RBAC policies here\n   def bulkRegisterSecondaryHosts(\n     argSupplier: Context[UserContext, _] => BulkRegisterSecondaryHostsReq\n   ): RbacPolicy = {\n-    // TODO(SPARK-572184): Add RBAC policy\n-    RbacPolicy(AdminOrOwnerAccessForDev)\n+    RbacPolicy(\n+      BulkSecondaryRegisterHostRbacCheck(argSupplier, uffs)\n+    )\n+  }\n+\n+  // TODO SPARK-283757 Fix RbacPolicy to use list of objects instead of\n+  //  multiple RBACChecks for each object.\n+  private case class BulkRegisterHostRbacCheck(",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2315088579"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-02T06:57:51Z",
            "body": "<h2>RSC ANTI PATTERN GITHUB RULE</h2>\n\n**Refactor `bulkRegisterSecondaryHosts` to use `NamedFetcher` for batching, adhering to Confluence Rule on hierarchical data queries.**\n\n```scala\n// Example refactor snippet\nval BulkRegisterSecondaryHostsFetcher: NamedFetcher[UserContext, HostRegister, HostRegister, UUID] =\n  NamedFetcher(\n    \"BulkRegisterSecondaryHostsFetcher\",\n    (ctx: UserContext, hostFids: Seq[String], span: Option[Span]) => {\n      implicit val spanOpt: Option[Span] = span\n      queries.bulkRegisterSecondaryHostsBatched(ctx, hostFids)\n    }\n  )(HasId(_.fid))\n\ndef bulkRegisterSecondaryHosts(\n  argSupplier: Context[UserContext, _] => BulkRegisterSecondaryHostsReq\n): RbacPolicy = {\n  RbacPolicy(\n    DeferredValue(BulkRegisterSecondaryHostsFetcher.defer(argSupplier(ctx).hosts.map(_.hostFid)))\n  )\n}\n\n```\n<details ><summary>More details here</summary><br>The `bulkRegisterSecondaryHosts` method uses `BulkSecondaryRegisterHostRbacCheck`. While this implementation is clear, no batching behavior has been introduced for any downstream calls made by this method. As per the Confluence Rule, batching should be introduced to avoid performance degradation for queries involving hierarchical data. Consider refactoring the implementation with a `NamedFetcher` for batching.  \n\n```scala\n// Example refactor snippet\nval BulkRegisterSecondaryHostsFetcher: NamedFetcher[UserContext, HostRegister, HostRegister, UUID] =\n  NamedFetcher(\n    \"BulkRegisterSecondaryHostsFetcher\",\n    (ctx: UserContext, hostFids: Seq[String], span: Option[Span]) => {\n      implicit val spanOpt: Option[Span] = span\n      queries.bulkRegisterSecondaryHostsBatched(ctx, hostFids)\n    }\n  )(HasId(_.fid))\n\ndef bulkRegisterSecondaryHosts(\n  argSupplier: Context[UserContext, _] => BulkRegisterSecondaryHostsReq\n): RbacPolicy = {\n  RbacPolicy(\n    DeferredValue(BulkRegisterSecondaryHostsFetcher.defer(argSupplier(ctx).hosts.map(_.hostFid)))\n  )\n}\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala</code>\n<ul><li>76 to 87</li></ul></details>\n<h2></h2>\n<!-- rule:rsc_anti_pattern_github_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/SPARK/pag...](https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/3463545100/graphql-batching)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"rsc_anti_pattern_github_rule\", \"processable\": true, \"contextual_eligible\": true, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala\": [[76, 87]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala",
            "line_number": 36,
            "diff_hunk": "@@ -1,17 +1,243 @@\n package services.physicalhost.rbac\n \n+import authzservice.authzservice.InventorySubHierarchyRootEnum.LINUX_HOST_ROOT\n+import authzservice.authzservice.InventorySubHierarchyRootEnum.WINDOWS_HOST_ROOT\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister.HostRegisterOsType\n+import dal.grpc.UnifiedFeatureFlagService\n+import javax.inject.Inject\n+import models.graphql.AttributedFeatureFlagName\n+import models.graphql.FeatureFlagAttribute\n+import models.graphql.FlagAttribute\n import physicalhost.physicalhost.BulkRegisterSecondaryHostsReq\n import sangria.schema.Context\n import security.UserContext\n-import security.rbac.AdminOrOwnerAccessForDev\n+import security.rbac.And\n+import security.rbac.CustomRbacCheck\n+import security.rbac.CustomRbacCheckResult\n+import security.rbac.MoreRbacChecksNeeded\n+import security.rbac.Operation.AddInventory\n+import security.rbac.Operation.Ctx\n+import security.rbac.Operation.ManageDataSource\n+import security.rbac.Or\n+import security.rbac.RbacCheck\n import security.rbac.RbacPolicy\n \n-class PhysicalHostRbacPoliciesImpl extends PhysicalHostRbacPolicies {\n+class PhysicalHostRbacPoliciesImpl @Inject() (\n+  uffs: UnifiedFeatureFlagService\n+) extends PhysicalHostRbacPolicies {\n   // Add your custom RBAC policies here\n   def bulkRegisterSecondaryHosts(\n     argSupplier: Context[UserContext, _] => BulkRegisterSecondaryHostsReq\n   ): RbacPolicy = {\n-    // TODO(SPARK-572184): Add RBAC policy\n-    RbacPolicy(AdminOrOwnerAccessForDev)\n+    RbacPolicy(\n+      BulkSecondaryRegisterHostRbacCheck(argSupplier, uffs)\n+    )\n+  }",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2315105851"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-02T06:57:54Z",
            "body": "<h2>POLARIS BACKWARD COMPATIBILITY RULE</h2>\n\n**Add `_UNSPECIFIED` to `HostRegisterOsType` ENUM and handle it in server code to ensure a default value.**\n\n```diff\n-        cdmrestservice.HostRegister.HostRegisterOsType os_type = 3;\n+        cdmrestservice.HostRegister.HostRegisterOsType os_type = 3 [(api.graphql_field).default_value = \"UNSPECIFIED\"];\n\n```\n<details ><summary>More details here</summary><br>The `os_type` field uses `cdmrestservice.HostRegister.HostRegisterOsType` without specifying a default value for the ENUM. As per guidelines, the ENUM type should include an `_UNSPECIFIED` value for the default case to prevent ambiguity. Update the ENUM definition in `HostRegisterOsType` to include an `_UNSPECIFIED` value and handle it appropriately in the server code.\n\n```diff\n-        cdmrestservice.HostRegister.HostRegisterOsType os_type = 3;\n+        cdmrestservice.HostRegister.HostRegisterOsType os_type = 3 [(api.graphql_field).default_value = \"UNSPECIFIED\"];\n```\n</details><h2></h2>\n<!-- rule:polaris_backward_compatibility_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/SPARK/pag...](https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2296840439/Guidelines)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"polaris_backward_compatibility_rule\", \"processable\": true, \"contextual_eligible\": true, \"distilled_type\": \"not_distilled\", \"other_locations\": {}} -->\n",
            "file_path": "polaris/src/rubrik/physicalhost/proto/physicalhost.proto",
            "line_number": 63,
            "diff_hunk": "@@ -53,11 +50,43 @@ message EchoReply {\n   string reply = 1;\n }\n \n+// Host details for secondary registration.\n+message SecondaryRegisterHostInput {\n+  // The host FID (unique identifier).\n+  string host_fid = 1 [(api.graphql_field).requiredness = REQUIRED];\n+\n+  // UUID of the primary cluster where the host currently resides.\n+  string primary_cluster_uuid = 2 [(api.graphql_field).requiredness = REQUIRED];\n+\n+  // Operating system type of the host.\n+  cdmrestservice.HostRegister.HostRegisterOsType os_type = 3;\n+}",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2315105936"
          },
          {
            "author": "ilya-netchitailo",
            "created_at": "2025-09-02T19:40:44Z",
            "body": "Are these the protos being used in the schema? cause the output looks different in terms of comments at least.\r\n\r\nI was going to say here, use `string_to_uuid` transform, but will it even apply?",
            "file_path": "polaris/src/rubrik/physicalhost/proto/physicalhost.proto",
            "line_number": 54,
            "diff_hunk": "@@ -53,11 +50,43 @@ message EchoReply {\n   string reply = 1;\n }\n \n+// Host details for secondary registration.\n+message SecondaryRegisterHostInput {",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2316996506"
          },
          {
            "author": "moht-agrawal-rubrik",
            "created_at": "2025-09-03T02:43:46Z",
            "body": "> Are these the protos being used in the schema\r\n\r\nYes this message proto is being used in the schema. `BulkRegisterSecondaryHostsReq` takes in array of `SecondaryRegisterHostInput`. The former is being used in the rpc.\r\n\r\n> cause the output looks different in terms of comments at least\r\n\r\nDidn't understood this point, which output are we talking about?\r\n\r\n> I was going to say here, use string_to_uuid transform, but will it even apply?\r\n\r\nSeems like a good idea. Why would it not apply? It is part of schema, BulkRegisterSecondaryHostsReq type uses this type.\r\n",
            "file_path": "polaris/src/rubrik/physicalhost/proto/physicalhost.proto",
            "line_number": 54,
            "diff_hunk": "@@ -53,11 +50,43 @@ message EchoReply {\n   string reply = 1;\n }\n \n+// Host details for secondary registration.\n+message SecondaryRegisterHostInput {",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2317616738"
          },
          {
            "author": "moht-agrawal-rubrik",
            "created_at": "2025-09-03T02:52:15Z",
            "body": "why i need to call fetcher for rbac check?",
            "file_path": "polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala",
            "line_number": 36,
            "diff_hunk": "@@ -1,17 +1,243 @@\n package services.physicalhost.rbac\n \n+import authzservice.authzservice.InventorySubHierarchyRootEnum.LINUX_HOST_ROOT\n+import authzservice.authzservice.InventorySubHierarchyRootEnum.WINDOWS_HOST_ROOT\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister.HostRegisterOsType\n+import dal.grpc.UnifiedFeatureFlagService\n+import javax.inject.Inject\n+import models.graphql.AttributedFeatureFlagName\n+import models.graphql.FeatureFlagAttribute\n+import models.graphql.FlagAttribute\n import physicalhost.physicalhost.BulkRegisterSecondaryHostsReq\n import sangria.schema.Context\n import security.UserContext\n-import security.rbac.AdminOrOwnerAccessForDev\n+import security.rbac.And\n+import security.rbac.CustomRbacCheck\n+import security.rbac.CustomRbacCheckResult\n+import security.rbac.MoreRbacChecksNeeded\n+import security.rbac.Operation.AddInventory\n+import security.rbac.Operation.Ctx\n+import security.rbac.Operation.ManageDataSource\n+import security.rbac.Or\n+import security.rbac.RbacCheck\n import security.rbac.RbacPolicy\n \n-class PhysicalHostRbacPoliciesImpl extends PhysicalHostRbacPolicies {\n+class PhysicalHostRbacPoliciesImpl @Inject() (\n+  uffs: UnifiedFeatureFlagService\n+) extends PhysicalHostRbacPolicies {\n   // Add your custom RBAC policies here\n   def bulkRegisterSecondaryHosts(\n     argSupplier: Context[UserContext, _] => BulkRegisterSecondaryHostsReq\n   ): RbacPolicy = {\n-    // TODO(SPARK-572184): Add RBAC policy\n-    RbacPolicy(AdminOrOwnerAccessForDev)\n+    RbacPolicy(\n+      BulkSecondaryRegisterHostRbacCheck(argSupplier, uffs)\n+    )\n+  }",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2317626786"
          },
          {
            "author": "moht-agrawal-rubrik",
            "created_at": "2025-09-03T02:53:48Z",
            "body": "You can't specify \"UNSPECIFIED\" to HostRegisterOsType. Also by default it is automatically taking the *EMPTY_VALUE, I don't think it is required to pass in explicitly. ",
            "file_path": "polaris/src/rubrik/physicalhost/proto/physicalhost.proto",
            "line_number": 63,
            "diff_hunk": "@@ -53,11 +50,43 @@ message EchoReply {\n   string reply = 1;\n }\n \n+// Host details for secondary registration.\n+message SecondaryRegisterHostInput {\n+  // The host FID (unique identifier).\n+  string host_fid = 1 [(api.graphql_field).requiredness = REQUIRED];\n+\n+  // UUID of the primary cluster where the host currently resides.\n+  string primary_cluster_uuid = 2 [(api.graphql_field).requiredness = REQUIRED];\n+\n+  // Operating system type of the host.\n+  cdmrestservice.HostRegister.HostRegisterOsType os_type = 3;\n+}",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2317628330"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T11:51:46Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Update `input` parameter description in `bulkRegisterSecondaryHosts` to: \"The request contains the secondary cluster UUID and the hosts to register.\"**\n\n```diff\n-\t    # The request containing secondary cluster UUID and hosts to register.\n+\t    # The request contains the secondary cluster UUID and the hosts to register.\n\n```\n<details ><summary>More details here</summary><br>The description for the `input` parameter in `bulkRegisterSecondaryHosts` is provided, but it does not follow the grammar rule. The description should use correct grammar. Suggestion: Update the description to \"The request contains the secondary cluster UUID and the hosts to register.\"\n\n```diff\n-\t    # The request containing secondary cluster UUID and hosts to register.\n+\t    # The request contains the secondary cluster UUID and the hosts to register.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 21 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql</code>\n<ul><li>52212 to 52213</li><li>98350 to 98360</li><li>168252 to 168254</li><li>168259 to 168261</li></ul>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql</code>\n<ul><li>10139 to 10142</li><li>37032 to 37033</li><li>37034 to 37036</li><li>37040 to 37041</li><li>69691 to 69693</li><li>69694 to 69696</li><li>69697 to 69699</li><li>118844</li><li>118851 to 118853</li></ul>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>10139 to 10140</li><li>10141 to 10142</li><li>37031</li><li>37032 to 37033</li><li>37035 to 37036</li><li>37038 to 37039</li><li>37040 to 37041</li><li>69697 to 69699</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql\": [[52212, 52213], [98350, 98360], [168252, 168254], [168259, 168261]], \"polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql\": [[10139, 10142], [37032, 37033], [37034, 37036], [37040, 37041], [69691, 69693], [69694, 69696], [69697, 69699], [118844, 118844], [118851, 118853]], \"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[10139, 10140], [10141, 10142], [37031, 37031], [37032, 37033], [37035, 37036], [37038, 37039], [37040, 37041], [69697, 69699]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql",
            "line_number": 17247,
            "diff_hunk": "@@ -17242,7 +17242,9 @@ type Mutation {\n     input: BulkRegisterHostAsyncInput!): BulkRegisterHostAsyncReply!\n \n   # BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n-  bulkRegisterSecondaryHosts: Void\n+  bulkRegisterSecondaryHosts(\n+    # The request containing secondary cluster UUID and hosts to register.\n+    input: BulkRegisterSecondaryHostsInput!): BulkRegisterSecondaryHostsReply!",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318722788"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T11:51:48Z",
            "body": "<h2>POLARIS BACKWARD COMPATIBILITY RULE</h2>\n\n**Add `HOST_REGISTER_OS_TYPE_UNSPECIFIED` as value `0` in `HostRegisterOsType` to ensure default enum clarity.**\n\n```diff\n-    cdmrestservice.HostRegister.HostRegisterOsType os_type = 3;\n+    cdmrestservice.HostRegister.HostRegisterOsType os_type = 3 [(api.graphql_field).default_value = HOSTREGISTER_UNSPECIFIED];\n\n```\n<details ><summary>More details here</summary><br>The `os_type` field in the `SecondaryRegisterHostInput` message does not include a default value for the enum type `cdmrestservice.HostRegister.HostRegisterOsType`. As per guidelines, all enums should have a value for `0` named `<ENUM_TYPE>_UNSPECIFIED` to avoid ambiguity. This should be added in the `HostRegisterOsType` definition.  \n\n```diff\n-    cdmrestservice.HostRegister.HostRegisterOsType os_type = 3;\n+    cdmrestservice.HostRegister.HostRegisterOsType os_type = 3 [(api.graphql_field).default_value = HOSTREGISTER_UNSPECIFIED];\n```\n</details><h2></h2>\n<!-- rule:polaris_backward_compatibility_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/SPARK/pag...](https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2296840439/Guidelines)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"polaris_backward_compatibility_rule\", \"processable\": true, \"contextual_eligible\": true, \"distilled_type\": \"not_distilled\", \"other_locations\": {}} -->\n",
            "file_path": "polaris/src/rubrik/physicalhost/proto/physicalhost.proto",
            "line_number": 63,
            "diff_hunk": "@@ -53,11 +50,43 @@ message EchoReply {\n   string reply = 1;\n }\n \n+// Host details for secondary registration.\n+message SecondaryRegisterHostInput {\n+  // The host FID (unique identifier).\n+  string host_fid = 1 [(api.graphql_field).requiredness = REQUIRED];\n+\n+  // UUID of the primary cluster where the host currently resides.\n+  string primary_cluster_uuid = 2 [(api.graphql_field).requiredness = REQUIRED];\n+\n+  // Operating system type of the host.\n+  cdmrestservice.HostRegister.HostRegisterOsType os_type = 3;\n+}",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318722841"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T11:51:50Z",
            "body": "<h2>POLARIS BACKWARD COMPATIBILITY RULE</h2>\n\n**Revert `HIDDEN` tag removal or implement deprecation process to maintain GraphQL endpoint visibility and adhere to guidelines.**\n\n```diff\n-\t    tags: [\n-\t      { type: HIDDEN }\n-\t    ]\n\n```\n<details ><summary>More details here</summary><br>The removal of the `HIDDEN` tag in the `option (api.graphql_method)` for the `BulkRegisterSecondaryHosts` endpoint changes its visibility in the GraphQL schema. According to the guidelines, modifications to GraphQL endpoints that affect their visibility should follow a deprecation process to ensure backward compatibility and proper client adaptation. The removal of the `HIDDEN` tag should be done cautiously, and documentation should include a note regarding this change for developers relying on the endpoint.  \n\nConsider reverting this change or implementing a deprecation process for the `HIDDEN` tag to ensure alignment with guidelines.  \n```diff\n-\t    tags: [\n-\t      { type: HIDDEN }\n-\t    ]\n```\n</details><h2></h2>\n<!-- rule:polaris_backward_compatibility_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/SPARK/pag...](https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2296840439/Guidelines)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"polaris_backward_compatibility_rule\", \"processable\": true, \"contextual_eligible\": true, \"distilled_type\": \"not_distilled\", \"other_locations\": {}} -->\n",
            "file_path": "polaris/src/rubrik/physicalhost/proto/physicalhost.proto",
            "line_number": 34,
            "diff_hunk": "@@ -23,16 +24,12 @@ service PhysicalHost {\n     }\n   };\n \n-  // TODO(SPARK-572184): Implement BulkRegisterSecondaryHosts\n-\n   // BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n+  // @param input The request containing secondary cluster UUID and hosts to register.\n   rpc BulkRegisterSecondaryHosts (BulkRegisterSecondaryHostsReq) returns (BulkRegisterSecondaryHostsReply) {\n     option (api.graphql_method) = {\n       type: MUTATION\n       name: \"bulkRegisterSecondaryHosts\"\n-      tags: [\n-        { type: HIDDEN }\n-      ]\n     };\n   }",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318722924"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T11:51:52Z",
            "body": "<h2>RSC ANTI PATTERN GITHUB RULE</h2>\n\n**Construct `BulkSecondaryRegisterHostRbacCheck` checks concurrently instead of using sequence comprehensions to avoid sequential RBAC execution.**\n\n```diff\n-\t        val primaryClusterChecks =\n-\t          primaryClusterUuids.map {\n-\t            primaryClusterUuid =>\n-\t              val hostsForCluster =\n-\t                req.hosts.filter(_.primaryClusterUuid == primaryClusterUuid)\n-\t              RbacCheck(\n-\t                ManageDataSource,\n-\t                _ => hostsForCluster.map(_.hostFid),\n-\t                clusterIdsOpt = _ => Some(Seq(primaryClusterUuid))\n-\t              )\n-\t          }\n-\t        val allChecks = secondaryClusterCheck +: primaryClusterChecks\n+\t        val primaryClusterChecksFutures = primaryClusterUuids.map {\n+\t          primaryClusterUuid =>\n+\t            Future {\n+\t              val hostsForCluster =\n+\t                req.hosts.filter(_.primaryClusterUuid == primaryClusterUuid)\n+\t              RbacCheck(\n+\t                ManageDataSource,\n+\t                _ => hostsForCluster.map(_.hostFid),\n+\t                clusterIdsOpt = _ => Some(Seq(primaryClusterUuid))\n+\t              )\n+\t            }\n+\t        }\n+\t\n+\t        val combinedCheckFuture = for {\n+\t          secondaryCheck <- Future.successful(secondaryClusterCheck)\n+\t          primaryClusterChecks <- Future.sequence(primaryClusterChecksFutures)\n+\t        } yield {\n+\t          secondaryCheck +: primaryClusterChecks.reduce(And(_, _))\n+\t        }\n+\t\n+\t        combinedCheckFuture.map(MoreRbacChecksNeeded)\n\n```\n<details ><summary>More details here</summary><br>The `BulkSecondaryRegisterHostRbacCheck` implementation uses sequence comprehensions for `primaryClusterChecks`, which might introduce sequential execution for RBAC checks. Consider constructing individual checks concurrently and combining them afterward.\n```diff\n-\t        val primaryClusterChecks =\n-\t          primaryClusterUuids.map {\n-\t            primaryClusterUuid =>\n-\t              val hostsForCluster =\n-\t                req.hosts.filter(_.primaryClusterUuid == primaryClusterUuid)\n-\t              RbacCheck(\n-\t                ManageDataSource,\n-\t                _ => hostsForCluster.map(_.hostFid),\n-\t                clusterIdsOpt = _ => Some(Seq(primaryClusterUuid))\n-\t              )\n-\t          }\n-\t        val allChecks = secondaryClusterCheck +: primaryClusterChecks\n+\t        val primaryClusterChecksFutures = primaryClusterUuids.map {\n+\t          primaryClusterUuid =>\n+\t            Future {\n+\t              val hostsForCluster =\n+\t                req.hosts.filter(_.primaryClusterUuid == primaryClusterUuid)\n+\t              RbacCheck(\n+\t                ManageDataSource,\n+\t                _ => hostsForCluster.map(_.hostFid),\n+\t                clusterIdsOpt = _ => Some(Seq(primaryClusterUuid))\n+\t              )\n+\t            }\n+\t        }\n+\t\n+\t        val combinedCheckFuture = for {\n+\t          secondaryCheck <- Future.successful(secondaryClusterCheck)\n+\t          primaryClusterChecks <- Future.sequence(primaryClusterChecksFutures)\n+\t        } yield {\n+\t          secondaryCheck +: primaryClusterChecks.reduce(And(_, _))\n+\t        }\n+\t\n+\t        combinedCheckFuture.map(MoreRbacChecksNeeded)\n```\n</details><h2></h2>\n<!-- rule:rsc_anti_pattern_github_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/SPARK/pag...](https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/3606118517/Sequential+chaining+of+Futures+in+API+Server)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"rsc_anti_pattern_github_rule\", \"processable\": true, \"contextual_eligible\": true, \"distilled_type\": \"not_distilled\", \"other_locations\": {}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala",
            "line_number": 239,
            "diff_hunk": "@@ -1,17 +1,243 @@\n package services.physicalhost.rbac\n \n+import authzservice.authzservice.InventorySubHierarchyRootEnum.LINUX_HOST_ROOT\n+import authzservice.authzservice.InventorySubHierarchyRootEnum.WINDOWS_HOST_ROOT\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister.HostRegisterOsType\n+import dal.grpc.UnifiedFeatureFlagService\n+import javax.inject.Inject\n+import models.graphql.AttributedFeatureFlagName\n+import models.graphql.FeatureFlagAttribute\n+import models.graphql.FlagAttribute\n import physicalhost.physicalhost.BulkRegisterSecondaryHostsReq\n import sangria.schema.Context\n import security.UserContext\n-import security.rbac.AdminOrOwnerAccessForDev\n+import security.rbac.And\n+import security.rbac.CustomRbacCheck\n+import security.rbac.CustomRbacCheckResult\n+import security.rbac.MoreRbacChecksNeeded\n+import security.rbac.Operation.AddInventory\n+import security.rbac.Operation.Ctx\n+import security.rbac.Operation.ManageDataSource\n+import security.rbac.Or\n+import security.rbac.RbacCheck\n import security.rbac.RbacPolicy\n \n-class PhysicalHostRbacPoliciesImpl extends PhysicalHostRbacPolicies {\n+class PhysicalHostRbacPoliciesImpl @Inject() (\n+  uffs: UnifiedFeatureFlagService\n+) extends PhysicalHostRbacPolicies {\n   // Add your custom RBAC policies here\n   def bulkRegisterSecondaryHosts(\n     argSupplier: Context[UserContext, _] => BulkRegisterSecondaryHostsReq\n   ): RbacPolicy = {\n-    // TODO(SPARK-572184): Add RBAC policy\n-    RbacPolicy(AdminOrOwnerAccessForDev)\n+    RbacPolicy(\n+      BulkSecondaryRegisterHostRbacCheck(argSupplier, uffs)\n+    )\n+  }\n+\n+  // TODO SPARK-283757 Fix RbacPolicy to use list of objects instead of\n+  //  multiple RBACChecks for each object.\n+  private case class BulkRegisterHostRbacCheck(\n+    clusterUuid: Ctx => String,\n+    hosts: Ctx => Seq[HostRegister]\n+  ) extends CustomRbacCheck {\n+    override def doRbacCheck(ctx: Ctx): CustomRbacCheckResult = {\n+      val hostRoots: Seq[String] =\n+        mapHostsToOsType(hosts, clusterUuid(ctx), ctx)\n+      // iterate over all hosts and check if they are linux or windows\n+      // if they are linux or windows, check if the user has the right to\n+      // manage the datasource\n+      val linuxHostRoots: Seq[String] =\n+        hostRoots.filter(\n+          _ == LINUX_HOST_ROOT.name\n+        )\n+      val windowsHostRoots: Seq[String] =\n+        hostRoots.filter(\n+          _ == WINDOWS_HOST_ROOT.name\n+        )\n+\n+      // If linuxHostRoots and windowsHostRoots both are empty,\n+      // then check access on\n+      // OR of Manage Data Source on linux and windows host roots\n+      (linuxHostRoots.nonEmpty, windowsHostRoots.nonEmpty) match {\n+        case (false, false) => {\n+          MoreRbacChecksNeeded(\n+            Or(\n+              RbacCheck(\n+                ManageDataSource,\n+                _ => Seq(LINUX_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+              RbacCheck(\n+                ManageDataSource,\n+                _ => Seq(WINDOWS_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+              And(\n+                RbacCheck(\n+                  AddInventory,\n+                  _ => Seq(LINUX_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+                RbacCheck(\n+                  AddInventory,\n+                  _ => Seq(WINDOWS_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+              )\n+            )\n+          )\n+        }\n+        // If linuxHostRoots and windowsHostRoots both are non-empty, then check\n+        // access on AND of Manage Data Source on linux and windows host roots\n+        case (true, true) => {\n+          MoreRbacChecksNeeded(\n+            Or(\n+              And(\n+                RbacCheck(\n+                  ManageDataSource,\n+                  _ => Seq(LINUX_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+                RbacCheck(\n+                  ManageDataSource,\n+                  _ => Seq(WINDOWS_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+              ),\n+              And(\n+                RbacCheck(\n+                  AddInventory,\n+                  _ => Seq(LINUX_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+                RbacCheck(\n+                  AddInventory,\n+                  _ => Seq(WINDOWS_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+              )\n+            )\n+          )\n+        }\n+        case (true, false) => {\n+          MoreRbacChecksNeeded(\n+            Or(\n+              RbacCheck(\n+                ManageDataSource,\n+                _ => Seq(LINUX_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+              RbacCheck(\n+                AddInventory,\n+                _ => Seq(LINUX_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+            )\n+          )\n+        }\n+        case (false, true) => {\n+          MoreRbacChecksNeeded(\n+            Or(\n+              RbacCheck(\n+                ManageDataSource,\n+                _ => Seq(WINDOWS_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+              RbacCheck(\n+                AddInventory,\n+                _ => Seq(WINDOWS_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+            )\n+          )\n+        }\n+      }\n+    }\n+  }\n+\n+  // A function that takes a Seq of HostRegister and filters it based on\n+  // osType of hosts\n+  private def mapHostsToOsType(\n+    hosts: Ctx => Seq[HostRegister],\n+    clusterUuid: String,\n+    ctx: Ctx\n+  ): Seq[String] = {\n+    val isRegisterHostOsTypeEnabled =\n+      uffs.isFeatureFlagTrue(\n+        ctx.ctx,\n+        AttributedFeatureFlagName.REGISTER_HOST_OS_TYPE_ENABLED.toString,\n+        Seq(\n+          FeatureFlagAttribute(\n+            FlagAttribute.CLUSTER_UUID,\n+            clusterUuid\n+          )\n+        )\n+      )\n+\n+    if (isRegisterHostOsTypeEnabled) {\n+      val hostRootsSeq: Seq[String] =\n+        hosts(ctx).map {\n+          host =>\n+            val osType = host.osType\n+            val hostRoot =\n+              Some(osType) match {\n+                case Some(HostRegisterOsType.HOST_REGISTER_OS_TYPE_LINUX) =>\n+                  LINUX_HOST_ROOT.name\n+                case Some(HostRegisterOsType.HOST_REGISTER_OS_TYPE_WINDOWS) =>\n+                  WINDOWS_HOST_ROOT.name\n+                case _ => \"\"\n+              }\n+            hostRoot\n+        }\n+      hostRootsSeq\n+    } else {\n+      Seq.empty\n+    }\n+  }\n+\n+  private case class BulkSecondaryRegisterHostRbacCheck(\n+    argSupplier: Context[UserContext, _] => BulkRegisterSecondaryHostsReq,\n+    uffs: UnifiedFeatureFlagService\n+  ) extends CustomRbacCheck {\n+    override def doRbacCheck(\n+      ctx: Context[UserContext, _]\n+    ): CustomRbacCheckResult = {\n+      val req = argSupplier(ctx)\n+      val primaryClusterUuids = req.hosts.map(_.primaryClusterUuid).distinct\n+\n+      // Secondary cluster check: Use the reusable BulkRegisterHostRbacCheck\n+      // class\n+      val secondaryClusterCheck =\n+        BulkRegisterHostRbacCheck(\n+          clusterUuid = _ => req.secondaryClusterUuid,\n+          hosts =\n+            ctx =>\n+              argSupplier(ctx).hosts.map(\n+                host =>\n+                  HostRegister()\n+                    .withOsType(host.osType)\n+              )\n+        )\n+\n+      // Primary cluster checks: requires ManageDataSource on individual host FIDs\n+      val primaryClusterChecks =\n+        primaryClusterUuids.map {\n+          primaryClusterUuid =>\n+            val hostsForCluster =\n+              req.hosts.filter(_.primaryClusterUuid == primaryClusterUuid)\n+            RbacCheck(\n+              ManageDataSource,\n+              _ => hostsForCluster.map(_.hostFid),\n+              clusterIdsOpt = _ => Some(Seq(primaryClusterUuid))\n+            )\n+        }\n+\n+      // Combine all checks with AND logic\n+      val allChecks = secondaryClusterCheck +: primaryClusterChecks\n+      val combinedCheck = allChecks.reduce(And(_, _))\n+",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318723054"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T12:37:11Z",
            "body": "<h2>POLARIS BACKWARD COMPATIBILITY RULE</h2>\n\n**Retain `tags: [{ type: HIDDEN }]` in `api.graphql_method` to prevent unintentional exposure of the GraphQL endpoint.**\n\n```diff\n+\t    option (api.graphql_method) = {\n+\t      type: MUTATION\n+\t      name: \"bulkRegisterSecondaryHosts\"\n+\t      tags: [\n+\t        { type: HIDDEN }\n+\t      ]\n+\t    };\n\n```\n<details ><summary>More details here</summary><br>The `BulkRegisterSecondaryHosts` method has been updated, but the removal of the `tags: [{ type: HIDDEN }]` option from the `api.graphql_method` is not addressed. As per the guidelines, changes to the visibility of GraphQL methods must be carefully considered to avoid exposing endpoints prematurely or unintentionally. If the endpoint is meant to remain hidden, the `tags: [{ type: HIDDEN }]` option should be retained.  \n\n```diff\n+\t    option (api.graphql_method) = {\n+\t      type: MUTATION\n+\t      name: \"bulkRegisterSecondaryHosts\"\n+\t      tags: [\n+\t        { type: HIDDEN }\n+\t      ]\n+\t    };\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/physicalhost/proto/physicalhost.proto</code>\n<ul><li>53 to 63</li></ul></details>\n<h2></h2>\n<!-- rule:polaris_backward_compatibility_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/SPARK/pag...](https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2296840439/Guidelines)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"polaris_backward_compatibility_rule\", \"processable\": true, \"contextual_eligible\": true, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/physicalhost/proto/physicalhost.proto\": [[53, 63]]}} -->\n",
            "file_path": "polaris/src/rubrik/physicalhost/proto/physicalhost.proto",
            "line_number": 35,
            "diff_hunk": "@@ -23,16 +24,12 @@ service PhysicalHost {\n     }\n   };\n \n-  // TODO(SPARK-572184): Implement BulkRegisterSecondaryHosts\n-\n   // BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n+  // @param input The request containing secondary cluster UUID and hosts to register.\n   rpc BulkRegisterSecondaryHosts (BulkRegisterSecondaryHostsReq) returns (BulkRegisterSecondaryHostsReply) {\n     option (api.graphql_method) = {\n       type: MUTATION\n       name: \"bulkRegisterSecondaryHosts\"\n-      tags: [\n-        { type: HIDDEN }\n-      ]\n     };\n   }\n ",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318838482"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T12:37:13Z",
            "body": "<h2>RSC ANTI PATTERN GITHUB RULE</h2>\n\n**Avoid `Await.result` and `Await.ready`; use Future combinators (`map`, `flatMap`, `for-yield`) for non-blocking asynchronous execution.**\n\n```diff\n-      override def doRbacCheck(ctx: Ctx): CustomRbacCheckResult = {\n-        val hostRoots: Seq[String] =\n-          mapHostsToOsType(hosts, clusterUuid(ctx), ctx)\n+      override def doRbacCheck(ctx: Ctx): CustomRbacCheckResult = {\n+        mapHostsToOsType(hosts, clusterUuid(ctx), ctx).map { hostRoots =>\n\n```\n<details ><summary>More details here</summary><br>Using `Await.result` or `Await.ready` is discouraged as per the Confluence Rule. Prefer using Future combinators like `map`, `flatMap`, or `for-yield`. This ensures non-blocking and asynchronous execution.  \n```diff\n-      override def doRbacCheck(ctx: Ctx): CustomRbacCheckResult = {\n-        val hostRoots: Seq[String] =\n-          mapHostsToOsType(hosts, clusterUuid(ctx), ctx)\n+      override def doRbacCheck(ctx: Ctx): CustomRbacCheckResult = {\n+        mapHostsToOsType(hosts, clusterUuid(ctx), ctx).map { hostRoots =>\n```\n</details><h2></h2>\n<!-- rule:rsc_anti_pattern_github_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/SPARK/pag...](https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/3605495935/Await+in+API+Server)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"rsc_anti_pattern_github_rule\", \"processable\": true, \"contextual_eligible\": true, \"distilled_type\": \"not_distilled\", \"other_locations\": {}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala",
            "line_number": 45,
            "diff_hunk": "@@ -1,17 +1,243 @@\n package services.physicalhost.rbac\n \n+import authzservice.authzservice.InventorySubHierarchyRootEnum.LINUX_HOST_ROOT\n+import authzservice.authzservice.InventorySubHierarchyRootEnum.WINDOWS_HOST_ROOT\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister.HostRegisterOsType\n+import dal.grpc.UnifiedFeatureFlagService\n+import javax.inject.Inject\n+import models.graphql.AttributedFeatureFlagName\n+import models.graphql.FeatureFlagAttribute\n+import models.graphql.FlagAttribute\n import physicalhost.physicalhost.BulkRegisterSecondaryHostsReq\n import sangria.schema.Context\n import security.UserContext\n-import security.rbac.AdminOrOwnerAccessForDev\n+import security.rbac.And\n+import security.rbac.CustomRbacCheck\n+import security.rbac.CustomRbacCheckResult\n+import security.rbac.MoreRbacChecksNeeded\n+import security.rbac.Operation.AddInventory\n+import security.rbac.Operation.Ctx\n+import security.rbac.Operation.ManageDataSource\n+import security.rbac.Or\n+import security.rbac.RbacCheck\n import security.rbac.RbacPolicy\n \n-class PhysicalHostRbacPoliciesImpl extends PhysicalHostRbacPolicies {\n+class PhysicalHostRbacPoliciesImpl @Inject() (\n+  uffs: UnifiedFeatureFlagService\n+) extends PhysicalHostRbacPolicies {\n   // Add your custom RBAC policies here\n   def bulkRegisterSecondaryHosts(\n     argSupplier: Context[UserContext, _] => BulkRegisterSecondaryHostsReq\n   ): RbacPolicy = {\n-    // TODO(SPARK-572184): Add RBAC policy\n-    RbacPolicy(AdminOrOwnerAccessForDev)\n+    RbacPolicy(\n+      BulkSecondaryRegisterHostRbacCheck(argSupplier, uffs)\n+    )\n+  }\n+\n+  // TODO SPARK-283757 Fix RbacPolicy to use list of objects instead of\n+  //  multiple RBACChecks for each object.\n+  private case class BulkRegisterHostRbacCheck(\n+    clusterUuid: Ctx => String,\n+    hosts: Ctx => Seq[HostRegister]\n+  ) extends CustomRbacCheck {\n+    override def doRbacCheck(ctx: Ctx): CustomRbacCheckResult = {\n+      val hostRoots: Seq[String] =",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318838578"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:21:54Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure `input` field description in `bulkRegisterSecondaryHosts` uses sentence case and proper grammar for clarity.**\n\n```diff\n-\t    # The request containing secondary cluster UUID and hosts to register.\n+\t    # The request contains the secondary cluster UUID and hosts to register.\n\n```\n<details ><summary>More details here</summary><br>The description for the `input` field in `bulkRegisterSecondaryHosts` is missing sentence case adherence and proper grammar. The description should begin with a capitalized word and use correct grammar to ensure clarity.  \n\n```diff\n-\t    # The request containing secondary cluster UUID and hosts to register.\n+\t    # The request contains the secondary cluster UUID and hosts to register.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 18 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql</code>\n<ul><li>52208 to 52213</li><li>52215 to 52218</li><li>98350 to 98360</li><li>98857 to 98859</li><li>168252 to 168262</li></ul>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql</code>\n<ul><li>10140 to 10142</li><li>37032 to 37033</li><li>37035 to 37036</li><li>37040 to 37041</li><li>69691 to 69700</li><li>70195 to 70199</li><li>118852 to 118853</li></ul>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>10139 to 10142</li><li>69691 to 69693</li><li>69694 to 69696</li><li>69697 to 69699</li><li>118845 to 118846</li><li>118851 to 118853</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql\": [[52208, 52213], [52215, 52218], [98350, 98360], [98857, 98859], [168252, 168262]], \"polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql\": [[10140, 10142], [37032, 37033], [37035, 37036], [37040, 37041], [69691, 69700], [70195, 70199], [118852, 118853]], \"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[10139, 10142], [69691, 69693], [69694, 69696], [69697, 69699], [118845, 118846], [118851, 118853]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql",
            "line_number": 17250,
            "diff_hunk": "@@ -17242,7 +17242,9 @@ type Mutation {\n     input: BulkRegisterHostAsyncInput!): BulkRegisterHostAsyncReply!\n \n   # BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n-  bulkRegisterSecondaryHosts: Void\n+  bulkRegisterSecondaryHosts(\n+    # The request containing secondary cluster UUID and hosts to register.\n+    input: BulkRegisterSecondaryHostsInput!): BulkRegisterSecondaryHostsReply!\n \n   # BulkRestoreM365BackupStorageObjects triggers the restore for the M365 Backup\n   # Storage Group workloads.",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318966891"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:21:57Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure `activeDirectoryAdditionalInfo` descriptions are in sentence case with proper grammar.**\n\n```diff\n-\t  # v9.3+: Additional Active Directory info for the host if applicable.\n+\t  # v9.3+: Additional Active Directory information for the host, if applicable.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `activeDirectoryAdditionalInfo` must be in sentence case and use correct grammar. Suggested fix:  \n```diff\n-\t  # v9.3+: Additional Active Directory info for the host if applicable.\n+\t  # v9.3+: Additional Active Directory information for the host, if applicable.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68937,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318966986"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:21:59Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Use sentence case for `compressionEnabled` descriptions.**\n\n```diff\n-\t  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+\t  # v5.3+: Indicates whether compression is enabled while transferring data between the host and the Rubrik cluster.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `compressionEnabled` must be in sentence case. Suggested fix:  \n```diff\n-\t  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+\t  # v5.3+: Indicates whether compression is enabled while transferring data between the host and the Rubrik cluster.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68947,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318967090"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:02Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Fix grammar in `hostDomainId` and `hostDomainName` descriptions.**\n\n```diff\n-\t  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+\t  # v9.2+: (DEPRECATED) This field is deprecated in favor of activeDirectoryAdditionalInfo. ID of the Active Directory domain if the Windows host has a domain controller hosted.\n\n-\t  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+\t  # v9.2+: (DEPRECATED) This field is deprecated in favor of activeDirectoryAdditionalInfo. Specifies the name of the Active Directory domain.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `hostDomainId` and `hostDomainName` must use correct grammar. Suggested fix:  \n```diff\n-\t  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+\t  # v9.2+: (DEPRECATED) This field is deprecated in favor of activeDirectoryAdditionalInfo. ID of the Active Directory domain if the Windows host has a domain controller hosted.\n\n-\t  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+\t  # v9.2+: (DEPRECATED) This field is deprecated in favor of activeDirectoryAdditionalInfo. Specifies the name of the Active Directory domain.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68957,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318967225"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:05Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Fix grammar in `hostVfdDriverState` descriptions.**\n\n```diff\n-\t  # Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+\t  # Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequired' when the driver is present but requires a restart of the Windows host to function.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `hostVfdDriverState` must use correct grammar. Suggested fix:  \n```diff\n-\t  # Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+\t  # Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequired' when the driver is present but requires a restart of the Windows host to function.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68963,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318967340"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:07Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure descriptions for `hostVfdEnabled` use correct grammar.**\n\n```diff\n-\t  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+\t  # Specifies whether VFD-based volume backups are enabled on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `hostVfdEnabled` must use correct grammar. Suggested fix:  \n```diff\n-\t  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+\t  # Specifies whether VFD-based volume backups are enabled on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68967,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318967432"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:09Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure `isOracleHost` descriptions use correct grammar. Suggested fix:**\n\n```diff\n-\t  # Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+\t  # Specifies whether the host is an Oracle host. This indicates whether Oracle discovery fields should be displayed in the UI.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `isOracleHost` must use correct grammar. Suggested fix:  \n```diff\n-\t  # Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+\t  # Specifies whether the host is an Oracle host. This indicates whether Oracle discovery fields should be displayed in the UI.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68973,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318967557"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:12Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Use sentence case for `isRefreshPaused` descriptions.**\n\n```diff\n-\t  # Specifies whether the refresh of host metadata for this host is paused.\n+\t  # Specifies whether the refresh of host metadata is paused for this host.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `isRefreshPaused` must be in sentence case. Suggested fix:  \n```diff\n-\t  # Specifies whether the refresh of host metadata for this host is paused.\n+\t  # Specifies whether the refresh of host metadata is paused for this host.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68977,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean\n+\n+  # Supported in v9.0+\n+  # Specifies whether the refresh of host metadata for this host is paused.\n+  isRefreshPaused: Boolean",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318967703"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:14Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure `mssqlCbtDriverInstalled` descriptions use correct grammar. Apply suggested fixes.**\n\n```diff\n-\t  # Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+\t  # Indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `mssqlCbtDriverInstalled` must use correct grammar. Suggested fix:  \n```diff\n-\t  # Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+\t  # Indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68987,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean\n+\n+  # Supported in v9.0+\n+  # Specifies whether the refresh of host metadata for this host is paused.\n+  isRefreshPaused: Boolean\n+\n+  # Required. Supported in v5.0+\n+  # A relic host is deleted, but still may have snapshots associated with its children (e.g. Fileset).\n+  isRelic: Boolean!\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v5.2: Boolean value that indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v5.3: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v6.0+: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+  mssqlCbtDriverInstalled: Boolean!",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318967784"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:16Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure `mssqlSddCertificateId` descriptions use correct grammar. Apply suggested fixes.**\n\n```diff\n-\t  # Specifies the certificate ID corresponding to the public key certificate of the CA that signed the SQL server certificate for Sensitive Data Discovery.\n+\t  # Specifies the certificate ID for the public key certificate of the CA that signed the SQL Server certificate for sensitive data discovery.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `mssqlSddCertificateId` must use correct grammar. Suggested fix:  \n```diff\n-\t  # Specifies the certificate ID corresponding to the public key certificate of the CA that signed the SQL server certificate for Sensitive Data Discovery.\n+\t  # Specifies the certificate ID for the public key certificate of the CA that signed the SQL Server certificate for sensitive data discovery.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68991,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean\n+\n+  # Supported in v9.0+\n+  # Specifies whether the refresh of host metadata for this host is paused.\n+  isRefreshPaused: Boolean\n+\n+  # Required. Supported in v5.0+\n+  # A relic host is deleted, but still may have snapshots associated with its children (e.g. Fileset).\n+  isRelic: Boolean!\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v5.2: Boolean value that indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v5.3: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v6.0+: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+  mssqlCbtDriverInstalled: Boolean!\n+\n+  # Supported in v9.2+\n+  # Specifies the certificate ID corresponding to the public key certificate of the CA that signed the SQL server certificate for Sensitive Data Discovery.\n+  mssqlSddCertificateId: String",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318967880"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:18Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Use sentence case for `mssqlSddUsername` descriptions.**\n\n```diff\n-\t  # Specifies the username configured for the SQL server instance for sensitive data discovery.\n+\t  # Specifies the username configured for the SQL Server instance for sensitive data discovery.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `mssqlSddUsername` must be in sentence case. Suggested fix:  \n```diff\n-\t  # Specifies the username configured for the SQL server instance for sensitive data discovery.\n+\t  # Specifies the username configured for the SQL Server instance for sensitive data discovery.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68995,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean\n+\n+  # Supported in v9.0+\n+  # Specifies whether the refresh of host metadata for this host is paused.\n+  isRefreshPaused: Boolean\n+\n+  # Required. Supported in v5.0+\n+  # A relic host is deleted, but still may have snapshots associated with its children (e.g. Fileset).\n+  isRelic: Boolean!\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v5.2: Boolean value that indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v5.3: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v6.0+: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+  mssqlCbtDriverInstalled: Boolean!\n+\n+  # Supported in v9.2+\n+  # Specifies the certificate ID corresponding to the public key certificate of the CA that signed the SQL server certificate for Sensitive Data Discovery.\n+  mssqlSddCertificateId: String\n+\n+  # Supported in v9.2+\n+  # Specifies the username configured for the SQL server instance for sensitive data discovery.\n+  mssqlSddUsername: String",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318967964"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:20Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure `oracleQueryUser` descriptions use correct grammar. Apply suggested fix.**\n\n```diff\n-\t  # Specifies the Oracle username for an account with query privileges.\n+\t  # Specifies the Oracle username for an account that has query privileges.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `oracleQueryUser` must use correct grammar. Suggested fix:  \n```diff\n-\t  # Specifies the Oracle username for an account with query privileges.\n+\t  # Specifies the Oracle username for an account that has query privileges.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 68999,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean\n+\n+  # Supported in v9.0+\n+  # Specifies whether the refresh of host metadata for this host is paused.\n+  isRefreshPaused: Boolean\n+\n+  # Required. Supported in v5.0+\n+  # A relic host is deleted, but still may have snapshots associated with its children (e.g. Fileset).\n+  isRelic: Boolean!\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v5.2: Boolean value that indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v5.3: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v6.0+: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+  mssqlCbtDriverInstalled: Boolean!\n+\n+  # Supported in v9.2+\n+  # Specifies the certificate ID corresponding to the public key certificate of the CA that signed the SQL server certificate for Sensitive Data Discovery.\n+  mssqlSddCertificateId: String\n+\n+  # Supported in v9.2+\n+  # Specifies the username configured for the SQL server instance for sensitive data discovery.\n+  mssqlSddUsername: String\n+\n+  # Supported in v5.0+\n+  # Specifies the Oracle username for an account with query privileges.\n+  oracleQueryUser: String",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318968058"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:22Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure descriptions for `oracleSddUsername` use correct grammar.**\n\n```diff\n-\t  # Specifies the username configured for the Oracle host for sensitive data discovery.\n+\t  # Specifies the username that is configured for the Oracle host for sensitive data discovery.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `oracleSddUsername` must use correct grammar. Suggested fix:  \n```diff\n-\t  # Specifies the username configured for the Oracle host for sensitive data discovery.\n+\t  # Specifies the username that is configured for the Oracle host for sensitive data discovery.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 69003,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean\n+\n+  # Supported in v9.0+\n+  # Specifies whether the refresh of host metadata for this host is paused.\n+  isRefreshPaused: Boolean\n+\n+  # Required. Supported in v5.0+\n+  # A relic host is deleted, but still may have snapshots associated with its children (e.g. Fileset).\n+  isRelic: Boolean!\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v5.2: Boolean value that indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v5.3: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v6.0+: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+  mssqlCbtDriverInstalled: Boolean!\n+\n+  # Supported in v9.2+\n+  # Specifies the certificate ID corresponding to the public key certificate of the CA that signed the SQL server certificate for Sensitive Data Discovery.\n+  mssqlSddCertificateId: String\n+\n+  # Supported in v9.2+\n+  # Specifies the username configured for the SQL server instance for sensitive data discovery.\n+  mssqlSddUsername: String\n+\n+  # Supported in v5.0+\n+  # Specifies the Oracle username for an account with query privileges.\n+  oracleQueryUser: String\n+\n+  # Supported in v9.3+\n+  # Specifies the username configured for the Oracle host for sensitive data discovery.\n+  oracleSddUsername: String",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318968152"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:24Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure `oracleSddWalletPath` descriptions use correct grammar. Suggested fix: [insert specific grammar correction].**\n\n```diff\n-\t  # Specifies the wallet path on the Oracle host which is used to authenticate remote connections to oracle databases during Sensitive Data Discovery.\n+\t  # Specifies the wallet path on the Oracle host used to authenticate remote connections to Oracle databases during sensitive data discovery.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `oracleSddWalletPath` must use correct grammar. Suggested fix:  \n```diff\n-\t  # Specifies the wallet path on the Oracle host which is used to authenticate remote connections to oracle databases during Sensitive Data Discovery.\n+\t  # Specifies the wallet path on the Oracle host used to authenticate remote connections to Oracle databases during sensitive data discovery.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 69007,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean\n+\n+  # Supported in v9.0+\n+  # Specifies whether the refresh of host metadata for this host is paused.\n+  isRefreshPaused: Boolean\n+\n+  # Required. Supported in v5.0+\n+  # A relic host is deleted, but still may have snapshots associated with its children (e.g. Fileset).\n+  isRelic: Boolean!\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v5.2: Boolean value that indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v5.3: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v6.0+: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+  mssqlCbtDriverInstalled: Boolean!\n+\n+  # Supported in v9.2+\n+  # Specifies the certificate ID corresponding to the public key certificate of the CA that signed the SQL server certificate for Sensitive Data Discovery.\n+  mssqlSddCertificateId: String\n+\n+  # Supported in v9.2+\n+  # Specifies the username configured for the SQL server instance for sensitive data discovery.\n+  mssqlSddUsername: String\n+\n+  # Supported in v5.0+\n+  # Specifies the Oracle username for an account with query privileges.\n+  oracleQueryUser: String\n+\n+  # Supported in v9.3+\n+  # Specifies the username configured for the Oracle host for sensitive data discovery.\n+  oracleSddUsername: String\n+\n+  # Supported in v9.3+\n+  # Specifies the wallet path on the Oracle host which is used to authenticate remote connections to oracle databases during Sensitive Data Discovery.\n+  oracleSddWalletPath: String",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318968248"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:26Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure descriptions for `oracleSepsSettings` use correct grammar; apply suggested fixes.**\n\n```diff\n-\t  # Oracle SEPS settings for the host.\n+\t  # Specifies Oracle SEPS settings for the host.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `oracleSepsSettings` must use correct grammar. Suggested fix:  \n```diff\n-\t  # Oracle SEPS settings for the host.\n+\t  # Specifies Oracle SEPS settings for the host.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 69011,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean\n+\n+  # Supported in v9.0+\n+  # Specifies whether the refresh of host metadata for this host is paused.\n+  isRefreshPaused: Boolean\n+\n+  # Required. Supported in v5.0+\n+  # A relic host is deleted, but still may have snapshots associated with its children (e.g. Fileset).\n+  isRelic: Boolean!\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v5.2: Boolean value that indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v5.3: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v6.0+: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+  mssqlCbtDriverInstalled: Boolean!\n+\n+  # Supported in v9.2+\n+  # Specifies the certificate ID corresponding to the public key certificate of the CA that signed the SQL server certificate for Sensitive Data Discovery.\n+  mssqlSddCertificateId: String\n+\n+  # Supported in v9.2+\n+  # Specifies the username configured for the SQL server instance for sensitive data discovery.\n+  mssqlSddUsername: String\n+\n+  # Supported in v5.0+\n+  # Specifies the Oracle username for an account with query privileges.\n+  oracleQueryUser: String\n+\n+  # Supported in v9.3+\n+  # Specifies the username configured for the Oracle host for sensitive data discovery.\n+  oracleSddUsername: String\n+\n+  # Supported in v9.3+\n+  # Specifies the wallet path on the Oracle host which is used to authenticate remote connections to oracle databases during Sensitive Data Discovery.\n+  oracleSddWalletPath: String\n+\n+  # Supported in v9.4+\n+  # Oracle SEPS settings for the host.\n+  oracleSepsSettings: OracleSepsWalletSettings",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318968331"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:29Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Fix grammar in `oracleSysDbaUser` descriptions.**\n\n```diff\n-\t  # Specifies the Oracle username for an account with sysdba privileges.\n+\t  # Specifies the Oracle username for an account that has sysdba privileges.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `oracleSysDbaUser` must use correct grammar. Suggested fix:  \n```diff\n-\t  # Specifies the Oracle username for an account with sysdba privileges.\n+\t  # Specifies the Oracle username for an account that has sysdba privileges.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 69015,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean\n+\n+  # Supported in v9.0+\n+  # Specifies whether the refresh of host metadata for this host is paused.\n+  isRefreshPaused: Boolean\n+\n+  # Required. Supported in v5.0+\n+  # A relic host is deleted, but still may have snapshots associated with its children (e.g. Fileset).\n+  isRelic: Boolean!\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v5.2: Boolean value that indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v5.3: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v6.0+: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+  mssqlCbtDriverInstalled: Boolean!\n+\n+  # Supported in v9.2+\n+  # Specifies the certificate ID corresponding to the public key certificate of the CA that signed the SQL server certificate for Sensitive Data Discovery.\n+  mssqlSddCertificateId: String\n+\n+  # Supported in v9.2+\n+  # Specifies the username configured for the SQL server instance for sensitive data discovery.\n+  mssqlSddUsername: String\n+\n+  # Supported in v5.0+\n+  # Specifies the Oracle username for an account with query privileges.\n+  oracleQueryUser: String\n+\n+  # Supported in v9.3+\n+  # Specifies the username configured for the Oracle host for sensitive data discovery.\n+  oracleSddUsername: String\n+\n+  # Supported in v9.3+\n+  # Specifies the wallet path on the Oracle host which is used to authenticate remote connections to oracle databases during Sensitive Data Discovery.\n+  oracleSddWalletPath: String\n+\n+  # Supported in v9.4+\n+  # Oracle SEPS settings for the host.\n+  oracleSepsSettings: OracleSepsWalletSettings\n+\n+  # Supported in v5.0+\n+  # Specifies the Oracle username for an account with sysdba privileges.\n+  oracleSysDbaUser: String",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318968444"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T13:22:31Z",
            "body": "<h2>DOCUMENTATION GQL CODING RULE</h2>\n\n**Ensure `shouldMssqlSddThroughRba` descriptions use correct grammar. Apply suggested fixes.**\n\n```diff\n-\t  # A Boolean flag that specifies whether to perform the Data Discovery and Classification data acquisition workflow for SQL Server host through RBA.\n+\t  # A Boolean flag that specifies whether to perform the data discovery and classification data acquisition workflow for the SQL Server host through RBA.\n\n```\n<details ><summary>More details here</summary><br>Descriptions for `shouldMssqlSddThroughRba` must use correct grammar. Suggested fix:  \n```diff\n-\t  # A Boolean flag that specifies whether to perform the Data Discovery and Classification data acquisition workflow for SQL Server host through RBA.\n+\t  # A Boolean flag that specifies whether to perform the data discovery and classification data acquisition workflow for the SQL Server host through RBA.\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql</code>\n<ul><li>68978 to 68981</li></ul></details>\n<h2></h2>\n<!-- rule:documentation_gql_coding_rule -->\n\n\n:page_facing_up: **Source Document**\n_[https://rubrik.atlassian.net/wiki/spaces/EN/pages/...](https://rubrik.atlassian.net/wiki/spaces/EN/pages/4081090617/TechPubs+-+GraphQL+Review+Guidelines+for+Edith+AI+Reviews)_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"documentation_gql_coding_rule\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql\": [[68978, 68981]]}} -->\n",
            "file_path": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
            "line_number": 69019,
            "diff_hunk": "@@ -68912,6 +68930,99 @@ type HostDetail {\n   shouldOracleSddThroughRba: Boolean\n }\n # Supported in v5.0+\n+type HostDetail {\n+  # Supported in v9.2+\n+  # v9.2:\n+  # v9.3+: Additional Active Directory info for the host if applicable.\n+  activeDirectoryAdditionalInfo: ActiveDirectoryAdditionalInfo\n+\n+  # Supported in v5.0-v9.0\n+  # v5.0-v5.2:\n+  # v5.3-v9.0: ID of the Rubrik Backup Service (RBS) installed on the host.\n+  agentId: String\n+\n+  # Supported in v5.0+\n+  # v5.0-v5.2:\n+  # v5.3+: Indicates if compression is enabled while transferring data between the host and the Rubrik cluster.\n+  compressionEnabled: Boolean\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Id of the Active Directory Domain if the windows host has domain controller hosted.\n+  hostDomainId: String\n+\n+  # Supported in v9.0+\n+  # v9.0-v9.1: Specify the name of active directory domain.\n+  # v9.2+: (DEPRECATED) This field is deprecate in favor of activeDirectoryAdditionalInfo. Specify the name of active directory domain.\n+  hostDomainName: String\n+  hostSummary: HostSummary\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v6.0: Specifies the installation status of the VFD driver on a Windows host. The value is 'NotInstalled' when the driver is absent. The value is 'Installed' when the driver is present. The value is 'RestartRequred' when the driver is present but requires a restart of the Windows host in order to function.\n+  # v7.0+: Specifies the installation status of the VFD driver on a Windows host. The value is - 'NotInstalled' when the driver is absent. - 'Installed' when the driver is present. - 'InstalledButRestartRequred' when the driver is present but requires a restart of the Windows host. - 'InstalledButTwoRestartsRequred' when the driver is updated but requires two restarts of the Window host. - 'UninstalledButRestartRequired' when the driver is uninstalled but requires a restart of the Windows host to remove the driver.\n+  hostVfdDriverState: HostVfdState!\n+\n+  # Supported in v5.0+\n+  # Specifies the status of VFD-based volume backups on Windows hosts. The value is 'Enabled' when VFD-based volume backups are enabled. The value is 'Disabled' when VFD-based volume backups are disabled.\n+  hostVfdEnabled: HostVfdInstallConfig!\n+\n+  # Supported in v5.2+\n+  # v5.2: Specifies whether the host is an Oracle host. When the host is an Oracle host, the UI displays the Oracle discovery fields.\n+  # v5.3: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  # v6.0+: Specifies whether this is an Oracle host. This indicates whether to show Oracle discovery fields in the UI.\n+  isOracleHost: Boolean\n+\n+  # Supported in v9.0+\n+  # Specifies whether the refresh of host metadata for this host is paused.\n+  isRefreshPaused: Boolean\n+\n+  # Required. Supported in v5.0+\n+  # A relic host is deleted, but still may have snapshots associated with its children (e.g. Fileset).\n+  isRelic: Boolean!\n+\n+  # Required. Supported in v5.0+\n+  # v5.0-v5.2: Boolean value that indicates whether the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v5.3: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed\n+  # v6.0+: Indicates if the CBT driver is installed for SQL Server instances on the specified Windows host. Set to true when the CBT driver is installed. Set to false when the CBT driver is not installed.\n+  mssqlCbtDriverInstalled: Boolean!\n+\n+  # Supported in v9.2+\n+  # Specifies the certificate ID corresponding to the public key certificate of the CA that signed the SQL server certificate for Sensitive Data Discovery.\n+  mssqlSddCertificateId: String\n+\n+  # Supported in v9.2+\n+  # Specifies the username configured for the SQL server instance for sensitive data discovery.\n+  mssqlSddUsername: String\n+\n+  # Supported in v5.0+\n+  # Specifies the Oracle username for an account with query privileges.\n+  oracleQueryUser: String\n+\n+  # Supported in v9.3+\n+  # Specifies the username configured for the Oracle host for sensitive data discovery.\n+  oracleSddUsername: String\n+\n+  # Supported in v9.3+\n+  # Specifies the wallet path on the Oracle host which is used to authenticate remote connections to oracle databases during Sensitive Data Discovery.\n+  oracleSddWalletPath: String\n+\n+  # Supported in v9.4+\n+  # Oracle SEPS settings for the host.\n+  oracleSepsSettings: OracleSepsWalletSettings\n+\n+  # Supported in v5.0+\n+  # Specifies the Oracle username for an account with sysdba privileges.\n+  oracleSysDbaUser: String\n+\n+  # Supported in v9.4+\n+  # A Boolean flag that specifies whether to perform the Data Discovery and Classification data acquisition workflow for SQL Server host through RBA.\n+  shouldMssqlSddThroughRba: Boolean",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97449#discussion_r2318968555"
          }
        ]
      },
      "files_changed": [
        {
          "filename": "polaris/src/rubrik/api-server/app/services/physicalhost/rbac/BUILD.bazel",
          "status": "modified",
          "additions": 2,
          "deletions": 0,
          "patch": "@@ -8,6 +8,8 @@ rkscala_library(\n     deps = [\n         \"//rubrik/api-server:app_lib\",\n         \"//rubrik/api-server:external_library_deps\",\n+        \"//rubrik/api-server:proto_deps\",\n         \"//rubrik/api-server/app/services/physicalhost:physicalhost_proto\",\n+        \"//rubrik/common-scala\",\n     ],\n )"
        },
        {
          "filename": "polaris/src/rubrik/api-server/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImpl.scala",
          "status": "modified",
          "additions": 230,
          "deletions": 4,
          "patch": "@@ -1,17 +1,243 @@\n package services.physicalhost.rbac\n \n+import authzservice.authzservice.InventorySubHierarchyRootEnum.LINUX_HOST_ROOT\n+import authzservice.authzservice.InventorySubHierarchyRootEnum.WINDOWS_HOST_ROOT\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister.HostRegisterOsType\n+import dal.grpc.UnifiedFeatureFlagService\n+import javax.inject.Inject\n+import models.graphql.AttributedFeatureFlagName\n+import models.graphql.FeatureFlagAttribute\n+import models.graphql.FlagAttribute\n import physicalhost.physicalhost.BulkRegisterSecondaryHostsReq\n import sangria.schema.Context\n import security.UserContext\n-import security.rbac.AdminOrOwnerAccessForDev\n+import security.rbac.And\n+import security.rbac.CustomRbacCheck\n+import security.rbac.CustomRbacCheckResult\n+import security.rbac.MoreRbacChecksNeeded\n+import security.rbac.Operation.AddInventory\n+import security.rbac.Operation.Ctx\n+import security.rbac.Operation.ManageDataSource\n+import security.rbac.Or\n+import security.rbac.RbacCheck\n import security.rbac.RbacPolicy\n \n-class PhysicalHostRbacPoliciesImpl extends PhysicalHostRbacPolicies {\n+class PhysicalHostRbacPoliciesImpl @Inject() (\n+  uffs: UnifiedFeatureFlagService\n+) extends PhysicalHostRbacPolicies {\n   // Add your custom RBAC policies here\n   def bulkRegisterSecondaryHosts(\n     argSupplier: Context[UserContext, _] => BulkRegisterSecondaryHostsReq\n   ): RbacPolicy = {\n-    // TODO(SPARK-572184): Add RBAC policy\n-    RbacPolicy(AdminOrOwnerAccessForDev)\n+    RbacPolicy(\n+      BulkSecondaryRegisterHostRbacCheck(argSupplier, uffs)\n+    )\n+  }\n+\n+  // TODO SPARK-283757 Fix RbacPolicy to use list of objects instead of\n+  //  multiple RBACChecks for each object.\n+  private case class BulkRegisterHostRbacCheck(\n+    clusterUuid: Ctx => String,\n+    hosts: Ctx => Seq[HostRegister]\n+  ) extends CustomRbacCheck {\n+    override def doRbacCheck(ctx: Ctx): CustomRbacCheckResult = {\n+      val hostRoots: Seq[String] =\n+        mapHostsToOsType(hosts, clusterUuid(ctx), ctx)\n+      // iterate over all hosts and check if they are linux or windows\n+      // if they are linux or windows, check if the user has the right to\n+      // manage the datasource\n+      val linuxHostRoots: Seq[String] =\n+        hostRoots.filter(\n+          _ == LINUX_HOST_ROOT.name\n+        )\n+      val windowsHostRoots: Seq[String] =\n+        hostRoots.filter(\n+          _ == WINDOWS_HOST_ROOT.name\n+        )\n+\n+      // If linuxHostRoots and windowsHostRoots both are empty,\n+      // then check access on\n+      // OR of Manage Data Source on linux and windows host roots\n+      (linuxHostRoots.nonEmpty, windowsHostRoots.nonEmpty) match {\n+        case (false, false) => {\n+          MoreRbacChecksNeeded(\n+            Or(\n+              RbacCheck(\n+                ManageDataSource,\n+                _ => Seq(LINUX_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+              RbacCheck(\n+                ManageDataSource,\n+                _ => Seq(WINDOWS_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+              And(\n+                RbacCheck(\n+                  AddInventory,\n+                  _ => Seq(LINUX_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+                RbacCheck(\n+                  AddInventory,\n+                  _ => Seq(WINDOWS_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+              )\n+            )\n+          )\n+        }\n+        // If linuxHostRoots and windowsHostRoots both are non-empty, then check\n+        // access on AND of Manage Data Source on linux and windows host roots\n+        case (true, true) => {\n+          MoreRbacChecksNeeded(\n+            Or(\n+              And(\n+                RbacCheck(\n+                  ManageDataSource,\n+                  _ => Seq(LINUX_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+                RbacCheck(\n+                  ManageDataSource,\n+                  _ => Seq(WINDOWS_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+              ),\n+              And(\n+                RbacCheck(\n+                  AddInventory,\n+                  _ => Seq(LINUX_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+                RbacCheck(\n+                  AddInventory,\n+                  _ => Seq(WINDOWS_HOST_ROOT.name),\n+                  clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+                ),\n+              )\n+            )\n+          )\n+        }\n+        case (true, false) => {\n+          MoreRbacChecksNeeded(\n+            Or(\n+              RbacCheck(\n+                ManageDataSource,\n+                _ => Seq(LINUX_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+              RbacCheck(\n+                AddInventory,\n+                _ => Seq(LINUX_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+            )\n+          )\n+        }\n+        case (false, true) => {\n+          MoreRbacChecksNeeded(\n+            Or(\n+              RbacCheck(\n+                ManageDataSource,\n+                _ => Seq(WINDOWS_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+              RbacCheck(\n+                AddInventory,\n+                _ => Seq(WINDOWS_HOST_ROOT.name),\n+                clusterIdsOpt = ctx => Some(Seq(clusterUuid(ctx))),\n+              ),\n+            )\n+          )\n+        }\n+      }\n+    }\n+  }\n+\n+  // A function that takes a Seq of HostRegister and filters it based on\n+  // osType of hosts\n+  private def mapHostsToOsType(\n+    hosts: Ctx => Seq[HostRegister],\n+    clusterUuid: String,\n+    ctx: Ctx\n+  ): Seq[String] = {\n+    val isRegisterHostOsTypeEnabled =\n+      uffs.isFeatureFlagTrue(\n+        ctx.ctx,\n+        AttributedFeatureFlagName.REGISTER_HOST_OS_TYPE_ENABLED.toString,\n+        Seq(\n+          FeatureFlagAttribute(\n+            FlagAttribute.CLUSTER_UUID,\n+            clusterUuid\n+          )\n+        )\n+      )\n+\n+    if (isRegisterHostOsTypeEnabled) {\n+      val hostRootsSeq: Seq[String] =\n+        hosts(ctx).map {\n+          host =>\n+            val osType = host.osType\n+            val hostRoot =\n+              Some(osType) match {\n+                case Some(HostRegisterOsType.HOST_REGISTER_OS_TYPE_LINUX) =>\n+                  LINUX_HOST_ROOT.name\n+                case Some(HostRegisterOsType.HOST_REGISTER_OS_TYPE_WINDOWS) =>\n+                  WINDOWS_HOST_ROOT.name\n+                case _ => \"\"\n+              }\n+            hostRoot\n+        }\n+      hostRootsSeq\n+    } else {\n+      Seq.empty\n+    }\n+  }\n+\n+  private case class BulkSecondaryRegisterHostRbacCheck(\n+    argSupplier: Context[UserContext, _] => BulkRegisterSecondaryHostsReq,\n+    uffs: UnifiedFeatureFlagService\n+  ) extends CustomRbacCheck {\n+    override def doRbacCheck(\n+      ctx: Context[UserContext, _]\n+    ): CustomRbacCheckResult = {\n+      val req = argSupplier(ctx)\n+      val primaryClusterUuids = req.hosts.map(_.primaryClusterUuid).distinct\n+\n+      // Secondary cluster check: Use the reusable BulkRegisterHostRbacCheck\n+      // class\n+      val secondaryClusterCheck =\n+        BulkRegisterHostRbacCheck(\n+          clusterUuid = _ => req.secondaryClusterUuid,\n+          hosts =\n+            ctx =>\n+              argSupplier(ctx).hosts.map(\n+                host =>\n+                  HostRegister()\n+                    .withOsType(host.osType)\n+              )\n+        )\n+\n+      // Primary cluster checks: requires ManageDataSource on individual host FIDs\n+      val primaryClusterChecks =\n+        primaryClusterUuids.map {\n+          primaryClusterUuid =>\n+            val hostsForCluster =\n+              req.hosts.filter(_.primaryClusterUuid == primaryClusterUuid)\n+            RbacCheck(\n+              ManageDataSource,\n+              _ => hostsForCluster.map(_.hostFid),\n+              clusterIdsOpt = _ => Some(Seq(primaryClusterUuid))\n+            )\n+        }\n+\n+      // Combine all checks with AND logic\n+      val allChecks = secondaryClusterCheck +: primaryClusterChecks\n+      val combinedCheck = allChecks.reduce(And(_, _))\n+\n+      MoreRbacChecksNeeded(combinedCheck)\n+    }\n   }\n }"
        },
        {
          "filename": "polaris/src/rubrik/api-server/documentation/schema/schema-internal.graphql",
          "status": "modified",
          "additions": 38,
          "deletions": 1,
          "patch": "@@ -17357,7 +17357,9 @@ type Mutation {\n     input: BulkRegisterHostAsyncInput!): BulkRegisterHostAsyncReply!\n \n   # BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n-  bulkRegisterSecondaryHosts: Void\n+  bulkRegisterSecondaryHosts(\n+    # The request containing secondary cluster UUID and hosts to register.\n+    input: BulkRegisterSecondaryHostsInput!): BulkRegisterSecondaryHostsReply!\n \n   # BulkRestoreM365BackupStorageObjects triggers the restore for the M365 Backup\n   # Storage Group workloads.\n@@ -52393,6 +52395,19 @@ type BulkRegisterHostReply {\n   # Total list responses.\n   total: Long\n }\n+# Request message for bulk registration of secondary hosts.\n+input BulkRegisterSecondaryHostsInput {\n+  # List of hosts to register as secondary hosts.\n+  hosts: [SecondaryRegisterHostInput!]!\n+\n+  # UUID of the secondary cluster where hosts will be registered.\n+  secondaryClusterUuid: String!\n+}\n+# Response message for bulk registration of secondary hosts.\n+type BulkRegisterSecondaryHostsReply {\n+  # Results for each host that was processed.\n+  hostResults: [HostSecondaryRegistrationResult!]!\n+}\n # Configuration for O365 Backup Storage Groups workload restore.\n input BulkRestoreM365BackupStorageObjectsInput {\n   # Collection of UUIDs of the all the group workloads.\n@@ -98730,6 +98745,17 @@ enum HostRoot {\n   # Windows Host Root.\n   WINDOWS_HOST_ROOT\n }\n+# Result for a single host registration.\n+type HostSecondaryRegistrationResult {\n+  # Error message if registration failed.\n+  errorMessage: String!\n+\n+  # Host details of secondary registration if registration was successful.\n+  hostDetail: HostDetail\n+\n+  # The host FID that was processed.\n+  primaryHostFid: String!\n+}\n # Host share type.\n type HostShare implements CdmHierarchyObject & HierarchyObject & PhysicalHostDescendantType & PhysicalHostPhysicalChildType {\n   # Organizations to which this hierarchy object belongs.\n@@ -169036,6 +169062,17 @@ type SecAppsUsage {\n   # Timestamp of the sec apps usage data.\n   timestamp: DateTime\n }\n+# Host details for secondary registration.\n+input SecondaryRegisterHostInput {\n+  # The host FID (unique identifier).\n+  hostFid: String!\n+\n+  # Operating system type of the host.\n+  osType: HostRegisterOsType\n+\n+  # UUID of the primary cluster where the host currently resides.\n+  primaryClusterUuid: String!\n+}\n # This is used by report tables that support a two-layer view of data.\n type SecondaryTableConfig {\n   # The primary table metadata values."
        },
        {
          "filename": "polaris/src/rubrik/api-server/documentation/schema/schema-public-standard.graphql",
          "status": "modified",
          "additions": 40,
          "deletions": 0,
          "patch": "@@ -10142,6 +10142,11 @@ type Mutation {\n     # Input for V1BulkRegisterHostAsync.\n     input: BulkRegisterHostAsyncInput!): BulkRegisterHostAsyncReply!\n \n+  # BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n+  bulkRegisterSecondaryHosts(\n+    # The request containing secondary cluster UUID and hosts to register.\n+    input: BulkRegisterSecondaryHostsInput!): BulkRegisterSecondaryHostsReply!\n+\n   # Bulk tier existing snapshots to cold storage\n   # \n   # Supported in v6.0+\n@@ -37073,6 +37078,19 @@ type BulkRegisterHostReply {\n   # Total list responses.\n   total: Long\n }\n+# Request message for bulk registration of secondary hosts.\n+input BulkRegisterSecondaryHostsInput {\n+  # List of hosts to register as secondary hosts.\n+  hosts: [SecondaryRegisterHostInput!]!\n+\n+  # UUID of the secondary cluster where hosts will be registered.\n+  secondaryClusterUuid: String!\n+}\n+# Response message for bulk registration of secondary hosts.\n+type BulkRegisterSecondaryHostsReply {\n+  # Results for each host that was processed.\n+  hostResults: [HostSecondaryRegistrationResult!]!\n+}\n # Validation status of the bulk threat hunt request.\n enum BulkThreatHuntValidationStatus {\n   # Validation failed because the number of separate hunts that will be\n@@ -69730,6 +69748,17 @@ enum HostRoot {\n   # Windows Host Root.\n   WINDOWS_HOST_ROOT\n }\n+# Result for a single host registration.\n+type HostSecondaryRegistrationResult {\n+  # Error message if registration failed.\n+  errorMessage: String!\n+\n+  # Host details of secondary registration if registration was successful.\n+  hostDetail: HostDetail\n+\n+  # The host FID that was processed.\n+  primaryHostFid: String!\n+}\n # Host share type.\n type HostShare implements CdmHierarchyObject & HierarchyObject & PhysicalHostDescendantType & PhysicalHostPhysicalChildType {\n   # Organizations to which this hierarchy object belongs.\n@@ -118916,6 +118945,17 @@ type SearchResponseListResponse {\n   # Total list responses.\n   total: Long\n }\n+# Host details for secondary registration.\n+input SecondaryRegisterHostInput {\n+  # The host FID (unique identifier).\n+  hostFid: String!\n+\n+  # Operating system type of the host.\n+  osType: HostRegisterOsType\n+\n+  # UUID of the primary cluster where the host currently resides.\n+  primaryClusterUuid: String!\n+}\n type SecurityGroup {\n   id: String!\n   name: String!"
        },
        {
          "filename": "polaris/src/rubrik/api-server/documentation/schema/schema-public.graphql",
          "status": "modified",
          "additions": 40,
          "deletions": 0,
          "patch": "@@ -10142,6 +10142,11 @@ type Mutation {\n     # Input for V1BulkRegisterHostAsync.\n     input: BulkRegisterHostAsyncInput!): BulkRegisterHostAsyncReply!\n \n+  # BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n+  bulkRegisterSecondaryHosts(\n+    # The request containing secondary cluster UUID and hosts to register.\n+    input: BulkRegisterSecondaryHostsInput!): BulkRegisterSecondaryHostsReply!\n+\n   # Bulk tier existing snapshots to cold storage\n   # \n   # Supported in v6.0+\n@@ -37073,6 +37078,19 @@ type BulkRegisterHostReply {\n   # Total list responses.\n   total: Long\n }\n+# Request message for bulk registration of secondary hosts.\n+input BulkRegisterSecondaryHostsInput {\n+  # List of hosts to register as secondary hosts.\n+  hosts: [SecondaryRegisterHostInput!]!\n+\n+  # UUID of the secondary cluster where hosts will be registered.\n+  secondaryClusterUuid: String!\n+}\n+# Response message for bulk registration of secondary hosts.\n+type BulkRegisterSecondaryHostsReply {\n+  # Results for each host that was processed.\n+  hostResults: [HostSecondaryRegistrationResult!]!\n+}\n # Validation status of the bulk threat hunt request.\n enum BulkThreatHuntValidationStatus {\n   # Validation failed because the number of separate hunts that will be\n@@ -69730,6 +69748,17 @@ enum HostRoot {\n   # Windows Host Root.\n   WINDOWS_HOST_ROOT\n }\n+# Result for a single host registration.\n+type HostSecondaryRegistrationResult {\n+  # Error message if registration failed.\n+  errorMessage: String!\n+\n+  # Host details of secondary registration if registration was successful.\n+  hostDetail: HostDetail\n+\n+  # The host FID that was processed.\n+  primaryHostFid: String!\n+}\n # Host share type.\n type HostShare implements CdmHierarchyObject , HierarchyObject , PhysicalHostDescendantType , PhysicalHostPhysicalChildType {\n   # Organizations to which this hierarchy object belongs.\n@@ -118916,6 +118945,17 @@ type SearchResponseListResponse {\n   # Total list responses.\n   total: Long\n }\n+# Host details for secondary registration.\n+input SecondaryRegisterHostInput {\n+  # The host FID (unique identifier).\n+  hostFid: String!\n+\n+  # Operating system type of the host.\n+  osType: HostRegisterOsType\n+\n+  # UUID of the primary cluster where the host currently resides.\n+  primaryClusterUuid: String!\n+}\n type SecurityGroup {\n   id: String!\n   name: String!"
        },
        {
          "filename": "polaris/src/rubrik/api-server/test/app/services/physicalhost/rbac/BUILD.bazel",
          "status": "added",
          "additions": 17,
          "deletions": 0,
          "patch": "@@ -0,0 +1,17 @@\n+rkscala_test(\n+    name = \"physicalhost_rbac_test\",\n+    srcs = glob([\"*.scala\"]),\n+    jvm_flags = [\n+        \"-Dconfig.resource=functional/application.conf\",\n+    ],\n+    deps = [\n+        \"//rubrik/api-server:app_lib\",\n+        \"//rubrik/api-server:external_library_deps\",\n+        \"//rubrik/api-server:proto_deps\",\n+        \"//rubrik/api-server/app/services/physicalhost:physicalhost_proto\",\n+        \"//rubrik/api-server/app/services/physicalhost/rbac\",\n+        \"//rubrik/api-server/testing/common\",\n+        \"//rubrik/common-scala\",\n+        \"//rubrik/scala_thirdparty/junit\",\n+    ],\n+)"
        },
        {
          "filename": "polaris/src/rubrik/api-server/test/app/services/physicalhost/rbac/PhysicalHostRbacPoliciesImplTest.scala",
          "status": "added",
          "additions": 230,
          "deletions": 0,
          "patch": "@@ -0,0 +1,230 @@\n+package services.physicalhost.rbac\n+\n+import authzservice.authzservice.InventorySubHierarchyRootEnum.LINUX_HOST_ROOT\n+import cdmrestservice.cdmrestservice.cdmrestservice_types.HostRegister.HostRegisterOsType\n+import dal.grpc.UnifiedFeatureFlagService\n+import java.util.UUID\n+import models.graphql.AttributedFeatureFlagName\n+import models.graphql.FeatureFlagAttribute\n+import org.junit.Test\n+import org.mockito.ArgumentMatchers\n+import org.mockito.ArgumentMatchers.any\n+import org.mockito.Mockito.when\n+import physicalhost.physicalhost.BulkRegisterSecondaryHostsReq\n+import physicalhost.physicalhost.SecondaryRegisterHostInput\n+import security.UserContext\n+import security.rbac.Operation.AddInventory\n+import security.rbac.Operation.Ctx\n+import security.rbac.Operation.ManageDataSource\n+import testing.common.RbacOperationTester\n+import testing.common.RbacTestHelper\n+import testing.common.RubrikUnitSuite\n+import testing.common.UserTestHelper\n+import testing.common.UserTestHelper.UserWrapper\n+\n+class PhysicalHostRbacPoliciesImplTest extends RubrikUnitSuite {\n+\n+  private case class Deps(\n+    tester: RbacOperationTester,\n+    rbacHelper: RbacTestHelper,\n+    localUser: UserWrapper,\n+    policies: PhysicalHostRbacPoliciesImpl,\n+    uffs: UnifiedFeatureFlagService,\n+  ) {}\n+\n+  private def init(): Deps = {\n+    val tester = RbacOperationTester()\n+    val userHelper = UserTestHelper(tester.fus, tester.authz, tester.ams)\n+    val rbacHelper = RbacTestHelper(tester.authz, tester.qauthSvc)\n+\n+    val uffs = mock[UnifiedFeatureFlagService]\n+    val policies = new PhysicalHostRbacPoliciesImpl(uffs)\n+\n+    val localUser = userHelper.createLocalUser()\n+    Deps(\n+      tester,\n+      rbacHelper,\n+      localUser,\n+      policies,\n+      uffs,\n+    )\n+  }\n+\n+  @Test\n+  def testRbacPolicyForBulkRegisterSecondaryHosts(): Unit = {\n+    val deps = init()\n+    val endUser = deps.localUser.user()\n+\n+    // Test data - matching the exact structure from v1 tests\n+    val secondaryClusterUuid = UUID.randomUUID.toString\n+    val primaryClusterUuid1 = UUID.randomUUID.toString\n+    val primaryClusterUuid2 = UUID.randomUUID.toString\n+    val hostFid1 = UUID.randomUUID.toString\n+    val hostFid2 = UUID.randomUUID.toString\n+    val hostFid3 = UUID.randomUUID.toString\n+\n+    // Enable feature flag\n+    when(\n+      deps.uffs.isFeatureFlagTrue(\n+        any[UserContext],\n+        ArgumentMatchers.eq(\n+          AttributedFeatureFlagName.REGISTER_HOST_OS_TYPE_ENABLED.toString\n+        ),\n+        any[Seq[FeatureFlagAttribute]]\n+      )\n+    ).thenReturn(true)\n+\n+    val hosts =\n+      Seq(\n+        SecondaryRegisterHostInput()\n+          .withHostFid(hostFid1)\n+          .withPrimaryClusterUuid(primaryClusterUuid1)\n+          .withOsType(HostRegisterOsType.HOST_REGISTER_OS_TYPE_LINUX),\n+        SecondaryRegisterHostInput()\n+          .withHostFid(hostFid2)\n+          .withPrimaryClusterUuid(primaryClusterUuid1)\n+          .withOsType(HostRegisterOsType.HOST_REGISTER_OS_TYPE_LINUX),\n+        SecondaryRegisterHostInput()\n+          .withHostFid(hostFid3)\n+          .withPrimaryClusterUuid(primaryClusterUuid2)\n+          .withOsType(HostRegisterOsType.HOST_REGISTER_OS_TYPE_LINUX)\n+      )\n+\n+    val reqFn: Ctx => BulkRegisterSecondaryHostsReq =\n+      _ =>\n+        BulkRegisterSecondaryHostsReq()\n+          .withSecondaryClusterUuid(secondaryClusterUuid)\n+          .withHosts(hosts)\n+\n+    // Test 1: No access without any permissions\n+    deps.rbacHelper.runWithAuthorization(\n+      endUser,\n+      List.empty,\n+      List.empty\n+    ) {\n+      deps.tester.assertNoAccess(\n+        user = endUser,\n+        rbacPolicy = deps.policies.bulkRegisterSecondaryHosts(reqFn)\n+      )\n+    }\n+\n+    // Test 2: No access with only ManageDataSource on secondary cluster\n+    // (missing permissions on primary cluster)\n+    deps.rbacHelper.runWithAuthorization(\n+      endUser,\n+      List(ManageDataSource),\n+      List(LINUX_HOST_ROOT.name),\n+      clusterIdsOpt = Some(List(secondaryClusterUuid))\n+    ) {\n+      deps.tester.assertNoAccess(\n+        user = endUser,\n+        rbacPolicy = deps.policies.bulkRegisterSecondaryHosts(reqFn)\n+      )\n+    }\n+\n+    // Test 3: No access with only AddInventory on secondary cluster\n+    // (missing permissions on primary cluster)\n+    deps.rbacHelper.runWithAuthorization(\n+      endUser,\n+      List(AddInventory),\n+      List(LINUX_HOST_ROOT.name),\n+      clusterIdsOpt = Some(List(secondaryClusterUuid))\n+    ) {\n+      deps.tester.assertNoAccess(\n+        user = endUser,\n+        rbacPolicy = deps.policies.bulkRegisterSecondaryHosts(reqFn)\n+      )\n+    }\n+\n+    // Test 4: No access with partial primary cluster permissions\n+    // (missing permission on the third host)\n+    deps.rbacHelper.runWithAuthorization(\n+      endUser,\n+      List(ManageDataSource, AddInventory),\n+      List(LINUX_HOST_ROOT.name, hostFid1, hostFid2), // Missing hostFid3\n+      clusterIdsOpt =\n+        Some(\n+          List(secondaryClusterUuid, primaryClusterUuid1, primaryClusterUuid2)\n+        )\n+    ) {\n+      deps.tester.assertNoAccess(\n+        user = endUser,\n+        rbacPolicy = deps.policies.bulkRegisterSecondaryHosts(reqFn)\n+      )\n+    }\n+\n+    // Test 5: Has access with all required permissions\n+    deps.rbacHelper.runWithAuthorization(\n+      endUser,\n+      List(ManageDataSource, AddInventory),\n+      List(LINUX_HOST_ROOT.name, hostFid1, hostFid2, hostFid3),\n+      clusterIdsOpt =\n+        Some(\n+          List(secondaryClusterUuid, primaryClusterUuid1, primaryClusterUuid2)\n+        )\n+    ) {\n+      deps.tester.assertHasAccess(\n+        user = endUser,\n+        rbacPolicy = deps.policies.bulkRegisterSecondaryHosts(reqFn)\n+      )\n+    }\n+\n+    // Test 6: Test with empty hosts list (should succeed with minimal\n+    // permissions)\n+    deps.rbacHelper.runWithAuthorization(\n+      endUser,\n+      List(ManageDataSource, AddInventory),\n+      List(LINUX_HOST_ROOT.name),\n+      clusterIdsOpt = Some(List(secondaryClusterUuid))\n+    ) {\n+      deps.tester.assertHasAccess(\n+        user = endUser,\n+        rbacPolicy =\n+          deps.policies.bulkRegisterSecondaryHosts(\n+            reqFn.andThen(_.withHosts(Seq.empty))\n+          )\n+      )\n+    }\n+\n+    // Test 7: Test with single host (simpler case)\n+    val singleHost = Seq(hosts.head)\n+    deps.rbacHelper.runWithAuthorization(\n+      endUser,\n+      List(ManageDataSource, AddInventory),\n+      List(LINUX_HOST_ROOT.name, hostFid1),\n+      clusterIdsOpt = Some(List(secondaryClusterUuid, primaryClusterUuid1))\n+    ) {\n+      deps.tester.assertHasAccess(\n+        user = endUser,\n+        rbacPolicy =\n+          deps.policies.bulkRegisterSecondaryHosts(\n+            reqFn.andThen(_.withHosts(singleHost))\n+          )\n+      )\n+    }\n+\n+    // Test 8: AddInventory on secondary cluster and ManageDataSource on\n+    // primary cluster\n+    deps.rbacHelper.runWithAuthorization(\n+      endUser,\n+      List(AddInventory),\n+      List(LINUX_HOST_ROOT.name),\n+      clusterIdsOpt = Some(List(secondaryClusterUuid))\n+    ) {\n+      deps.rbacHelper.runWithAuthorization(\n+        endUser,\n+        List(ManageDataSource),\n+        List(hostFid1),\n+        clusterIdsOpt = Some(List(primaryClusterUuid1))\n+      ) {\n+        deps.tester.assertHasAccess(\n+          user = endUser,\n+          rbacPolicy =\n+            deps.policies.bulkRegisterSecondaryHosts(\n+              reqFn.andThen(_.withHosts(singleHost))\n+            )\n+        )\n+      }\n+    }\n+  }\n+}"
        },
        {
          "filename": "polaris/src/rubrik/global-api/schema/schema.go",
          "status": "modified",
          "additions": 24,
          "deletions": 1,
          "patch": "@@ -11167,6 +11167,12 @@ type AzureAdOnPremSyncStatus string\n \n type CdmDataGuardType string\n \n+type SecondaryRegisterHostInput struct {\n+\tHostFid            string              `json:\"hostFid\"`\n+\tOsType             *HostRegisterOsType `json:\"osType\"`\n+\tPrimaryClusterUuid string              `json:\"primaryClusterUuid\"`\n+}\n+\n type SourceDataFiltersInput struct {\n \tExtensionWhitelist     []string                     `json:\"extensionWhitelist\"`\n \tModifiedTimeRange      *ChatbotTimeRangeFilterInput `json:\"modifiedTimeRange\"`\n@@ -35272,6 +35278,11 @@ type SnappableInfoType struct {\n \tRecoveryPoint *int64  `json:\"recoveryPoint\"`\n }\n \n+type BulkRegisterSecondaryHostsInput struct {\n+\tHosts                []SecondaryRegisterHostInput `json:\"hosts\"`\n+\tSecondaryClusterUuid string                       `json:\"secondaryClusterUuid\"`\n+}\n+\n type TprRequestSummaryEdge struct {\n \t__typename string            `json:\"__typename\"`\n \tCursor     string            `json:\"cursor\"`\n@@ -44482,6 +44493,13 @@ type SalesforcePermissionNode struct {\n \tSalesforcePermission *SalesforcePermission `json:\"salesforcePermission\"`\n }\n \n+type HostSecondaryRegistrationResult struct {\n+\t__typename     string      `json:\"__typename\"`\n+\tErrorMessage   string      `json:\"errorMessage\"`\n+\tHostDetail     *HostDetail `json:\"hostDetail\"`\n+\tPrimaryHostFid string      `json:\"primaryHostFid\"`\n+}\n+\n type MetadataOneof struct {\n \tHuntId             *string `json:\"huntId\"`\n \tIsThreatMonitoring *bool   `json:\"isThreatMonitoring\"`\n@@ -54075,7 +54093,7 @@ type Mutation struct {\n \tBulkRefreshHosts                                       BulkRefreshHostsReply                                `json:\"bulkRefreshHosts\"`\n \tBulkRegisterHost                                       BulkRegisterHostReply                                `json:\"bulkRegisterHost\"`\n \tBulkRegisterHostAsync                                  BulkRegisterHostAsyncReply                           `json:\"bulkRegisterHostAsync\"`\n-\tBulkRegisterSecondaryHosts                             *Void                                                `json:\"bulkRegisterSecondaryHosts\"`\n+\tBulkRegisterSecondaryHosts                             BulkRegisterSecondaryHostsReply                      `json:\"bulkRegisterSecondaryHosts\"`\n \tBulkRestoreM365BackupStorageObjects                    BulkRestoreM365BackupStorageObjectsReply             `json:\"bulkRestoreM365BackupStorageObjects\"`\n \tBulkRotateClusterEncryptionKey                         BulkRotateClusterEncryptionKeyReply                  `json:\"bulkRotateClusterEncryptionKey\"`\n \tBulkTierExistingSnapshots                              AsyncRequestStatus                                   `json:\"bulkTierExistingSnapshots\"`\n@@ -67472,6 +67490,11 @@ type M365BackupStorageLicenseUsage struct {\n \tOrgConsumptionsEntry []M365BackupStorageOrgLicenseUsage  `json:\"orgConsumptionsEntry\"`\n }\n \n+type BulkRegisterSecondaryHostsReply struct {\n+\t__typename  string                            `json:\"__typename\"`\n+\tHostResults []HostSecondaryRegistrationResult `json:\"hostResults\"`\n+}\n+\n type LinuxRbsBulkInstallReply struct {\n \t__typename string               `json:\"__typename\"`\n \tOutput     *BulkRbsInstallReply `json:\"output\"`"
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/proto/BUILD.bazel",
          "status": "modified",
          "additions": 2,
          "deletions": 0,
          "patch": "@@ -5,6 +5,7 @@ proto_library(\n     visibility = [\"//visibility:public\"],\n     deps = [\n         \"//rubrik/api-server/app/v2/proto:api_proto\",\n+        \"//rubrik/cdm-rest-service/proto/types:types_proto\",\n         \"//rubrik/common-go/api/context/proto:proto_proto\",\n         \"//rubrik/scalapb/proto:scalapb_proto\",\n     ],\n@@ -21,6 +22,7 @@ go_library(\n     visibility = [\"//visibility:public\"],\n     deps = [\n         \"//rubrik/api-server/app/v2/proto:go_default_library\",\n+        \"//rubrik/cdm-rest-service/proto/types:go_default_library\",\n         \"//rubrik/common-go/api/context/proto:go_default_library\",\n         \"//rubrik/scalapb/proto:go_default_library\",\n         \"//rubrik/vendor/github.com/stretchr/testify/mock:go_default_library\","
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/proto/physicalhost.pb.go",
          "status": "modified",
          "additions": 291,
          "deletions": 53,
          "patch": "@@ -18,6 +18,7 @@ import (\n \tprotoimpl \"google.golang.org/protobuf/runtime/protoimpl\"\n \n \t_ \"rubrik/api-server/app/v2/proto\"\n+\ttypes \"rubrik/cdm-rest-service/proto/types\"\n \tproto \"rubrik/common-go/api/context/proto\"\n \t_ \"rubrik/scalapb/proto\"\n )\n@@ -127,19 +128,90 @@ func (x *EchoReply) GetReply() string {\n \treturn \"\"\n }\n \n+// Host details for secondary registration.\n+type SecondaryRegisterHostInput struct {\n+\tstate         protoimpl.MessageState\n+\tsizeCache     protoimpl.SizeCache\n+\tunknownFields protoimpl.UnknownFields\n+\n+\t// The host FID (unique identifier).\n+\tHostFid string `protobuf:\"bytes,1,opt,name=host_fid,json=hostFid,proto3\" json:\"host_fid,omitempty\"`\n+\t// UUID of the primary cluster where the host currently resides.\n+\tPrimaryClusterUuid string `protobuf:\"bytes,2,opt,name=primary_cluster_uuid,json=primaryClusterUuid,proto3\" json:\"primary_cluster_uuid,omitempty\"`\n+\t// Operating system type of the host.\n+\tOsType types.HostRegister_HostRegisterOsType `protobuf:\"varint,3,opt,name=os_type,json=osType,proto3,enum=cdmrestservice.HostRegister_HostRegisterOsType\" json:\"os_type,omitempty\"`\n+}\n+\n+func (x *SecondaryRegisterHostInput) Reset() {\n+\t*x = SecondaryRegisterHostInput{}\n+\tif protoimpl.UnsafeEnabled {\n+\t\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[2]\n+\t\tms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))\n+\t\tms.StoreMessageInfo(mi)\n+\t}\n+}\n+\n+func (x *SecondaryRegisterHostInput) String() string {\n+\treturn protoimpl.X.MessageStringOf(x)\n+}\n+\n+func (*SecondaryRegisterHostInput) ProtoMessage() {}\n+\n+func (x *SecondaryRegisterHostInput) ProtoReflect() protoreflect.Message {\n+\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[2]\n+\tif protoimpl.UnsafeEnabled && x != nil {\n+\t\tms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))\n+\t\tif ms.LoadMessageInfo() == nil {\n+\t\t\tms.StoreMessageInfo(mi)\n+\t\t}\n+\t\treturn ms\n+\t}\n+\treturn mi.MessageOf(x)\n+}\n+\n+// Deprecated: Use SecondaryRegisterHostInput.ProtoReflect.Descriptor instead.\n+func (*SecondaryRegisterHostInput) Descriptor() ([]byte, []int) {\n+\treturn file_rubrik_physicalhost_proto_physicalhost_proto_rawDescGZIP(), []int{2}\n+}\n+\n+func (x *SecondaryRegisterHostInput) GetHostFid() string {\n+\tif x != nil {\n+\t\treturn x.HostFid\n+\t}\n+\treturn \"\"\n+}\n+\n+func (x *SecondaryRegisterHostInput) GetPrimaryClusterUuid() string {\n+\tif x != nil {\n+\t\treturn x.PrimaryClusterUuid\n+\t}\n+\treturn \"\"\n+}\n+\n+func (x *SecondaryRegisterHostInput) GetOsType() types.HostRegister_HostRegisterOsType {\n+\tif x != nil {\n+\t\treturn x.OsType\n+\t}\n+\treturn types.HostRegister_HostRegisterOsType(0)\n+}\n+\n // Request message for bulk registration of secondary hosts.\n type BulkRegisterSecondaryHostsReq struct {\n \tstate         protoimpl.MessageState\n \tsizeCache     protoimpl.SizeCache\n \tunknownFields protoimpl.UnknownFields\n \n \tReqCtx *proto.RequestContext `protobuf:\"bytes,1,opt,name=req_ctx,json=reqCtx,proto3\" json:\"req_ctx,omitempty\"`\n+\t// UUID of the secondary cluster where hosts will be registered.\n+\tSecondaryClusterUuid string `protobuf:\"bytes,2,opt,name=secondary_cluster_uuid,json=secondaryClusterUuid,proto3\" json:\"secondary_cluster_uuid,omitempty\"`\n+\t// List of hosts to register as secondary hosts.\n+\tHosts []*SecondaryRegisterHostInput `protobuf:\"bytes,3,rep,name=hosts,proto3\" json:\"hosts,omitempty\"`\n }\n \n func (x *BulkRegisterSecondaryHostsReq) Reset() {\n \t*x = BulkRegisterSecondaryHostsReq{}\n \tif protoimpl.UnsafeEnabled {\n-\t\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[2]\n+\t\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[3]\n \t\tms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))\n \t\tms.StoreMessageInfo(mi)\n \t}\n@@ -152,7 +224,7 @@ func (x *BulkRegisterSecondaryHostsReq) String() string {\n func (*BulkRegisterSecondaryHostsReq) ProtoMessage() {}\n \n func (x *BulkRegisterSecondaryHostsReq) ProtoReflect() protoreflect.Message {\n-\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[2]\n+\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[3]\n \tif protoimpl.UnsafeEnabled && x != nil {\n \t\tms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))\n \t\tif ms.LoadMessageInfo() == nil {\n@@ -165,7 +237,7 @@ func (x *BulkRegisterSecondaryHostsReq) ProtoReflect() protoreflect.Message {\n \n // Deprecated: Use BulkRegisterSecondaryHostsReq.ProtoReflect.Descriptor instead.\n func (*BulkRegisterSecondaryHostsReq) Descriptor() ([]byte, []int) {\n-\treturn file_rubrik_physicalhost_proto_physicalhost_proto_rawDescGZIP(), []int{2}\n+\treturn file_rubrik_physicalhost_proto_physicalhost_proto_rawDescGZIP(), []int{3}\n }\n \n func (x *BulkRegisterSecondaryHostsReq) GetReqCtx() *proto.RequestContext {\n@@ -175,17 +247,101 @@ func (x *BulkRegisterSecondaryHostsReq) GetReqCtx() *proto.RequestContext {\n \treturn nil\n }\n \n+func (x *BulkRegisterSecondaryHostsReq) GetSecondaryClusterUuid() string {\n+\tif x != nil {\n+\t\treturn x.SecondaryClusterUuid\n+\t}\n+\treturn \"\"\n+}\n+\n+func (x *BulkRegisterSecondaryHostsReq) GetHosts() []*SecondaryRegisterHostInput {\n+\tif x != nil {\n+\t\treturn x.Hosts\n+\t}\n+\treturn nil\n+}\n+\n+// Result for a single host registration.\n+type HostSecondaryRegistrationResult struct {\n+\tstate         protoimpl.MessageState\n+\tsizeCache     protoimpl.SizeCache\n+\tunknownFields protoimpl.UnknownFields\n+\n+\t// The host FID that was processed.\n+\tPrimaryHostFid string `protobuf:\"bytes,1,opt,name=primary_host_fid,json=primaryHostFid,proto3\" json:\"primary_host_fid,omitempty\"`\n+\t// Error message if registration failed.\n+\tErrorMessage string `protobuf:\"bytes,2,opt,name=error_message,json=errorMessage,proto3\" json:\"error_message,omitempty\"`\n+\t// Host details of secondary registration if registration was successful.\n+\tHostDetail *types.HostDetail `protobuf:\"bytes,3,opt,name=host_detail,json=hostDetail,proto3\" json:\"host_detail,omitempty\"`\n+}\n+\n+func (x *HostSecondaryRegistrationResult) Reset() {\n+\t*x = HostSecondaryRegistrationResult{}\n+\tif protoimpl.UnsafeEnabled {\n+\t\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[4]\n+\t\tms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))\n+\t\tms.StoreMessageInfo(mi)\n+\t}\n+}\n+\n+func (x *HostSecondaryRegistrationResult) String() string {\n+\treturn protoimpl.X.MessageStringOf(x)\n+}\n+\n+func (*HostSecondaryRegistrationResult) ProtoMessage() {}\n+\n+func (x *HostSecondaryRegistrationResult) ProtoReflect() protoreflect.Message {\n+\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[4]\n+\tif protoimpl.UnsafeEnabled && x != nil {\n+\t\tms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))\n+\t\tif ms.LoadMessageInfo() == nil {\n+\t\t\tms.StoreMessageInfo(mi)\n+\t\t}\n+\t\treturn ms\n+\t}\n+\treturn mi.MessageOf(x)\n+}\n+\n+// Deprecated: Use HostSecondaryRegistrationResult.ProtoReflect.Descriptor instead.\n+func (*HostSecondaryRegistrationResult) Descriptor() ([]byte, []int) {\n+\treturn file_rubrik_physicalhost_proto_physicalhost_proto_rawDescGZIP(), []int{4}\n+}\n+\n+func (x *HostSecondaryRegistrationResult) GetPrimaryHostFid() string {\n+\tif x != nil {\n+\t\treturn x.PrimaryHostFid\n+\t}\n+\treturn \"\"\n+}\n+\n+func (x *HostSecondaryRegistrationResult) GetErrorMessage() string {\n+\tif x != nil {\n+\t\treturn x.ErrorMessage\n+\t}\n+\treturn \"\"\n+}\n+\n+func (x *HostSecondaryRegistrationResult) GetHostDetail() *types.HostDetail {\n+\tif x != nil {\n+\t\treturn x.HostDetail\n+\t}\n+\treturn nil\n+}\n+\n // Response message for bulk registration of secondary hosts.\n type BulkRegisterSecondaryHostsReply struct {\n \tstate         protoimpl.MessageState\n \tsizeCache     protoimpl.SizeCache\n \tunknownFields protoimpl.UnknownFields\n+\n+\t// Results for each host that was processed.\n+\tHostResults []*HostSecondaryRegistrationResult `protobuf:\"bytes,1,rep,name=host_results,json=hostResults,proto3\" json:\"host_results,omitempty\"`\n }\n \n func (x *BulkRegisterSecondaryHostsReply) Reset() {\n \t*x = BulkRegisterSecondaryHostsReply{}\n \tif protoimpl.UnsafeEnabled {\n-\t\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[3]\n+\t\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[5]\n \t\tms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))\n \t\tms.StoreMessageInfo(mi)\n \t}\n@@ -198,7 +354,7 @@ func (x *BulkRegisterSecondaryHostsReply) String() string {\n func (*BulkRegisterSecondaryHostsReply) ProtoMessage() {}\n \n func (x *BulkRegisterSecondaryHostsReply) ProtoReflect() protoreflect.Message {\n-\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[3]\n+\tmi := &file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[5]\n \tif protoimpl.UnsafeEnabled && x != nil {\n \t\tms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))\n \t\tif ms.LoadMessageInfo() == nil {\n@@ -211,7 +367,14 @@ func (x *BulkRegisterSecondaryHostsReply) ProtoReflect() protoreflect.Message {\n \n // Deprecated: Use BulkRegisterSecondaryHostsReply.ProtoReflect.Descriptor instead.\n func (*BulkRegisterSecondaryHostsReply) Descriptor() ([]byte, []int) {\n-\treturn file_rubrik_physicalhost_proto_physicalhost_proto_rawDescGZIP(), []int{3}\n+\treturn file_rubrik_physicalhost_proto_physicalhost_proto_rawDescGZIP(), []int{5}\n+}\n+\n+func (x *BulkRegisterSecondaryHostsReply) GetHostResults() []*HostSecondaryRegistrationResult {\n+\tif x != nil {\n+\t\treturn x.HostResults\n+\t}\n+\treturn nil\n }\n \n var File_rubrik_physicalhost_proto_physicalhost_proto protoreflect.FileDescriptor\n@@ -228,39 +391,80 @@ var file_rubrik_physicalhost_proto_physicalhost_proto_rawDesc = []byte{\n \t0x72, 0x2f, 0x61, 0x70, 0x70, 0x2f, 0x76, 0x32, 0x2f, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x2f, 0x61,\n \t0x70, 0x69, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x1a, 0x22, 0x72, 0x75, 0x62, 0x72, 0x69, 0x6b,\n \t0x2f, 0x73, 0x63, 0x61, 0x6c, 0x61, 0x70, 0x62, 0x2f, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x2f, 0x73,\n-\t0x63, 0x61, 0x6c, 0x61, 0x70, 0x62, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x22, 0x1d, 0x0a, 0x07,\n+\t0x63, 0x61, 0x6c, 0x61, 0x70, 0x62, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x1a, 0x3e, 0x72, 0x75,\n+\t0x62, 0x72, 0x69, 0x6b, 0x2f, 0x63, 0x64, 0x6d, 0x2d, 0x72, 0x65, 0x73, 0x74, 0x2d, 0x73, 0x65,\n+\t0x72, 0x76, 0x69, 0x63, 0x65, 0x2f, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x2f, 0x74, 0x79, 0x70, 0x65,\n+\t0x73, 0x2f, 0x63, 0x64, 0x6d, 0x72, 0x65, 0x73, 0x74, 0x73, 0x65, 0x72, 0x76, 0x69, 0x63, 0x65,\n+\t0x5f, 0x74, 0x79, 0x70, 0x65, 0x73, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x22, 0x1d, 0x0a, 0x07,\n \t0x45, 0x63, 0x68, 0x6f, 0x52, 0x65, 0x71, 0x12, 0x12, 0x0a, 0x04, 0x61, 0x72, 0x67, 0x31, 0x18,\n \t0x01, 0x20, 0x01, 0x28, 0x09, 0x52, 0x04, 0x61, 0x72, 0x67, 0x31, 0x22, 0x21, 0x0a, 0x09, 0x45,\n \t0x63, 0x68, 0x6f, 0x52, 0x65, 0x70, 0x6c, 0x79, 0x12, 0x14, 0x0a, 0x05, 0x72, 0x65, 0x70, 0x6c,\n-\t0x79, 0x18, 0x01, 0x20, 0x01, 0x28, 0x09, 0x52, 0x05, 0x72, 0x65, 0x70, 0x6c, 0x79, 0x22, 0x51,\n-\t0x0a, 0x1d, 0x42, 0x75, 0x6c, 0x6b, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x53, 0x65,\n-\t0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x48, 0x6f, 0x73, 0x74, 0x73, 0x52, 0x65, 0x71, 0x12,\n-\t0x30, 0x0a, 0x07, 0x72, 0x65, 0x71, 0x5f, 0x63, 0x74, 0x78, 0x18, 0x01, 0x20, 0x01, 0x28, 0x0b,\n-\t0x32, 0x17, 0x2e, 0x63, 0x6f, 0x6e, 0x74, 0x65, 0x78, 0x74, 0x2e, 0x52, 0x65, 0x71, 0x75, 0x65,\n-\t0x73, 0x74, 0x43, 0x6f, 0x6e, 0x74, 0x65, 0x78, 0x74, 0x52, 0x06, 0x72, 0x65, 0x71, 0x43, 0x74,\n-\t0x78, 0x22, 0x21, 0x0a, 0x1f, 0x42, 0x75, 0x6c, 0x6b, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65,\n-\t0x72, 0x53, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x48, 0x6f, 0x73, 0x74, 0x73, 0x52,\n-\t0x65, 0x70, 0x6c, 0x79, 0x32, 0x96, 0x02, 0x0a, 0x0c, 0x50, 0x68, 0x79, 0x73, 0x69, 0x63, 0x61,\n-\t0x6c, 0x48, 0x6f, 0x73, 0x74, 0x12, 0xa2, 0x01, 0x0a, 0x1a, 0x42, 0x75, 0x6c, 0x6b, 0x52, 0x65,\n+\t0x79, 0x18, 0x01, 0x20, 0x01, 0x28, 0x09, 0x52, 0x05, 0x72, 0x65, 0x70, 0x6c, 0x79, 0x22, 0xc7,\n+\t0x01, 0x0a, 0x1a, 0x53, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x52, 0x65, 0x67, 0x69,\n+\t0x73, 0x74, 0x65, 0x72, 0x48, 0x6f, 0x73, 0x74, 0x49, 0x6e, 0x70, 0x75, 0x74, 0x12, 0x23, 0x0a,\n+\t0x08, 0x68, 0x6f, 0x73, 0x74, 0x5f, 0x66, 0x69, 0x64, 0x18, 0x01, 0x20, 0x01, 0x28, 0x09, 0x42,\n+\t0x08, 0x92, 0xa2, 0xb9, 0xb8, 0x04, 0x02, 0x10, 0x01, 0x52, 0x07, 0x68, 0x6f, 0x73, 0x74, 0x46,\n+\t0x69, 0x64, 0x12, 0x3a, 0x0a, 0x14, 0x70, 0x72, 0x69, 0x6d, 0x61, 0x72, 0x79, 0x5f, 0x63, 0x6c,\n+\t0x75, 0x73, 0x74, 0x65, 0x72, 0x5f, 0x75, 0x75, 0x69, 0x64, 0x18, 0x02, 0x20, 0x01, 0x28, 0x09,\n+\t0x42, 0x08, 0x92, 0xa2, 0xb9, 0xb8, 0x04, 0x02, 0x10, 0x01, 0x52, 0x12, 0x70, 0x72, 0x69, 0x6d,\n+\t0x61, 0x72, 0x79, 0x43, 0x6c, 0x75, 0x73, 0x74, 0x65, 0x72, 0x55, 0x75, 0x69, 0x64, 0x12, 0x48,\n+\t0x0a, 0x07, 0x6f, 0x73, 0x5f, 0x74, 0x79, 0x70, 0x65, 0x18, 0x03, 0x20, 0x01, 0x28, 0x0e, 0x32,\n+\t0x2f, 0x2e, 0x63, 0x64, 0x6d, 0x72, 0x65, 0x73, 0x74, 0x73, 0x65, 0x72, 0x76, 0x69, 0x63, 0x65,\n+\t0x2e, 0x48, 0x6f, 0x73, 0x74, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x2e, 0x48, 0x6f,\n+\t0x73, 0x74, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x4f, 0x73, 0x54, 0x79, 0x70, 0x65,\n+\t0x52, 0x06, 0x6f, 0x73, 0x54, 0x79, 0x70, 0x65, 0x22, 0xdb, 0x01, 0x0a, 0x1d, 0x42, 0x75, 0x6c,\n+\t0x6b, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x53, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61,\n+\t0x72, 0x79, 0x48, 0x6f, 0x73, 0x74, 0x73, 0x52, 0x65, 0x71, 0x12, 0x30, 0x0a, 0x07, 0x72, 0x65,\n+\t0x71, 0x5f, 0x63, 0x74, 0x78, 0x18, 0x01, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x17, 0x2e, 0x63, 0x6f,\n+\t0x6e, 0x74, 0x65, 0x78, 0x74, 0x2e, 0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x43, 0x6f, 0x6e,\n+\t0x74, 0x65, 0x78, 0x74, 0x52, 0x06, 0x72, 0x65, 0x71, 0x43, 0x74, 0x78, 0x12, 0x3e, 0x0a, 0x16,\n+\t0x73, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x5f, 0x63, 0x6c, 0x75, 0x73, 0x74, 0x65,\n+\t0x72, 0x5f, 0x75, 0x75, 0x69, 0x64, 0x18, 0x02, 0x20, 0x01, 0x28, 0x09, 0x42, 0x08, 0x92, 0xa2,\n+\t0xb9, 0xb8, 0x04, 0x02, 0x10, 0x01, 0x52, 0x14, 0x73, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72,\n+\t0x79, 0x43, 0x6c, 0x75, 0x73, 0x74, 0x65, 0x72, 0x55, 0x75, 0x69, 0x64, 0x12, 0x48, 0x0a, 0x05,\n+\t0x68, 0x6f, 0x73, 0x74, 0x73, 0x18, 0x03, 0x20, 0x03, 0x28, 0x0b, 0x32, 0x28, 0x2e, 0x70, 0x68,\n+\t0x79, 0x73, 0x69, 0x63, 0x61, 0x6c, 0x68, 0x6f, 0x73, 0x74, 0x2e, 0x53, 0x65, 0x63, 0x6f, 0x6e,\n+\t0x64, 0x61, 0x72, 0x79, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x48, 0x6f, 0x73, 0x74,\n+\t0x49, 0x6e, 0x70, 0x75, 0x74, 0x42, 0x08, 0x92, 0xa2, 0xb9, 0xb8, 0x04, 0x02, 0x10, 0x01, 0x52,\n+\t0x05, 0x68, 0x6f, 0x73, 0x74, 0x73, 0x22, 0xad, 0x01, 0x0a, 0x1f, 0x48, 0x6f, 0x73, 0x74, 0x53,\n+\t0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x72, 0x61,\n+\t0x74, 0x69, 0x6f, 0x6e, 0x52, 0x65, 0x73, 0x75, 0x6c, 0x74, 0x12, 0x28, 0x0a, 0x10, 0x70, 0x72,\n+\t0x69, 0x6d, 0x61, 0x72, 0x79, 0x5f, 0x68, 0x6f, 0x73, 0x74, 0x5f, 0x66, 0x69, 0x64, 0x18, 0x01,\n+\t0x20, 0x01, 0x28, 0x09, 0x52, 0x0e, 0x70, 0x72, 0x69, 0x6d, 0x61, 0x72, 0x79, 0x48, 0x6f, 0x73,\n+\t0x74, 0x46, 0x69, 0x64, 0x12, 0x23, 0x0a, 0x0d, 0x65, 0x72, 0x72, 0x6f, 0x72, 0x5f, 0x6d, 0x65,\n+\t0x73, 0x73, 0x61, 0x67, 0x65, 0x18, 0x02, 0x20, 0x01, 0x28, 0x09, 0x52, 0x0c, 0x65, 0x72, 0x72,\n+\t0x6f, 0x72, 0x4d, 0x65, 0x73, 0x73, 0x61, 0x67, 0x65, 0x12, 0x3b, 0x0a, 0x0b, 0x68, 0x6f, 0x73,\n+\t0x74, 0x5f, 0x64, 0x65, 0x74, 0x61, 0x69, 0x6c, 0x18, 0x03, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x1a,\n+\t0x2e, 0x63, 0x64, 0x6d, 0x72, 0x65, 0x73, 0x74, 0x73, 0x65, 0x72, 0x76, 0x69, 0x63, 0x65, 0x2e,\n+\t0x48, 0x6f, 0x73, 0x74, 0x44, 0x65, 0x74, 0x61, 0x69, 0x6c, 0x52, 0x0a, 0x68, 0x6f, 0x73, 0x74,\n+\t0x44, 0x65, 0x74, 0x61, 0x69, 0x6c, 0x22, 0x73, 0x0a, 0x1f, 0x42, 0x75, 0x6c, 0x6b, 0x52, 0x65,\n \t0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x53, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x48,\n-\t0x6f, 0x73, 0x74, 0x73, 0x12, 0x2b, 0x2e, 0x70, 0x68, 0x79, 0x73, 0x69, 0x63, 0x61, 0x6c, 0x68,\n-\t0x6f, 0x73, 0x74, 0x2e, 0x42, 0x75, 0x6c, 0x6b, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72,\n-\t0x53, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x48, 0x6f, 0x73, 0x74, 0x73, 0x52, 0x65,\n-\t0x71, 0x1a, 0x2d, 0x2e, 0x70, 0x68, 0x79, 0x73, 0x69, 0x63, 0x61, 0x6c, 0x68, 0x6f, 0x73, 0x74,\n-\t0x2e, 0x42, 0x75, 0x6c, 0x6b, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x53, 0x65, 0x63,\n-\t0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x48, 0x6f, 0x73, 0x74, 0x73, 0x52, 0x65, 0x70, 0x6c, 0x79,\n-\t0x22, 0x28, 0xba, 0xce, 0x95, 0xf1, 0x06, 0x22, 0x08, 0x03, 0x12, 0x1a, 0x62, 0x75, 0x6c, 0x6b,\n-\t0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x53, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72,\n-\t0x79, 0x48, 0x6f, 0x73, 0x74, 0x73, 0x2a, 0x02, 0x08, 0x01, 0x12, 0x38, 0x0a, 0x04, 0x45, 0x63,\n-\t0x68, 0x6f, 0x12, 0x15, 0x2e, 0x70, 0x68, 0x79, 0x73, 0x69, 0x63, 0x61, 0x6c, 0x68, 0x6f, 0x73,\n-\t0x74, 0x2e, 0x45, 0x63, 0x68, 0x6f, 0x52, 0x65, 0x71, 0x1a, 0x17, 0x2e, 0x70, 0x68, 0x79, 0x73,\n-\t0x69, 0x63, 0x61, 0x6c, 0x68, 0x6f, 0x73, 0x74, 0x2e, 0x45, 0x63, 0x68, 0x6f, 0x52, 0x65, 0x70,\n-\t0x6c, 0x79, 0x22, 0x00, 0x1a, 0x27, 0xc2, 0xce, 0x95, 0xf1, 0x06, 0x21, 0x0a, 0x1f, 0x0a, 0x03,\n-\t0x52, 0x42, 0x53, 0x12, 0x0e, 0x49, 0x6e, 0x66, 0x69, 0x6e, 0x69, 0x74, 0x79, 0x20, 0x2d, 0x20,\n-\t0x52, 0x42, 0x53, 0x1a, 0x08, 0x23, 0x72, 0x62, 0x61, 0x2d, 0x64, 0x65, 0x76, 0x42, 0x20, 0xe2,\n-\t0x3f, 0x02, 0x68, 0x01, 0x5a, 0x19, 0x72, 0x75, 0x62, 0x72, 0x69, 0x6b, 0x2f, 0x70, 0x68, 0x79,\n-\t0x73, 0x69, 0x63, 0x61, 0x6c, 0x68, 0x6f, 0x73, 0x74, 0x2f, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x62,\n-\t0x06, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x33,\n+\t0x6f, 0x73, 0x74, 0x73, 0x52, 0x65, 0x70, 0x6c, 0x79, 0x12, 0x50, 0x0a, 0x0c, 0x68, 0x6f, 0x73,\n+\t0x74, 0x5f, 0x72, 0x65, 0x73, 0x75, 0x6c, 0x74, 0x73, 0x18, 0x01, 0x20, 0x03, 0x28, 0x0b, 0x32,\n+\t0x2d, 0x2e, 0x70, 0x68, 0x79, 0x73, 0x69, 0x63, 0x61, 0x6c, 0x68, 0x6f, 0x73, 0x74, 0x2e, 0x48,\n+\t0x6f, 0x73, 0x74, 0x53, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x52, 0x65, 0x67, 0x69,\n+\t0x73, 0x74, 0x72, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x52, 0x65, 0x73, 0x75, 0x6c, 0x74, 0x52, 0x0b,\n+\t0x68, 0x6f, 0x73, 0x74, 0x52, 0x65, 0x73, 0x75, 0x6c, 0x74, 0x73, 0x32, 0x92, 0x02, 0x0a, 0x0c,\n+\t0x50, 0x68, 0x79, 0x73, 0x69, 0x63, 0x61, 0x6c, 0x48, 0x6f, 0x73, 0x74, 0x12, 0x9e, 0x01, 0x0a,\n+\t0x1a, 0x42, 0x75, 0x6c, 0x6b, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x53, 0x65, 0x63,\n+\t0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x48, 0x6f, 0x73, 0x74, 0x73, 0x12, 0x2b, 0x2e, 0x70, 0x68,\n+\t0x79, 0x73, 0x69, 0x63, 0x61, 0x6c, 0x68, 0x6f, 0x73, 0x74, 0x2e, 0x42, 0x75, 0x6c, 0x6b, 0x52,\n+\t0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x53, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79,\n+\t0x48, 0x6f, 0x73, 0x74, 0x73, 0x52, 0x65, 0x71, 0x1a, 0x2d, 0x2e, 0x70, 0x68, 0x79, 0x73, 0x69,\n+\t0x63, 0x61, 0x6c, 0x68, 0x6f, 0x73, 0x74, 0x2e, 0x42, 0x75, 0x6c, 0x6b, 0x52, 0x65, 0x67, 0x69,\n+\t0x73, 0x74, 0x65, 0x72, 0x53, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x48, 0x6f, 0x73,\n+\t0x74, 0x73, 0x52, 0x65, 0x70, 0x6c, 0x79, 0x22, 0x24, 0xba, 0xce, 0x95, 0xf1, 0x06, 0x1e, 0x08,\n+\t0x03, 0x12, 0x1a, 0x62, 0x75, 0x6c, 0x6b, 0x52, 0x65, 0x67, 0x69, 0x73, 0x74, 0x65, 0x72, 0x53,\n+\t0x65, 0x63, 0x6f, 0x6e, 0x64, 0x61, 0x72, 0x79, 0x48, 0x6f, 0x73, 0x74, 0x73, 0x12, 0x38, 0x0a,\n+\t0x04, 0x45, 0x63, 0x68, 0x6f, 0x12, 0x15, 0x2e, 0x70, 0x68, 0x79, 0x73, 0x69, 0x63, 0x61, 0x6c,\n+\t0x68, 0x6f, 0x73, 0x74, 0x2e, 0x45, 0x63, 0x68, 0x6f, 0x52, 0x65, 0x71, 0x1a, 0x17, 0x2e, 0x70,\n+\t0x68, 0x79, 0x73, 0x69, 0x63, 0x61, 0x6c, 0x68, 0x6f, 0x73, 0x74, 0x2e, 0x45, 0x63, 0x68, 0x6f,\n+\t0x52, 0x65, 0x70, 0x6c, 0x79, 0x22, 0x00, 0x1a, 0x27, 0xc2, 0xce, 0x95, 0xf1, 0x06, 0x21, 0x0a,\n+\t0x1f, 0x0a, 0x03, 0x52, 0x42, 0x53, 0x12, 0x0e, 0x49, 0x6e, 0x66, 0x69, 0x6e, 0x69, 0x74, 0x79,\n+\t0x20, 0x2d, 0x20, 0x52, 0x42, 0x53, 0x1a, 0x08, 0x23, 0x72, 0x62, 0x61, 0x2d, 0x64, 0x65, 0x76,\n+\t0x42, 0x20, 0xe2, 0x3f, 0x02, 0x68, 0x01, 0x5a, 0x19, 0x72, 0x75, 0x62, 0x72, 0x69, 0x6b, 0x2f,\n+\t0x70, 0x68, 0x79, 0x73, 0x69, 0x63, 0x61, 0x6c, 0x68, 0x6f, 0x73, 0x74, 0x2f, 0x70, 0x72, 0x6f,\n+\t0x74, 0x6f, 0x62, 0x06, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x33,\n }\n \n var (\n@@ -275,25 +479,33 @@ func file_rubrik_physicalhost_proto_physicalhost_proto_rawDescGZIP() []byte {\n \treturn file_rubrik_physicalhost_proto_physicalhost_proto_rawDescData\n }\n \n-var file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes = make([]protoimpl.MessageInfo, 4)\n+var file_rubrik_physicalhost_proto_physicalhost_proto_msgTypes = make([]protoimpl.MessageInfo, 6)\n var file_rubrik_physicalhost_proto_physicalhost_proto_goTypes = []interface{}{\n-\t(*EchoReq)(nil),                         // 0: physicalhost.EchoReq\n-\t(*EchoReply)(nil),                       // 1: physicalhost.EchoReply\n-\t(*BulkRegisterSecondaryHostsReq)(nil),   // 2: physicalhost.BulkRegisterSecondaryHostsReq\n-\t(*BulkRegisterSecondaryHostsReply)(nil), // 3: physicalhost.BulkRegisterSecondaryHostsReply\n-\t(*proto.RequestContext)(nil),            // 4: context.RequestContext\n+\t(*EchoReq)(nil),                            // 0: physicalhost.EchoReq\n+\t(*EchoReply)(nil),                          // 1: physicalhost.EchoReply\n+\t(*SecondaryRegisterHostInput)(nil),         // 2: physicalhost.SecondaryRegisterHostInput\n+\t(*BulkRegisterSecondaryHostsReq)(nil),      // 3: physicalhost.BulkRegisterSecondaryHostsReq\n+\t(*HostSecondaryRegistrationResult)(nil),    // 4: physicalhost.HostSecondaryRegistrationResult\n+\t(*BulkRegisterSecondaryHostsReply)(nil),    // 5: physicalhost.BulkRegisterSecondaryHostsReply\n+\t(types.HostRegister_HostRegisterOsType)(0), // 6: cdmrestservice.HostRegister.HostRegisterOsType\n+\t(*proto.RequestContext)(nil),               // 7: context.RequestContext\n+\t(*types.HostDetail)(nil),                   // 8: cdmrestservice.HostDetail\n }\n var file_rubrik_physicalhost_proto_physicalhost_proto_depIdxs = []int32{\n-\t4, // 0: physicalhost.BulkRegisterSecondaryHostsReq.req_ctx:type_name -> context.RequestContext\n-\t2, // 1: physicalhost.PhysicalHost.BulkRegisterSecondaryHosts:input_type -> physicalhost.BulkRegisterSecondaryHostsReq\n-\t0, // 2: physicalhost.PhysicalHost.Echo:input_type -> physicalhost.EchoReq\n-\t3, // 3: physicalhost.PhysicalHost.BulkRegisterSecondaryHosts:output_type -> physicalhost.BulkRegisterSecondaryHostsReply\n-\t1, // 4: physicalhost.PhysicalHost.Echo:output_type -> physicalhost.EchoReply\n-\t3, // [3:5] is the sub-list for method output_type\n-\t1, // [1:3] is the sub-list for method input_type\n-\t1, // [1:1] is the sub-list for extension type_name\n-\t1, // [1:1] is the sub-list for extension extendee\n-\t0, // [0:1] is the sub-list for field type_name\n+\t6, // 0: physicalhost.SecondaryRegisterHostInput.os_type:type_name -> cdmrestservice.HostRegister.HostRegisterOsType\n+\t7, // 1: physicalhost.BulkRegisterSecondaryHostsReq.req_ctx:type_name -> context.RequestContext\n+\t2, // 2: physicalhost.BulkRegisterSecondaryHostsReq.hosts:type_name -> physicalhost.SecondaryRegisterHostInput\n+\t8, // 3: physicalhost.HostSecondaryRegistrationResult.host_detail:type_name -> cdmrestservice.HostDetail\n+\t4, // 4: physicalhost.BulkRegisterSecondaryHostsReply.host_results:type_name -> physicalhost.HostSecondaryRegistrationResult\n+\t3, // 5: physicalhost.PhysicalHost.BulkRegisterSecondaryHosts:input_type -> physicalhost.BulkRegisterSecondaryHostsReq\n+\t0, // 6: physicalhost.PhysicalHost.Echo:input_type -> physicalhost.EchoReq\n+\t5, // 7: physicalhost.PhysicalHost.BulkRegisterSecondaryHosts:output_type -> physicalhost.BulkRegisterSecondaryHostsReply\n+\t1, // 8: physicalhost.PhysicalHost.Echo:output_type -> physicalhost.EchoReply\n+\t7, // [7:9] is the sub-list for method output_type\n+\t5, // [5:7] is the sub-list for method input_type\n+\t5, // [5:5] is the sub-list for extension type_name\n+\t5, // [5:5] is the sub-list for extension extendee\n+\t0, // [0:5] is the sub-list for field type_name\n }\n \n func init() { file_rubrik_physicalhost_proto_physicalhost_proto_init() }\n@@ -327,7 +539,7 @@ func file_rubrik_physicalhost_proto_physicalhost_proto_init() {\n \t\t\t}\n \t\t}\n \t\tfile_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[2].Exporter = func(v interface{}, i int) interface{} {\n-\t\t\tswitch v := v.(*BulkRegisterSecondaryHostsReq); i {\n+\t\t\tswitch v := v.(*SecondaryRegisterHostInput); i {\n \t\t\tcase 0:\n \t\t\t\treturn &v.state\n \t\t\tcase 1:\n@@ -339,6 +551,30 @@ func file_rubrik_physicalhost_proto_physicalhost_proto_init() {\n \t\t\t}\n \t\t}\n \t\tfile_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[3].Exporter = func(v interface{}, i int) interface{} {\n+\t\t\tswitch v := v.(*BulkRegisterSecondaryHostsReq); i {\n+\t\t\tcase 0:\n+\t\t\t\treturn &v.state\n+\t\t\tcase 1:\n+\t\t\t\treturn &v.sizeCache\n+\t\t\tcase 2:\n+\t\t\t\treturn &v.unknownFields\n+\t\t\tdefault:\n+\t\t\t\treturn nil\n+\t\t\t}\n+\t\t}\n+\t\tfile_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[4].Exporter = func(v interface{}, i int) interface{} {\n+\t\t\tswitch v := v.(*HostSecondaryRegistrationResult); i {\n+\t\t\tcase 0:\n+\t\t\t\treturn &v.state\n+\t\t\tcase 1:\n+\t\t\t\treturn &v.sizeCache\n+\t\t\tcase 2:\n+\t\t\t\treturn &v.unknownFields\n+\t\t\tdefault:\n+\t\t\t\treturn nil\n+\t\t\t}\n+\t\t}\n+\t\tfile_rubrik_physicalhost_proto_physicalhost_proto_msgTypes[5].Exporter = func(v interface{}, i int) interface{} {\n \t\t\tswitch v := v.(*BulkRegisterSecondaryHostsReply); i {\n \t\t\tcase 0:\n \t\t\t\treturn &v.state\n@@ -357,7 +593,7 @@ func file_rubrik_physicalhost_proto_physicalhost_proto_init() {\n \t\t\tGoPackagePath: reflect.TypeOf(x{}).PkgPath(),\n \t\t\tRawDescriptor: file_rubrik_physicalhost_proto_physicalhost_proto_rawDesc,\n \t\t\tNumEnums:      0,\n-\t\t\tNumMessages:   4,\n+\t\t\tNumMessages:   6,\n \t\t\tNumExtensions: 0,\n \t\t\tNumServices:   1,\n \t\t},\n@@ -384,6 +620,7 @@ const _ = grpc.SupportPackageIsVersion6\n // For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.\n type PhysicalHostClient interface {\n \t// BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n+\t// @param input The request containing secondary cluster UUID and hosts to register.\n \tBulkRegisterSecondaryHosts(ctx context.Context, in *BulkRegisterSecondaryHostsReq, opts ...grpc.CallOption) (*BulkRegisterSecondaryHostsReply, error)\n \t// Echo performs a simple echo operation for testing connectivity and service health.\n \t// This is primarily used for service validation and debugging purposes.\n@@ -419,6 +656,7 @@ func (c *physicalHostClient) Echo(ctx context.Context, in *EchoReq, opts ...grpc\n // PhysicalHostServer is the server API for PhysicalHost service.\n type PhysicalHostServer interface {\n \t// BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n+\t// @param input The request containing secondary cluster UUID and hosts to register.\n \tBulkRegisterSecondaryHosts(context.Context, *BulkRegisterSecondaryHostsReq) (*BulkRegisterSecondaryHostsReply, error)\n \t// Echo performs a simple echo operation for testing connectivity and service health.\n \t// This is primarily used for service validation and debugging purposes."
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/proto/physicalhost.proto",
          "status": "modified",
          "additions": 34,
          "deletions": 5,
          "patch": "@@ -6,6 +6,7 @@ option go_package = \"rubrik/physicalhost/proto\";\n import \"rubrik/common-go/api/context/proto/context.proto\";\n import \"rubrik/api-server/app/v2/proto/api.proto\";\n import \"rubrik/scalapb/proto/scalapb.proto\";\n+import \"rubrik/cdm-rest-service/proto/types/cdmrestservice_types.proto\";\n \n option (scalapb.options) = {\n   retain_source_code_info: true\n@@ -23,16 +24,12 @@ service PhysicalHost {\n     }\n   };\n \n-  // TODO(SPARK-572184): Implement BulkRegisterSecondaryHosts\n-\n   // BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n+  // @param input The request containing secondary cluster UUID and hosts to register.\n   rpc BulkRegisterSecondaryHosts (BulkRegisterSecondaryHostsReq) returns (BulkRegisterSecondaryHostsReply) {\n     option (api.graphql_method) = {\n       type: MUTATION\n       name: \"bulkRegisterSecondaryHosts\"\n-      tags: [\n-        { type: HIDDEN }\n-      ]\n     };\n   }\n \n@@ -53,11 +50,43 @@ message EchoReply {\n   string reply = 1;\n }\n \n+// Host details for secondary registration.\n+message SecondaryRegisterHostInput {\n+  // The host FID (unique identifier).\n+  string host_fid = 1 [(api.graphql_field).requiredness = REQUIRED];\n+\n+  // UUID of the primary cluster where the host currently resides.\n+  string primary_cluster_uuid = 2 [(api.graphql_field).requiredness = REQUIRED];\n+\n+  // Operating system type of the host.\n+  cdmrestservice.HostRegister.HostRegisterOsType os_type = 3;\n+}\n+\n // Request message for bulk registration of secondary hosts.\n message BulkRegisterSecondaryHostsReq {\n   context.RequestContext req_ctx = 1;\n+\n+  // UUID of the secondary cluster where hosts will be registered.\n+  string secondary_cluster_uuid = 2 [(api.graphql_field).requiredness = REQUIRED];\n+\n+  // List of hosts to register as secondary hosts.\n+  repeated SecondaryRegisterHostInput hosts = 3 [(api.graphql_field).requiredness = REQUIRED];\n+}\n+\n+// Result for a single host registration.\n+message HostSecondaryRegistrationResult {\n+  // The host FID that was processed.\n+  string primary_host_fid = 1;\n+\n+  // Error message if registration failed.\n+  string error_message = 2;\n+\n+  // Host details of secondary registration if registration was successful.\n+  cdmrestservice.HostDetail host_detail = 3;\n }\n \n // Response message for bulk registration of secondary hosts.\n message BulkRegisterSecondaryHostsReply {\n+  // Results for each host that was processed.\n+  repeated HostSecondaryRegistrationResult host_results = 1;\n }"
        },
        {
          "filename": "polaris/src/rubrik/sdk_internal/grpc/physicalhost_pb2.py",
          "status": "modified",
          "additions": 151,
          "deletions": 13,
          "patch": "@@ -14,6 +14,7 @@\n import rubrik.sdk_internal.grpc.context_pb2 as rubrik_dot_common__go_dot_api_dot_context_dot_proto_dot_context__pb2\n import rubrik.sdk_internal.grpc.api_pb2 as rubrik_dot_api__server_dot_app_dot_v2_dot_proto_dot_api__pb2\n import rubrik.sdk_internal.grpc.scalapb_pb2 as rubrik_dot_scalapb_dot_proto_dot_scalapb__pb2\n+import rubrik.sdk_internal.grpc.cdmrestservice_types_pb2 as rubrik_dot_cdm__rest__service_dot_proto_dot_types_dot_cdmrestservice__types__pb2\n \n \n PROTO_SRC = \"src/rubrik/physicalhost/proto/physicalhost.proto\"\n@@ -23,9 +24,9 @@\n   syntax='proto3',\n   serialized_options=b'Z\\031rubrik/physicalhost/proto\\342?\\002h\\001',\n   create_key=_descriptor._internal_create_key,\n-  serialized_pb=b'\\n\\x12physicalhost.proto\\x12\\x0cphysicalhost\\x1a\\x30rubrik/common-go/api/context/proto/context.proto\\x1a(rubrik/api-server/app/v2/proto/api.proto\\x1a\\\"rubrik/scalapb/proto/scalapb.proto\\\"\\x17\\n\\x07\\x45\\x63hoReq\\x12\\x0c\\n\\x04\\x61rg1\\x18\\x01 \\x01(\\t\\\"\\x1a\\n\\tEchoReply\\x12\\r\\n\\x05reply\\x18\\x01 \\x01(\\t\\\"I\\n\\x1d\\x42ulkRegisterSecondaryHostsReq\\x12(\\n\\x07req_ctx\\x18\\x01 \\x01(\\x0b\\x32\\x17.context.RequestContext\\\"!\\n\\x1f\\x42ulkRegisterSecondaryHostsReply2\\x96\\x02\\n\\x0cPhysicalHost\\x12\\xa2\\x01\\n\\x1a\\x42ulkRegisterSecondaryHosts\\x12+.physicalhost.BulkRegisterSecondaryHostsReq\\x1a-.physicalhost.BulkRegisterSecondaryHostsReply\\\"(\\xba\\xce\\x95\\xf1\\x06\\\"\\x08\\x03\\x12\\x1a\\x62ulkRegisterSecondaryHosts*\\x02\\x08\\x01\\x12\\x38\\n\\x04\\x45\\x63ho\\x12\\x15.physicalhost.EchoReq\\x1a\\x17.physicalhost.EchoReply\\\"\\x00\\x1a\\'\\xc2\\xce\\x95\\xf1\\x06!\\n\\x1f\\n\\x03RBS\\x12\\x0eInfinity - RBS\\x1a\\x08#rba-devB Z\\x19rubrik/physicalhost/proto\\xe2?\\x02h\\x01\\x62\\x06proto3'\n+  serialized_pb=b'\\n\\x12physicalhost.proto\\x12\\x0cphysicalhost\\x1a\\x30rubrik/common-go/api/context/proto/context.proto\\x1a(rubrik/api-server/app/v2/proto/api.proto\\x1a\\\"rubrik/scalapb/proto/scalapb.proto\\x1a>rubrik/cdm-rest-service/proto/types/cdmrestservice_types.proto\\\"\\x17\\n\\x07\\x45\\x63hoReq\\x12\\x0c\\n\\x04\\x61rg1\\x18\\x01 \\x01(\\t\\\"\\x1a\\n\\tEchoReply\\x12\\r\\n\\x05reply\\x18\\x01 \\x01(\\t\\\"\\xa2\\x01\\n\\x1aSecondaryRegisterHostInput\\x12\\x1a\\n\\x08host_fid\\x18\\x01 \\x01(\\tB\\x08\\x92\\xa2\\xb9\\xb8\\x04\\x02\\x10\\x01\\x12&\\n\\x14primary_cluster_uuid\\x18\\x02 \\x01(\\tB\\x08\\x92\\xa2\\xb9\\xb8\\x04\\x02\\x10\\x01\\x12@\\n\\x07os_type\\x18\\x03 \\x01(\\x0e\\x32/.cdmrestservice.HostRegister.HostRegisterOsType\\\"\\xb6\\x01\\n\\x1d\\x42ulkRegisterSecondaryHostsReq\\x12(\\n\\x07req_ctx\\x18\\x01 \\x01(\\x0b\\x32\\x17.context.RequestContext\\x12(\\n\\x16secondary_cluster_uuid\\x18\\x02 \\x01(\\tB\\x08\\x92\\xa2\\xb9\\xb8\\x04\\x02\\x10\\x01\\x12\\x41\\n\\x05hosts\\x18\\x03 \\x03(\\x0b\\x32(.physicalhost.SecondaryRegisterHostInputB\\x08\\x92\\xa2\\xb9\\xb8\\x04\\x02\\x10\\x01\\\"\\x83\\x01\\n\\x1fHostSecondaryRegistrationResult\\x12\\x18\\n\\x10primary_host_fid\\x18\\x01 \\x01(\\t\\x12\\x15\\n\\rerror_message\\x18\\x02 \\x01(\\t\\x12/\\n\\x0bhost_detail\\x18\\x03 \\x01(\\x0b\\x32\\x1a.cdmrestservice.HostDetail\\\"f\\n\\x1f\\x42ulkRegisterSecondaryHostsReply\\x12\\x43\\n\\x0chost_results\\x18\\x01 \\x03(\\x0b\\x32-.physicalhost.HostSecondaryRegistrationResult2\\x92\\x02\\n\\x0cPhysicalHost\\x12\\x9e\\x01\\n\\x1a\\x42ulkRegisterSecondaryHosts\\x12+.physicalhost.BulkRegisterSecondaryHostsReq\\x1a-.physicalhost.BulkRegisterSecondaryHostsReply\\\"$\\xba\\xce\\x95\\xf1\\x06\\x1e\\x08\\x03\\x12\\x1a\\x62ulkRegisterSecondaryHosts\\x12\\x38\\n\\x04\\x45\\x63ho\\x12\\x15.physicalhost.EchoReq\\x1a\\x17.physicalhost.EchoReply\\\"\\x00\\x1a\\'\\xc2\\xce\\x95\\xf1\\x06!\\n\\x1f\\n\\x03RBS\\x12\\x0eInfinity - RBS\\x1a\\x08#rba-devB Z\\x19rubrik/physicalhost/proto\\xe2?\\x02h\\x01\\x62\\x06proto3'\n   ,\n-  dependencies=[rubrik_dot_common__go_dot_api_dot_context_dot_proto_dot_context__pb2.DESCRIPTOR,rubrik_dot_api__server_dot_app_dot_v2_dot_proto_dot_api__pb2.DESCRIPTOR,rubrik_dot_scalapb_dot_proto_dot_scalapb__pb2.DESCRIPTOR,])\n+  dependencies=[rubrik_dot_common__go_dot_api_dot_context_dot_proto_dot_context__pb2.DESCRIPTOR,rubrik_dot_api__server_dot_app_dot_v2_dot_proto_dot_api__pb2.DESCRIPTOR,rubrik_dot_scalapb_dot_proto_dot_scalapb__pb2.DESCRIPTOR,rubrik_dot_cdm__rest__service_dot_proto_dot_types_dot_cdmrestservice__types__pb2.DESCRIPTOR,])\n \n \n \n@@ -57,8 +58,8 @@\n   extension_ranges=[],\n   oneofs=[\n   ],\n-  serialized_start=164,\n-  serialized_end=187,\n+  serialized_start=228,\n+  serialized_end=251,\n )\n \n \n@@ -89,8 +90,54 @@\n   extension_ranges=[],\n   oneofs=[\n   ],\n-  serialized_start=189,\n-  serialized_end=215,\n+  serialized_start=253,\n+  serialized_end=279,\n+)\n+\n+\n+_SECONDARYREGISTERHOSTINPUT = _descriptor.Descriptor(\n+  name='SecondaryRegisterHostInput',\n+  full_name='physicalhost.SecondaryRegisterHostInput',\n+  filename=None,\n+  file=DESCRIPTOR,\n+  containing_type=None,\n+  create_key=_descriptor._internal_create_key,\n+  fields=[\n+    _descriptor.FieldDescriptor(\n+      name='host_fid', full_name='physicalhost.SecondaryRegisterHostInput.host_fid', index=0,\n+      number=1, type=9, cpp_type=9, label=1,\n+      has_default_value=False, default_value=b\"\".decode('utf-8'),\n+      message_type=None, enum_type=None, containing_type=None,\n+      is_extension=False, extension_scope=None,\n+      serialized_options=b'\\222\\242\\271\\270\\004\\002\\020\\001', file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n+    _descriptor.FieldDescriptor(\n+      name='primary_cluster_uuid', full_name='physicalhost.SecondaryRegisterHostInput.primary_cluster_uuid', index=1,\n+      number=2, type=9, cpp_type=9, label=1,\n+      has_default_value=False, default_value=b\"\".decode('utf-8'),\n+      message_type=None, enum_type=None, containing_type=None,\n+      is_extension=False, extension_scope=None,\n+      serialized_options=b'\\222\\242\\271\\270\\004\\002\\020\\001', file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n+    _descriptor.FieldDescriptor(\n+      name='os_type', full_name='physicalhost.SecondaryRegisterHostInput.os_type', index=2,\n+      number=3, type=14, cpp_type=8, label=1,\n+      has_default_value=False, default_value=0,\n+      message_type=None, enum_type=None, containing_type=None,\n+      is_extension=False, extension_scope=None,\n+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n+  ],\n+  extensions=[\n+  ],\n+  nested_types=[],\n+  enum_types=[\n+  ],\n+  serialized_options=None,\n+  is_extendable=False,\n+  syntax='proto3',\n+  extension_ranges=[],\n+  oneofs=[\n+  ],\n+  serialized_start=282,\n+  serialized_end=444,\n )\n \n \n@@ -109,6 +156,66 @@\n       message_type=None, enum_type=None, containing_type=None,\n       is_extension=False, extension_scope=None,\n       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n+    _descriptor.FieldDescriptor(\n+      name='secondary_cluster_uuid', full_name='physicalhost.BulkRegisterSecondaryHostsReq.secondary_cluster_uuid', index=1,\n+      number=2, type=9, cpp_type=9, label=1,\n+      has_default_value=False, default_value=b\"\".decode('utf-8'),\n+      message_type=None, enum_type=None, containing_type=None,\n+      is_extension=False, extension_scope=None,\n+      serialized_options=b'\\222\\242\\271\\270\\004\\002\\020\\001', file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n+    _descriptor.FieldDescriptor(\n+      name='hosts', full_name='physicalhost.BulkRegisterSecondaryHostsReq.hosts', index=2,\n+      number=3, type=11, cpp_type=10, label=3,\n+      has_default_value=False, default_value=[],\n+      message_type=None, enum_type=None, containing_type=None,\n+      is_extension=False, extension_scope=None,\n+      serialized_options=b'\\222\\242\\271\\270\\004\\002\\020\\001', file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n+  ],\n+  extensions=[\n+  ],\n+  nested_types=[],\n+  enum_types=[\n+  ],\n+  serialized_options=None,\n+  is_extendable=False,\n+  syntax='proto3',\n+  extension_ranges=[],\n+  oneofs=[\n+  ],\n+  serialized_start=447,\n+  serialized_end=629,\n+)\n+\n+\n+_HOSTSECONDARYREGISTRATIONRESULT = _descriptor.Descriptor(\n+  name='HostSecondaryRegistrationResult',\n+  full_name='physicalhost.HostSecondaryRegistrationResult',\n+  filename=None,\n+  file=DESCRIPTOR,\n+  containing_type=None,\n+  create_key=_descriptor._internal_create_key,\n+  fields=[\n+    _descriptor.FieldDescriptor(\n+      name='primary_host_fid', full_name='physicalhost.HostSecondaryRegistrationResult.primary_host_fid', index=0,\n+      number=1, type=9, cpp_type=9, label=1,\n+      has_default_value=False, default_value=b\"\".decode('utf-8'),\n+      message_type=None, enum_type=None, containing_type=None,\n+      is_extension=False, extension_scope=None,\n+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n+    _descriptor.FieldDescriptor(\n+      name='error_message', full_name='physicalhost.HostSecondaryRegistrationResult.error_message', index=1,\n+      number=2, type=9, cpp_type=9, label=1,\n+      has_default_value=False, default_value=b\"\".decode('utf-8'),\n+      message_type=None, enum_type=None, containing_type=None,\n+      is_extension=False, extension_scope=None,\n+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n+    _descriptor.FieldDescriptor(\n+      name='host_detail', full_name='physicalhost.HostSecondaryRegistrationResult.host_detail', index=2,\n+      number=3, type=11, cpp_type=10, label=1,\n+      has_default_value=False, default_value=None,\n+      message_type=None, enum_type=None, containing_type=None,\n+      is_extension=False, extension_scope=None,\n+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n   ],\n   extensions=[\n   ],\n@@ -121,8 +228,8 @@\n   extension_ranges=[],\n   oneofs=[\n   ],\n-  serialized_start=217,\n-  serialized_end=290,\n+  serialized_start=632,\n+  serialized_end=763,\n )\n \n \n@@ -134,6 +241,13 @@\n   containing_type=None,\n   create_key=_descriptor._internal_create_key,\n   fields=[\n+    _descriptor.FieldDescriptor(\n+      name='host_results', full_name='physicalhost.BulkRegisterSecondaryHostsReply.host_results', index=0,\n+      number=1, type=11, cpp_type=10, label=3,\n+      has_default_value=False, default_value=[],\n+      message_type=None, enum_type=None, containing_type=None,\n+      is_extension=False, extension_scope=None,\n+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n   ],\n   extensions=[\n   ],\n@@ -146,14 +260,20 @@\n   extension_ranges=[],\n   oneofs=[\n   ],\n-  serialized_start=292,\n-  serialized_end=325,\n+  serialized_start=765,\n+  serialized_end=867,\n )\n \n+_SECONDARYREGISTERHOSTINPUT.fields_by_name['os_type'].enum_type = rubrik_dot_cdm__rest__service_dot_proto_dot_types_dot_cdmrestservice__types__pb2._HOSTREGISTER_HOSTREGISTEROSTYPE\n _BULKREGISTERSECONDARYHOSTSREQ.fields_by_name['req_ctx'].message_type = rubrik_dot_common__go_dot_api_dot_context_dot_proto_dot_context__pb2._REQUESTCONTEXT\n+_BULKREGISTERSECONDARYHOSTSREQ.fields_by_name['hosts'].message_type = _SECONDARYREGISTERHOSTINPUT\n+_HOSTSECONDARYREGISTRATIONRESULT.fields_by_name['host_detail'].message_type = rubrik_dot_cdm__rest__service_dot_proto_dot_types_dot_cdmrestservice__types__pb2._HOSTDETAIL\n+_BULKREGISTERSECONDARYHOSTSREPLY.fields_by_name['host_results'].message_type = _HOSTSECONDARYREGISTRATIONRESULT\n DESCRIPTOR.message_types_by_name['EchoReq'] = _ECHOREQ\n DESCRIPTOR.message_types_by_name['EchoReply'] = _ECHOREPLY\n+DESCRIPTOR.message_types_by_name['SecondaryRegisterHostInput'] = _SECONDARYREGISTERHOSTINPUT\n DESCRIPTOR.message_types_by_name['BulkRegisterSecondaryHostsReq'] = _BULKREGISTERSECONDARYHOSTSREQ\n+DESCRIPTOR.message_types_by_name['HostSecondaryRegistrationResult'] = _HOSTSECONDARYREGISTRATIONRESULT\n DESCRIPTOR.message_types_by_name['BulkRegisterSecondaryHostsReply'] = _BULKREGISTERSECONDARYHOSTSREPLY\n _sym_db.RegisterFileDescriptor(DESCRIPTOR)\n \n@@ -171,13 +291,27 @@\n   })\n _sym_db.RegisterMessage(EchoReply)\n \n+SecondaryRegisterHostInput = _reflection.GeneratedProtocolMessageType('SecondaryRegisterHostInput', (_message.Message,), {\n+  'DESCRIPTOR' : _SECONDARYREGISTERHOSTINPUT,\n+  '__module__' : 'physicalhost_pb2'\n+  # @@protoc_insertion_point(class_scope:physicalhost.SecondaryRegisterHostInput)\n+  })\n+_sym_db.RegisterMessage(SecondaryRegisterHostInput)\n+\n BulkRegisterSecondaryHostsReq = _reflection.GeneratedProtocolMessageType('BulkRegisterSecondaryHostsReq', (_message.Message,), {\n   'DESCRIPTOR' : _BULKREGISTERSECONDARYHOSTSREQ,\n   '__module__' : 'physicalhost_pb2'\n   # @@protoc_insertion_point(class_scope:physicalhost.BulkRegisterSecondaryHostsReq)\n   })\n _sym_db.RegisterMessage(BulkRegisterSecondaryHostsReq)\n \n+HostSecondaryRegistrationResult = _reflection.GeneratedProtocolMessageType('HostSecondaryRegistrationResult', (_message.Message,), {\n+  'DESCRIPTOR' : _HOSTSECONDARYREGISTRATIONRESULT,\n+  '__module__' : 'physicalhost_pb2'\n+  # @@protoc_insertion_point(class_scope:physicalhost.HostSecondaryRegistrationResult)\n+  })\n+_sym_db.RegisterMessage(HostSecondaryRegistrationResult)\n+\n BulkRegisterSecondaryHostsReply = _reflection.GeneratedProtocolMessageType('BulkRegisterSecondaryHostsReply', (_message.Message,), {\n   'DESCRIPTOR' : _BULKREGISTERSECONDARYHOSTSREPLY,\n   '__module__' : 'physicalhost_pb2'\n@@ -187,6 +321,10 @@\n \n \n DESCRIPTOR._options = None\n+_SECONDARYREGISTERHOSTINPUT.fields_by_name['host_fid']._options = None\n+_SECONDARYREGISTERHOSTINPUT.fields_by_name['primary_cluster_uuid']._options = None\n+_BULKREGISTERSECONDARYHOSTSREQ.fields_by_name['secondary_cluster_uuid']._options = None\n+_BULKREGISTERSECONDARYHOSTSREQ.fields_by_name['hosts']._options = None\n \n _PHYSICALHOST = _descriptor.ServiceDescriptor(\n   name='PhysicalHost',\n@@ -195,8 +333,8 @@\n   index=0,\n   serialized_options=b'\\302\\316\\225\\361\\006!\\n\\037\\n\\003RBS\\022\\016Infinity - RBS\\032\\010#rba-dev',\n   create_key=_descriptor._internal_create_key,\n-  serialized_start=328,\n-  serialized_end=606,\n+  serialized_start=870,\n+  serialized_end=1144,\n   methods=[\n   _descriptor.MethodDescriptor(\n     name='BulkRegisterSecondaryHosts',\n@@ -205,7 +343,7 @@\n     containing_service=None,\n     input_type=_BULKREGISTERSECONDARYHOSTSREQ,\n     output_type=_BULKREGISTERSECONDARYHOSTSREPLY,\n-    serialized_options=b'\\272\\316\\225\\361\\006\\\"\\010\\003\\022\\032bulkRegisterSecondaryHosts*\\002\\010\\001',\n+    serialized_options=b'\\272\\316\\225\\361\\006\\036\\010\\003\\022\\032bulkRegisterSecondaryHosts',\n     create_key=_descriptor._internal_create_key,\n   ),\n   _descriptor.MethodDescriptor("
        },
        {
          "filename": "polaris/src/rubrik/sdk_internal/grpc/physicalhost_pb2_grpc.py",
          "status": "modified",
          "additions": 2,
          "deletions": 3,
          "patch": "@@ -36,9 +36,8 @@ class PhysicalHostServicer(object):\n     \"\"\"\n \n     def BulkRegisterSecondaryHosts(self, request, context):\n-        \"\"\"TODO(SPARK-572184): Implement BulkRegisterSecondaryHosts\n-\n-        BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n+        \"\"\"BulkRegisterSecondaryHosts is used to register secondary hosts in bulk.\n+        @param input The request containing secondary cluster UUID and hosts to register.\n         \"\"\"\n         context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n         context.set_details('Method not implemented!')"
        },
        {
          "filename": "polaris/yodalibs/generated/gql_inputs.py",
          "status": "modified",
          "additions": 13,
          "deletions": 0,
          "patch": "@@ -2838,6 +2838,12 @@ class BulkRegisterHostInput:\n     clusterUuid: str\n     hosts: List['HostRegisterInput']\n \n+@dataclass_json\n+@dataclass\n+class BulkRegisterSecondaryHostsInput:\n+    hosts: List['SecondaryRegisterHostInput']\n+    secondaryClusterUuid: str\n+\n @dataclass_json\n @dataclass\n class BulkRestoreM365BackupStorageObjectsInput:\n@@ -15808,6 +15814,13 @@ class SearchVectorDBInput:\n     query: str\n     topK: Optional[int] = None\n \n+@dataclass_json\n+@dataclass\n+class SecondaryRegisterHostInput:\n+    hostFid: str\n+    primaryClusterUuid: str\n+    osType: Optional['HostRegisterOsType'] = None\n+\n @dataclass_json\n @dataclass\n class SecureAuthAzureKeyVaultDetails:"
        }
      ],
      "statistics": {
        "commits": 6,
        "files_changed": 14,
        "additions": 1114,
        "deletions": 80,
        "total_comments": 45
      }
    },
    "processed_data": {
      "title": "PR Review: Add RBAC test for the bulk secondary register host",
      "summary": "## Summary:\n- Added rbac check for bulk secondary register api.\r\n- Created request and response message protos for the same.\r\n\r\nRBAC Design:\r\nhttps://docs.google.com/document/d/1PfqHPiWWrg6N2iZ3pvJ1Bo...",
      "action_items": [
        {
          "item": "Review PR: Add RBAC test for the bulk secondary register host",
          "priority": "medium",
          "next_steps": [
            "Read description",
            "Review code changes",
            "Test locally"
          ]
        },
        {
          "item": "Address code review comments",
          "priority": "high",
          "next_steps": [
            "Review inline comments",
            "Make necessary changes",
            "Respond to reviewers"
          ]
        }
      ],
      "urgency_score": 1.0,
      "context": "GitHub PR in master branch"
    }
  },
  {
    "source": "github",
    "candidate_id": "github_pr_97821",
    "raw_data": {
      "pr_title": "Send audits for failed secondary host registration",
      "pr_summary": "## Summary:\n- Added new audit for failed secondary host registration.\r\n- Added an audit sender to the physicalhost service.\r\n- Sending audits for failed secondary host registration.\r\n\r\nRef: https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/442826876/Sending+Polaris+Event+Audit\n\n## Test Plan:\nManual testing and UTs\r\n\r\n### Manual testing plan:\r\n\r\n<img width=\"1407\" height=\"358\" alt=\"image\" src=\"https://github.com/user-attachments/assets/10ee8da2-a30c-43d9-95ca-7d7b97f6d515\" />\n\n## JIRA Issues:\nSPARK-572184\n\n## Revert Plan:\n## PR Stack:\nStack from arc wrapper with help from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):\n* __->__ #97821\n* #97551\n* #97450\n* #97449\n",
      "pr_url": "https://github.com/scaledata/sdmain/pull/97821",
      "metadata": {
        "number": 97821,
        "state": "open",
        "author": "moht-agrawal-rubrik",
        "created_at": "2025-09-03T06:09:01Z",
        "updated_at": "2025-09-09T18:40:07Z",
        "merged_at": null,
        "base_branch": "gh/moht-agrawal-rubrik/17/head",
        "head_branch": "gh/moht-agrawal-rubrik/18/head",
        "labels": [],
        "assignees": [
          "jordanbarkley",
          "Nagavenimythri",
          "Arqum212",
          "sreshth-dev"
        ],
        "reviewers": [
          "Nagavenimythri",
          "Arqum212"
        ]
      },
      "comments": {
        "global_comments": [
          {
            "type": "discussion",
            "author": "rogers-sail-information[bot]",
            "created_at": "2025-09-03T06:09:33Z",
            "body": "<!-- rogers sail info comment -->\n## Sail Request\n\n> Rogers will automatically update this comment to reflect the current sail status of your PR when you begin a sail request.",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#issuecomment-3247811330"
          },
          {
            "type": "discussion",
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-04T07:47:16Z",
            "body": "_:hourglass: Your RR [scaledata/sdmain/97821](https://github.com/scaledata/sdmain/pull/97821) has not been reviewed within the SLO. Resigning the following blocking reviewers:_\n * @scaledata/rba-shadow\n * @scaledata/rba-rba-reviews",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#issuecomment-3252358761"
          },
          {
            "type": "discussion",
            "author": "rubrik-alfred[bot]",
            "created_at": "2025-09-09T18:40:07Z",
            "body": "## :man_in_tuxedo: Alfred Comments\n<input type='hidden' commit='61598da389fa54cfafb0039eb098df35b95fe4fa' global='true'/>\n<!--Header_Done-->\n\nThese changes might require a full GCP upgrade to validate. Refer to [this](https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/2672918625/Platform+Infra+Reviews) for more context \nRun `arc sail --additional_tests canary-pipeline`if some of the following is True:\n* Some change other than memory, CPU, replicas etc\n* The changed service is a third-party service\n* The changed service was not deployed on GCP. (If done, include in test plan).Requires review from #platform_polaris-platform-infra-reviews.\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/sdk_internal/services/gps/datacenter/physicalhost_service.py</code></li>\n</ul>\n</details>\n\n\n------\n\nTouching Polaris deployment scripts requires review from #platform_polaris-platform-infra-reviews.\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/sdk_internal/services/gps/datacenter/physicalhost_service.py</code></li>\n</ul>\n</details>\n\n\n------\n\nMake sure you check these lines.\n\n<details><summary>Click here to view the Inline Comments</summary><ul><li><a href=\"https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455741\">https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455741</a></li></ul></details>\n\n------\n\nPlease follow [Sending Polaris Event/Audit](https://rubrik.atlassian.net/wiki/spaces/SPARK/pages/442826876/Sending+Polaris+Event+Audit) if adding a new event/audit. Changes to user visible audits, events and notifications should be reviewed by #rsc_documentation_rsc_doc_diff_reviews. \n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/common-go/audits/templates/cdm-host.yml</code></li>\n</ul>\n</details>\n\n\n------\n\n Looks like you are modifying Polaris Events related code. This needs review by #polaris_events_watchers-events-reviews.     \n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/common-go/audits/templates/cdm-host.yml</code></li>\n</ul>\n</details>\n\n\n------\n\nTriggering the detect-changed-services pipeline. If your PR is raised against a Polaris release branch, this pipeline will leave a comment with a list of the services that will be affected by the changes in your PR.\n\n\nThe following jobs are triggered:\n\n\n- [detect-changed-services](https://polaris-builds.stark.rubrik.com/job/detect-changed-services)\n\n\n<details>\n<summary>Click here to view the file paths triggering these jobs</summary>\n<ul>\n<li><code>polaris/src/rubrik/common-go/audits/templates/cdm-host.yml</code></li>\n<li><code>polaris/src/rubrik/physicalhost/cmd/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/physicalhost/cmd/flags.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/cmd/run.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration_test.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/service.go</code></li>\n<li><code>polaris/src/rubrik/sdk_internal/services/gps/datacenter/physicalhost_service.py</code></li>\n</ul>\n</details>\n\n\n------\n\nMake sure you check these lines.\n\n<details><summary>Click here to view the Inline Comments</summary><ul><li><a href=\"https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455666\">https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455666</a></li></ul></details>\n\n------\n\nChanges in RBA code require review from #rba_rba-reviews. For guidelines, please check [RBA Code Review Checklist](https://rubrik.atlassian.net/wiki/spaces/EN/pages/3835331585/RBA+Code+Review+Checklist).\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/common-go/audits/templates/cdm-host.yml</code></li>\n<li><code>polaris/src/rubrik/physicalhost/cmd/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/physicalhost/cmd/flags.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/cmd/run.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration_test.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/service.go</code></li>\n<li><code>polaris/src/rubrik/sdk_internal/services/gps/datacenter/physicalhost_service.py</code></li>\n</ul>\n</details>\n\n\n------\n\nMake sure you check these lines.\n\n<details><summary>Click here to view the Inline Comments</summary><ul><li><a href=\"https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455695\">https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455695</a></li>\n<li><a href=\"https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455718\">https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455718</a></li></ul></details>\n\n------\n\nMake sure you check these lines.\n\n<details><summary>Click here to view the Inline Comments</summary><ul><li><a href=\"https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455771\">https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455771</a></li></ul></details>\n\n------\n\nChanges to user facing polaris documentation require review from #rsc_documentation_rsc_doc_diff_reviews.\n\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/common-go/audits/templates/cdm-host.yml</code></li>\n</ul>\n</details>\n\n\n------\n\n<!--Footer_Start-->\n\n",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#issuecomment-3271866430"
          },
          {
            "type": "review_summary",
            "author": "sreshth-dev",
            "created_at": "2025-09-03T09:57:08Z",
            "body": "lgtm",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#pullrequestreview-3179889138"
          }
        ],
        "inline_comments": [
          {
            "author": "rubrik-alfred[bot]",
            "created_at": "2025-09-03T06:10:00Z",
            "body": "Please refer to  [wiki](https://rubrik.atlassian.net/wiki/spaces/EVENT/pages/4230217894/Events+Review+Guidelines+2x025#Should-I-Include-an-Email-Notification?) for guidance on if an event should be emailable or not.\n\n\n<details><summary>Associated Global Comment</summary>\n\n------\n\nMake sure you check these lines.</details>",
            "file_path": "polaris/src/rubrik/common-go/audits/templates/cdm-host.yml",
            "line_number": 122,
            "diff_hunk": "@@ -112,6 +112,21 @@\n     syslog_facility: RubrikEvent\n     syslog_severity: Info\n \n+- name: RegisterSecondaryHostFailure\n+  message:\n+    v1:\n+      audit_msg: >\n+        ${username} failed to register host '${hostName}' as secondary. Reason: ${reason}.\n+      email_subject: >\n+        ${username} failed to register host '${hostName}' as secondary\n+  status: Failure",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2317861137"
          },
          {
            "author": "rubrik-alfred[bot]",
            "created_at": "2025-09-03T06:10:03Z",
            "body": "Looks like you're adding or modifying an event message. Please follow the guildlines for writing message in  [wiki](https://rubrik.atlassian.net/wiki/spaces/EVENT/pages/4230217894/Events+Review+Guidelines+2x025#Writing-Event-Messages)\n\n\n<details><summary>Associated Global Comment</summary>\n\n------\n\nMake sure you check these lines.</details>",
            "file_path": "polaris/src/rubrik/common-go/audits/templates/cdm-host.yml",
            "line_number": 116,
            "diff_hunk": "@@ -112,6 +112,21 @@\n     syslog_facility: RubrikEvent\n     syslog_severity: Info\n \n+- name: RegisterSecondaryHostFailure\n+  message:",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2317861252"
          },
          {
            "author": "moht-agrawal-rubrik",
            "created_at": "2025-09-03T06:11:06Z",
            "body": "primary host registration audit is emailable, hence added the same for secondary host registrationl",
            "file_path": "polaris/src/rubrik/common-go/audits/templates/cdm-host.yml",
            "line_number": 122,
            "diff_hunk": "@@ -112,6 +112,21 @@\n     syslog_facility: RubrikEvent\n     syslog_severity: Info\n \n+- name: RegisterSecondaryHostFailure\n+  message:\n+    v1:\n+      audit_msg: >\n+        ${username} failed to register host '${hostName}' as secondary. Reason: ${reason}.\n+      email_subject: >\n+        ${username} failed to register host '${hostName}' as secondary\n+  status: Failure",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2317862844"
          },
          {
            "author": "moht-agrawal-rubrik",
            "created_at": "2025-09-03T06:12:03Z",
            "body": "creating a new audit, didn't modify any existing one.",
            "file_path": "polaris/src/rubrik/common-go/audits/templates/cdm-host.yml",
            "line_number": 116,
            "diff_hunk": "@@ -112,6 +112,21 @@\n     syslog_facility: RubrikEvent\n     syslog_severity: Info\n \n+- name: RegisterSecondaryHostFailure\n+  message:",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2317864442"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T07:15:13Z",
            "body": "<h2>GOLANG USE RUBRIK ERRORS PACKAGE</h2>\n\n**Refactor `newAuditSender` to use `rubrik/common-go/errors` for error construction, ensuring consistency and compliance with review guidelines.**\n\n```diff\n-\t\treturn auditslib.NewAuditSender(mqFactory)\n+\t\treturn errors.Wrap(auditslib.NewAuditSender(mqFactory), \"Failed to create AuditSender\")\n\n```\n<details ><summary>More details here</summary><br>The `newAuditSender` function constructs errors using a standard approach. However, as per the review guidelines, errors should be constructed using the `rubrik/common-go/errors` package. If `auditslib.NewAuditSender` internally raises errors using standard packages, consider refactoring to use the `rubrik/common-go/errors` package for consistency and compliance.  \n\n```diff\n-\t\treturn auditslib.NewAuditSender(mqFactory)\n+\t\treturn errors.Wrap(auditslib.NewAuditSender(mqFactory), \"Failed to create AuditSender\")\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 3 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go</code>\n<ul><li>126 to 128</li><li>698 to 720</li></ul>\n<code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration_test.go</code>\n<ul><li>1830 to 1831</li></ul></details>\n<h2></h2>\n<!-- rule:GOLANG_USE_RUBRIK_ERRORS_PACKAGE -->\n\n\n:page_facing_up: **Source Document**\n_Edith Review Rule: GOLANG_USE_RUBRIK_ERRORS_PACKAGE_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"GOLANG_USE_RUBRIK_ERRORS_PACKAGE\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go\": [[126, 128], [698, 719], [719, 720]], \"polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration_test.go\": [[1830, 1831]]}} -->\n",
            "file_path": "polaris/src/rubrik/physicalhost/cmd/run.go",
            "line_number": 123,
            "diff_hunk": "@@ -109,3 +111,13 @@ func newCDMRestServiceClient(\n \t}\n \treturn crs.NewCDMRestServiceClient(crsConn)\n }\n+\n+func newMQFactory(ctx context.Context, conf *config) *mq.MessageQueueFactory {\n+\tmqFactory := mq.CreateMessageQueueFactory(ctx, conf.messageQueueConfig)\n+\treturn mqFactory\n+}\n+\n+func newAuditSender(ctx context.Context, conf *config) auditslib.AuditSender {\n+\tmqFactory := newMQFactory(ctx, conf)\n+\treturn auditslib.NewAuditSender(mqFactory)\n+}",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2317996432"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T07:15:15Z",
            "body": "<h2>GOLANG PROPAGATE ERRORS TO CALLER</h2>\n\n**Wrap `mq.ParseMessageQueueConfig(ctx)` errors with context and ensure stack trace capture. Update error handling accordingly.**\n\n```diff\n-        conf.messageQueueConfig = mq.ParseMessageQueueConfig(ctx)\n+        mqConfig, err := mq.ParseMessageQueueConfig(ctx)\n+        if err != nil {\n+            return nil, errors.Wrap(err, \"Failed to parse message queue configuration\")\n+        }\n+        conf.messageQueueConfig = mqConfig\n\n```\n<details ><summary>More details here</summary><br>The function `mq.ParseMessageQueueConfig(ctx)` potentially calls a third-party library. If it returns an error, it should be wrapped to provide additional context and ensure the stack trace is captured. Update this line to handle errors correctly.  \n\n```diff\n-        conf.messageQueueConfig = mq.ParseMessageQueueConfig(ctx)\n+        mqConfig, err := mq.ParseMessageQueueConfig(ctx)\n+        if err != nil {\n+            return nil, errors.Wrap(err, \"Failed to parse message queue configuration\")\n+        }\n+        conf.messageQueueConfig = mqConfig\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 7 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/physicalhost/cmd/run.go</code>\n<ul><li>114 to 118</li><li>119 to 123</li></ul>\n<code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go</code>\n<ul><li>120 to 124</li><li>708 to 715</li></ul>\n<code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration_test.go</code>\n<ul><li>1702</li><li>1837 to 1843</li><li>2235 to 2236</li></ul></details>\n<h2></h2>\n<!-- rule:GOLANG_PROPAGATE_ERRORS_TO_CALLER -->\n\n\n:page_facing_up: **Source Document**\n_Edith Review Rule: GOLANG_PROPAGATE_ERRORS_TO_CALLER_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"GOLANG_PROPAGATE_ERRORS_TO_CALLER\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/physicalhost/cmd/run.go\": [[114, 118], [119, 123]], \"polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go\": [[120, 124], [708, 715]], \"polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration_test.go\": [[1702, 1702], [1837, 1843], [2235, 2236]]}} -->\n",
            "file_path": "polaris/src/rubrik/physicalhost/cmd/flags.go",
            "line_number": 44,
            "diff_hunk": "@@ -37,5 +41,7 @@ func parseArgs(\n \n \tflaggy.Parse()\n \n+\tconf.messageQueueConfig = mq.ParseMessageQueueConfig(ctx)",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2317996523"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T07:15:18Z",
            "body": "<h2>GOLANG SEQUENTIAL RPC CALLS</h2>\n\n**Implement a batched approach for `auditSender.Send(ctx, audit)` to avoid RPC calls inside the loop.**\n\n```diff\n-\t\tfor _, host := range req.Hosts {\n-\t\t\tif hostResults[host.HostFid] != nil {\n-\t\t\t\t...\n-\t\t\t\terr := auditSender.Send(ctx, audit)\n-\t\t\t\tif err != nil {\n-\t\t\t\t\t...\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n\n+\t\tbatchedAudits := make([]auditslib.Audit, 0)\n+\t\tfor _, host := range req.Hosts {\n+\t\t\tif hostResults[host.HostFid] != nil {\n+\t\t\t\t...\n+\t\t\t\taudit := auditslib.NewRegisterSecondaryHostFailureAudit(\n+\t\t\t\t\tcommonFields,\n+\t\t\t\t\tauditslib.RegisterSecondaryHostFailureMessageVars{\n+\t\t\t\t\t\tUsername: req.ReqCtx.GetUsername(),\n+\t\t\t\t\t\tHostName: hostName,\n+\t\t\t\t\t\tReason:   hostResults[host.HostFid].Error(),\n+\t\t\t\t\t},\n+\t\t\t\t)\n+\t\t\t\tbatchedAudits = append(batchedAudits, audit)\n+\t\t\t}\n+\t\t}\n+\t\terr := auditSender.SendBatch(ctx, batchedAudits)\n+\t\tif err != nil {\n+\t\t\tlog.Errorf(ctx, \"Failed to send batched audits: %v\", err)\n+\t\t\treturn err\n+\t\t}\n\n```\n<details ><summary>More details here</summary><br>This code sequentially calls `auditSender.Send(ctx, audit)` inside the loop for each host that failed registration. This violates the guideline to avoid calling RPCs inside a loop when a batched alternative is available. Consider implementing a batched approach to send audits for multiple hosts in a single call.\n\n```diff\n-\t\tfor _, host := range req.Hosts {\n-\t\t\tif hostResults[host.HostFid] != nil {\n-\t\t\t\t...\n-\t\t\t\terr := auditSender.Send(ctx, audit)\n-\t\t\t\tif err != nil {\n-\t\t\t\t\t...\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n\n+\t\tbatchedAudits := make([]auditslib.Audit, 0)\n+\t\tfor _, host := range req.Hosts {\n+\t\t\tif hostResults[host.HostFid] != nil {\n+\t\t\t\t...\n+\t\t\t\taudit := auditslib.NewRegisterSecondaryHostFailureAudit(\n+\t\t\t\t\tcommonFields,\n+\t\t\t\t\tauditslib.RegisterSecondaryHostFailureMessageVars{\n+\t\t\t\t\t\tUsername: req.ReqCtx.GetUsername(),\n+\t\t\t\t\t\tHostName: hostName,\n+\t\t\t\t\t\tReason:   hostResults[host.HostFid].Error(),\n+\t\t\t\t\t},\n+\t\t\t\t)\n+\t\t\t\tbatchedAudits = append(batchedAudits, audit)\n+\t\t\t}\n+\t\t}\n+\t\terr := auditSender.SendBatch(ctx, batchedAudits)\n+\t\tif err != nil {\n+\t\t\tlog.Errorf(ctx, \"Failed to send batched audits: %v\", err)\n+\t\t\treturn err\n+\t\t}\n```\n</details><h2></h2>\n<!-- rule:GOLANG_SEQUENTIAL_RPC_CALLS -->\n\n\n:page_facing_up: **Source Document**\n_Edith Review Rule: GOLANG_SEQUENTIAL_RPC_CALLS_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"GOLANG_SEQUENTIAL_RPC_CALLS\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"not_distilled\", \"other_locations\": {}} -->\n",
            "file_path": "polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go",
            "line_number": 718,
            "diff_hunk": "@@ -663,3 +672,49 @@ func runHostDiagnosis(\n \n \treturn diagnosisResults\n }\n+\n+func sendAuditsForFailedHosts(\n+\tctx context.Context,\n+\treq *proto.BulkRegisterSecondaryHostsReq,\n+\thostResults map[string]error,\n+\thostFidToCdmHost map[string]*aspb.CdmPhysicalHost,\n+\tauditSender auditslib.AuditSender,\n+) error {\n+\tauditErrors := make([]error, 0)\n+\tfor _, host := range req.Hosts {\n+\t\tif hostResults[host.HostFid] != nil {\n+\t\t\thostName := \"unknown\"\n+\t\t\tif cdmHost, exists := hostFidToCdmHost[host.HostFid]; exists {\n+\t\t\t\thostName = cdmHost.GetName()\n+\t\t\t}\n+\t\t\tcommonFields := auditslib.CommonAuditFields{\n+\t\t\t\tAccountName: req.ReqCtx.AuthzCtx.Account,\n+\t\t\t\tUserID:      req.ReqCtx.GetUserId(),\n+\t\t\t\tUserName:    req.ReqCtx.GetUsername(),\n+\t\t\t\tObjectID:    host.HostFid,\n+\t\t\t\tObjectName:  hostName,\n+\t\t\t\tObjectType:  adm.PolarisAuditObjectType_HOST,\n+\t\t\t}\n+\n+\t\t\taudit := auditslib.NewRegisterSecondaryHostFailureAudit(\n+\t\t\t\tcommonFields,\n+\t\t\t\tauditslib.RegisterSecondaryHostFailureMessageVars{\n+\t\t\t\t\tUsername: req.ReqCtx.GetUsername(),\n+\t\t\t\t\tHostName: hostName,\n+\t\t\t\t\tReason:   hostResults[host.HostFid].Error(),\n+\t\t\t\t},\n+\t\t\t)\n+\t\t\terr := auditSender.Send(ctx, audit)\n+\t\t\tif err != nil {\n+\t\t\t\tlog.Errorf(\n+\t\t\t\t\tctx,\n+\t\t\t\t\t\"Failed to send audit for host %s: %v\",\n+\t\t\t\t\thost.HostFid,\n+\t\t\t\t\terr,\n+\t\t\t\t)\n+\t\t\t\tauditErrors = append(auditErrors, err)\n+\t\t\t}\n+\t\t}\n+\t}",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2317996596"
          },
          {
            "author": "rubrik-stark-edith[bot]",
            "created_at": "2025-09-03T07:15:20Z",
            "body": "<h2>GOLANG DO NOT LOG ERRORS WHEN PROPAGATING</h2>\n\n**Remove `log.Errorf` to comply with `GOLANG_DO_NOT_LOG_ERRORS_WHEN_PROPAGATING_ACTION`; return the error without logging.**\n\n```diff\n-        log.Errorf(ctx, \"Certificate transfer failed to all the hosts: %v\", err)\n         return err\n\n```\n<details ><summary>More details here</summary><br>Logging the error with `log.Errorf` when the error is already propagated upward violates the guideline `GOLANG_DO_NOT_LOG_ERRORS_WHEN_PROPAGATING_ACTION`. This is redundant since errors should only be logged when the execution thread terminates. Remove the logging statement and ensure the error is only returned.\n\n```diff\n-        log.Errorf(ctx, \"Certificate transfer failed to all the hosts: %v\", err)\n         return err\n```\n</details><h2></h2><details ><summary><b>Similar comment also applies to the following 1 instance/s.</b></summary><br>\n<code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration_test.go</code>\n<ul><li>1837 to 1843</li></ul></details>\n<h2></h2>\n<!-- rule:GOLANG_DO_NOT_LOG_ERRORS_WHEN_PROPAGATING -->\n\n\n:page_facing_up: **Source Document**\n_Edith Review Rule: GOLANG_DO_NOT_LOG_ERRORS_WHEN_PROPAGATING_\n\n_Please share your feedback by reacting with a :+1: or :-1: and feel free to leave more detailed feedback in a reply to this comment_\n<!-- metadata:{\"rule\": \"GOLANG_DO_NOT_LOG_ERRORS_WHEN_PROPAGATING\", \"processable\": true, \"contextual_eligible\": false, \"distilled_type\": \"main_comment\", \"other_locations\": {\"polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration_test.go\": [[1837, 1843]]}} -->\n",
            "file_path": "polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go",
            "line_number": 128,
            "diff_hunk": "@@ -114,6 +116,13 @@ func processBulkRegistration(\n \t\t}\n \t}\n \n+\t// Send audits for hosts that failed before reaching the bulk registration API\n+\t// The V1BulkRegisterHostAsyncRPC API sends its own audits.\n+\t_ = sendAuditsForFailedHosts(\n+\t\tctx, req, hostResults, hostFidToCdmHost,\n+\t\tauditSender,\n+\t)\n+\n \tif len(hostRegisters) == 0 {\n \t\t// Certificate transfer failed to all the hosts\n \t\tlog.Errorf(",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2317996688"
          },
          {
            "author": "sreshth-dev",
            "created_at": "2025-09-03T08:09:47Z",
            "body": "Please add \r\n```\r\nenv_vars = super().env(realm, deployment, config)\r\n```\r\nAnd then append your envs",
            "file_path": "polaris/src/rubrik/sdk_internal/services/gps/datacenter/physicalhost_service.py",
            "line_number": 56,
            "diff_hunk": "@@ -45,3 +45,14 @@ def capabilities(self, dependencies: Capabilities) -> Sequence[Capability]:\n             dependencies.access('cdm-rest-service', Scope.rw),\n             dependencies.access('forever-uuid-service', Scope.rw),\n         ]\n+\n+    def env(\n+        self,\n+        realm: 'Realm',\n+        deployment: 'Deployment',\n+        config: 'ConfigSet',\n+    ) -> Mapping[str, str]:\n+        \"\"\"Environment variables for the service.\"\"\"\n+        return {",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2318144006"
          },
          {
            "author": "moht-agrawal-rubrik",
            "created_at": "2025-09-03T09:19:09Z",
            "body": "Thanks, made the changes.",
            "file_path": "polaris/src/rubrik/sdk_internal/services/gps/datacenter/physicalhost_service.py",
            "line_number": 56,
            "diff_hunk": "@@ -45,3 +45,14 @@ def capabilities(self, dependencies: Capabilities) -> Sequence[Capability]:\n             dependencies.access('cdm-rest-service', Scope.rw),\n             dependencies.access('forever-uuid-service', Scope.rw),\n         ]\n+\n+    def env(\n+        self,\n+        realm: 'Realm',\n+        deployment: 'Deployment',\n+        config: 'ConfigSet',\n+    ) -> Mapping[str, str]:\n+        \"\"\"Environment variables for the service.\"\"\"\n+        return {",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2318346326"
          },
          {
            "author": "Arqum212",
            "created_at": "2025-09-04T08:59:24Z",
            "body": "@moht-agrawal-rubrik Do we send a mail and audit for per host failure in primary registration?",
            "file_path": "polaris/src/rubrik/common-go/audits/templates/cdm-host.yml",
            "line_number": 122,
            "diff_hunk": "@@ -112,6 +112,21 @@\n     syslog_facility: RubrikEvent\n     syslog_severity: Info\n \n+- name: RegisterSecondaryHostFailure\n+  message:\n+    v1:\n+      audit_msg: >\n+        ${username} failed to register host '${hostName}' as secondary. Reason: ${reason}.\n+      email_subject: >\n+        ${username} failed to register host '${hostName}' as secondary\n+  status: Failure",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2321342488"
          },
          {
            "author": "moht-agrawal-rubrik",
            "created_at": "2025-09-04T09:06:34Z",
            "body": "@Arqum212 From the code it looks like that (not able to test it if it works or not).\r\n\r\n```\r\n- name: RegisterHostFailure\r\n  message:\r\n    v1: >\r\n      ${username} failed to register host '${hostName}'. Reason: ${reason}.\r\n    v2:\r\n      audit_msg: >\r\n        ${username} failed to register host '${hostName}'. Reason: ${reason}.\r\n      email_subject: >\r\n        DONT SEND\r\n    v3:\r\n      audit_msg: >\r\n        ${username} failed to register host '${hostName}'. Reason: ${reason}.\r\n      email_subject: >\r\n        ${username} failed to register host '${hostName}'\r\n  status: Failure\r\n  severity: Info\r\n  type: Configuration\r\n  emailable: true\r\n  syslog:\r\n    syslog_facility: RubrikEvent\r\n    syslog_severity: Info\r\n```\r\nVersion v3 will be used for sending audits.",
            "file_path": "polaris/src/rubrik/common-go/audits/templates/cdm-host.yml",
            "line_number": 122,
            "diff_hunk": "@@ -112,6 +112,21 @@\n     syslog_facility: RubrikEvent\n     syslog_severity: Info\n \n+- name: RegisterSecondaryHostFailure\n+  message:\n+    v1:\n+      audit_msg: >\n+        ${username} failed to register host '${hostName}' as secondary. Reason: ${reason}.\n+      email_subject: >\n+        ${username} failed to register host '${hostName}' as secondary\n+  status: Failure",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2321360380"
          },
          {
            "author": "rubrik-alfred[bot]",
            "created_at": "2025-09-09T18:40:00Z",
            "body": "ObjectID and ObjectType control RBAC for events. Please ensure these fields are set as described in in  [wiki](https://rubrik.atlassian.net/wiki/spaces/EVENT/pages/4230217894/Events+Review+Guidelines+2x025#Object-ID%2C-ObjectType%2C-and-RBAC)\n\n\n<details><summary>Associated Global Comment</summary>\n\n------\n\nMake sure you check these lines.</details>",
            "file_path": "polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go",
            "line_number": 690,
            "diff_hunk": "@@ -663,3 +672,49 @@ func runHostDiagnosis(\n \n \treturn diagnosisResults\n }\n+\n+func sendAuditsForFailedHosts(\n+\tctx context.Context,\n+\treq *proto.BulkRegisterSecondaryHostsReq,\n+\thostResults map[string]error,\n+\thostFidToCdmHost map[string]*aspb.CdmPhysicalHost,\n+\tauditSender auditslib.AuditSender,\n+) error {\n+\tauditErrors := make([]error, 0)\n+\tfor _, host := range req.Hosts {\n+\t\tif hostResults[host.HostFid] != nil {\n+\t\t\thostName := \"unknown\"\n+\t\t\tif cdmHost, exists := hostFidToCdmHost[host.HostFid]; exists {\n+\t\t\t\thostName = cdmHost.GetName()\n+\t\t\t}\n+\t\t\tcommonFields := auditslib.CommonAuditFields{",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455666"
          },
          {
            "author": "rubrik-alfred[bot]",
            "created_at": "2025-09-09T18:40:01Z",
            "body": "Please refer to  [wiki](https://rubrik.atlassian.net/wiki/spaces/EVENT/pages/4230217894/Events+Review+Guidelines+2x025#Should-I-Include-an-Email-Notification?) for guidance on if an event should be emailable or not.\n\n\n<details><summary>Associated Global Comment</summary>\n\n------\n\nMake sure you check these lines.</details>",
            "file_path": "polaris/src/rubrik/common-go/audits/templates/cdm-host.yml",
            "line_number": 122,
            "diff_hunk": "@@ -112,6 +112,21 @@\n     syslog_facility: RubrikEvent\n     syslog_severity: Info\n \n+- name: RegisterSecondaryHostFailure\n+  message:\n+    v1:\n+      audit_msg: >\n+        ${username} failed to register host '${hostName}' as secondary. Reason: ${reason}.\n+      email_subject: >\n+        ${username} failed to register host '${hostName}' as secondary\n+  status: Failure",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455695"
          },
          {
            "author": "rubrik-alfred[bot]",
            "created_at": "2025-09-09T18:40:02Z",
            "body": "Please refer to  [wiki](https://rubrik.atlassian.net/wiki/spaces/EVENT/pages/4230217894/Events+Review+Guidelines+2x025#Should-I-Include-an-Email-Notification?) for guidance on if an event should be emailable or not.\n\n\n<details><summary>Associated Global Comment</summary>\n\n------\n\nMake sure you check these lines.</details>",
            "file_path": "polaris/src/rubrik/common-go/audits/templates/cdm-host.yml",
            "line_number": 125,
            "diff_hunk": "@@ -112,6 +112,21 @@\n     syslog_facility: RubrikEvent\n     syslog_severity: Info\n \n+- name: RegisterSecondaryHostFailure\n+  message:\n+    v1:\n+      audit_msg: >\n+        ${username} failed to register host '${hostName}' as secondary. Reason: ${reason}.\n+      email_subject: >\n+        ${username} failed to register host '${hostName}' as secondary\n+  status: Failure\n+  severity: Info\n+  type: Configuration\n+  emailable: true",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455718"
          },
          {
            "author": "rubrik-alfred[bot]",
            "created_at": "2025-09-09T18:40:03Z",
            "body": "Sending events/audits requires review from #polaris_events_watchers-events-reviews. There is a hard limit of 500 events per event series. Please check that you are not potentially sending more than this. For example, be sure you are not sending running events continuously in a loop while waiting certain tasks to complete. Another example, if your job operates over a large number of objects at once which all share a single event series, be sure to take steps to limit the number of events sent to the series.\n\n\n<details><summary>Associated Global Comment</summary>\n\n------\n\nMake sure you check these lines.</details>",
            "file_path": "polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go",
            "line_number": 707,
            "diff_hunk": "@@ -663,3 +672,49 @@ func runHostDiagnosis(\n \n \treturn diagnosisResults\n }\n+\n+func sendAuditsForFailedHosts(\n+\tctx context.Context,\n+\treq *proto.BulkRegisterSecondaryHostsReq,\n+\thostResults map[string]error,\n+\thostFidToCdmHost map[string]*aspb.CdmPhysicalHost,\n+\tauditSender auditslib.AuditSender,\n+) error {\n+\tauditErrors := make([]error, 0)\n+\tfor _, host := range req.Hosts {\n+\t\tif hostResults[host.HostFid] != nil {\n+\t\t\thostName := \"unknown\"\n+\t\t\tif cdmHost, exists := hostFidToCdmHost[host.HostFid]; exists {\n+\t\t\t\thostName = cdmHost.GetName()\n+\t\t\t}\n+\t\t\tcommonFields := auditslib.CommonAuditFields{\n+\t\t\t\tAccountName: req.ReqCtx.AuthzCtx.Account,\n+\t\t\t\tUserID:      req.ReqCtx.GetUserId(),\n+\t\t\t\tUserName:    req.ReqCtx.GetUsername(),\n+\t\t\t\tObjectID:    host.HostFid,\n+\t\t\t\tObjectName:  hostName,\n+\t\t\t\tObjectType:  adm.PolarisAuditObjectType_HOST,\n+\t\t\t}\n+\n+\t\t\taudit := auditslib.NewRegisterSecondaryHostFailureAudit(\n+\t\t\t\tcommonFields,\n+\t\t\t\tauditslib.RegisterSecondaryHostFailureMessageVars{\n+\t\t\t\t\tUsername: req.ReqCtx.GetUsername(),\n+\t\t\t\t\tHostName: hostName,\n+\t\t\t\t\tReason:   hostResults[host.HostFid].Error(),\n+\t\t\t\t},\n+\t\t\t)\n+\t\t\terr := auditSender.Send(ctx, audit)",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455741"
          },
          {
            "author": "rubrik-alfred[bot]",
            "created_at": "2025-09-09T18:40:04Z",
            "body": "Looks like you're adding or modifying an event message. Please follow the guildlines for writing message in  [wiki](https://rubrik.atlassian.net/wiki/spaces/EVENT/pages/4230217894/Events+Review+Guidelines+2x025#Writing-Event-Messages)\n\n\n<details><summary>Associated Global Comment</summary>\n\n------\n\nMake sure you check these lines.</details>",
            "file_path": "polaris/src/rubrik/common-go/audits/templates/cdm-host.yml",
            "line_number": 116,
            "diff_hunk": "@@ -112,6 +112,21 @@\n     syslog_facility: RubrikEvent\n     syslog_severity: Info\n \n+- name: RegisterSecondaryHostFailure\n+  message:",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97821#discussion_r2334455771"
          }
        ]
      },
      "files_changed": [
        {
          "filename": "polaris/src/rubrik/common-go/audits/templates/cdm-host.yml",
          "status": "modified",
          "additions": 15,
          "deletions": 0,
          "patch": "@@ -112,6 +112,21 @@\n     syslog_facility: RubrikEvent\n     syslog_severity: Info\n \n+- name: RegisterSecondaryHostFailure\n+  message:\n+    v1:\n+      audit_msg: >\n+        ${username} failed to register host '${hostName}' as secondary. Reason: ${reason}.\n+      email_subject: >\n+        ${username} failed to register host '${hostName}' as secondary\n+  status: Failure\n+  severity: Info\n+  type: Configuration\n+  emailable: true\n+  syslog:\n+    syslog_facility: RubrikEvent\n+    syslog_severity: Info\n+\n - name: DeleteHostStarted\n   message:\n     v1: >"
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/cmd/BUILD.bazel",
          "status": "modified",
          "additions": 2,
          "deletions": 0,
          "patch": "@@ -10,9 +10,11 @@ go_library(\n     deps = [\n         \"//rubrik/authz-service/proto:go_default_library\",\n         \"//rubrik/cdm-rest-service/proto:go_default_library\",\n+        \"//rubrik/common-go/audits:go_default_library\",\n         \"//rubrik/common-go/dual:go_default_library\",\n         \"//rubrik/common-go/flaggy:go_default_library\",\n         \"//rubrik/common-go/log:go_default_library\",\n+        \"//rubrik/common-go/message-queue:go_default_library\",\n         \"//rubrik/common-go/service:go_default_library\",\n         \"//rubrik/physicalhost/proto:go_default_library\",\n         \"//rubrik/physicalhost/svc:go_default_library\","
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/cmd/flags.go",
          "status": "modified",
          "additions": 6,
          "deletions": 0,
          "patch": "@@ -5,6 +5,7 @@ import (\n \n \t\"rubrik/common-go/dual\"\n \t\"rubrik/common-go/flaggy\"\n+\tmq \"rubrik/common-go/message-queue\"\n )\n \n // config stores the configuration loaded from flags and the environment.\n@@ -20,6 +21,9 @@ type config struct {\n \n \t// our settings\n \tgrpcPort dual.ServerPort\n+\n+\t// message queue configuration\n+\tmessageQueueConfig mq.MessageQueueConfig\n }\n \n // parseArgs loads configuration values from flags and the environment.\n@@ -37,5 +41,7 @@ func parseArgs(\n \n \tflaggy.Parse()\n \n+\tconf.messageQueueConfig = mq.ParseMessageQueueConfig(ctx)\n+\n \treturn &conf\n }"
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/cmd/run.go",
          "status": "modified",
          "additions": 15,
          "deletions": 3,
          "patch": "@@ -10,11 +10,12 @@ import (\n \n \tauthz \"rubrik/authz-service/proto\"\n \tcrs \"rubrik/cdm-rest-service/proto\"\n-\t\"rubrik/physicalhost/proto\"\n-\t\"rubrik/physicalhost/svc\"\n-\n+\tauditslib \"rubrik/common-go/audits\"\n \t\"rubrik/common-go/log\"\n+\tmq \"rubrik/common-go/message-queue\"\n \t\"rubrik/common-go/service\"\n+\t\"rubrik/physicalhost/proto\"\n+\t\"rubrik/physicalhost/svc\"\n )\n \n // Main is the beginning and end of life for PhysicalHostService.\n@@ -64,6 +65,7 @@ func buildService(\n \treturn svc.NewPhysicalHostService(\n \t\tnewCDMRestServiceClient(ctx, conf),\n \t\tnewAuthzClient(ctx, conf),\n+\t\tnewAuditSender(ctx, conf),\n \t)\n }\n \n@@ -109,3 +111,13 @@ func newCDMRestServiceClient(\n \t}\n \treturn crs.NewCDMRestServiceClient(crsConn)\n }\n+\n+func newMQFactory(ctx context.Context, conf *config) *mq.MessageQueueFactory {\n+\tmqFactory := mq.CreateMessageQueueFactory(ctx, conf.messageQueueConfig)\n+\treturn mqFactory\n+}\n+\n+func newAuditSender(ctx context.Context, conf *config) auditslib.AuditSender {\n+\tmqFactory := newMQFactory(ctx, conf)\n+\treturn auditslib.NewAuditSender(mqFactory)\n+}"
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/svc/BUILD.bazel",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -11,8 +11,10 @@ go_library(\n         \"//rubrik/authz-service/proto:go_default_library\",\n         \"//rubrik/cdm-rest-service/proto:go_default_library\",\n         \"//rubrik/cdm-rest-service/proto/types:go_default_library\",\n+        \"//rubrik/common-go/audits:go_default_library\",\n         \"//rubrik/common-go/authz/proto:go_default_library\",\n         \"//rubrik/common-go/log:go_default_library\",\n+        \"//rubrik/common-go/message-queue/audits/proto:go_default_library\",\n         \"//rubrik/physicalhost/errors:go_default_library\",\n         \"//rubrik/physicalhost/proto:go_default_library\",\n         \"//rubrik/vendor/github.com/golang/protobuf/ptypes/wrappers:go_default_library\",\n@@ -33,7 +35,6 @@ go_test(\n         \"//rubrik/common-go/api/context/proto:go_default_library\",\n         \"//rubrik/common-go/authz/proto:go_default_library\",\n         \"//rubrik/physicalhost/proto:go_default_library\",\n-        \"//rubrik/vendor/github.com/golang/protobuf/ptypes/wrappers:go_default_library\",\n         \"//rubrik/vendor/github.com/stretchr/testify/assert:go_default_library\",\n         \"//rubrik/vendor/github.com/stretchr/testify/mock:go_default_library\",\n         \"//rubrik/vendor/github.com/stretchr/testify/require:go_default_library\","
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go",
          "status": "modified",
          "additions": 57,
          "deletions": 2,
          "patch": "@@ -16,8 +16,10 @@ import (\n \tauthzclient \"rubrik/authz-service/proto\"\n \tcrs \"rubrik/cdm-rest-service/proto\"\n \tcrstypes \"rubrik/cdm-rest-service/proto/types\"\n+\tauditslib \"rubrik/common-go/audits\"\n \tacpb \"rubrik/common-go/authz/proto\"\n \t\"rubrik/common-go/log\"\n+\tadm \"rubrik/common-go/message-queue/audits/proto\"\n \t\"rubrik/physicalhost/proto\"\n )\n \n@@ -62,7 +64,7 @@ func (service *PhysicalHostService) BulkRegisterSecondaryHosts(\n \t\treq,\n \t\thostFidToCdmPhysicalHost,\n \t\tservice.crsClient,\n-\t\tservice.authzClient,\n+\t\tservice.auditSender,\n \t)\n }\n \n@@ -72,7 +74,7 @@ func processBulkRegistration(\n \treq *proto.BulkRegisterSecondaryHostsReq,\n \thostFidToCdmHost map[string]*aspb.CdmPhysicalHost,\n \tcrsClient crs.CDMRestServiceClient,\n-\tauthzClient authzclient.AuthzClient,\n+\tauditSender auditslib.AuditSender,\n ) (*proto.BulkRegisterSecondaryHostsReply, error) {\n \tlog.Infof(\n \t\tctx, \"Starting bulk secondary host registration for %d hosts on cluster %s\",\n@@ -114,6 +116,13 @@ func processBulkRegistration(\n \t\t}\n \t}\n \n+\t// Send audits for hosts that failed before reaching the bulk registration API\n+\t// The V1BulkRegisterHostAsyncRPC API sends its own audits.\n+\t_ = sendAuditsForFailedHosts(\n+\t\tctx, req, hostResults, hostFidToCdmHost,\n+\t\tauditSender,\n+\t)\n+\n \tif len(hostRegisters) == 0 {\n \t\t// Certificate transfer failed to all the hosts\n \t\tlog.Errorf(\n@@ -663,3 +672,49 @@ func runHostDiagnosis(\n \n \treturn diagnosisResults\n }\n+\n+func sendAuditsForFailedHosts(\n+\tctx context.Context,\n+\treq *proto.BulkRegisterSecondaryHostsReq,\n+\thostResults map[string]error,\n+\thostFidToCdmHost map[string]*aspb.CdmPhysicalHost,\n+\tauditSender auditslib.AuditSender,\n+) error {\n+\tauditErrors := make([]error, 0)\n+\tfor _, host := range req.Hosts {\n+\t\tif hostResults[host.HostFid] != nil {\n+\t\t\thostName := \"unknown\"\n+\t\t\tif cdmHost, exists := hostFidToCdmHost[host.HostFid]; exists {\n+\t\t\t\thostName = cdmHost.GetName()\n+\t\t\t}\n+\t\t\tcommonFields := auditslib.CommonAuditFields{\n+\t\t\t\tAccountName: req.ReqCtx.AuthzCtx.Account,\n+\t\t\t\tUserID:      req.ReqCtx.GetUserId(),\n+\t\t\t\tUserName:    req.ReqCtx.GetUsername(),\n+\t\t\t\tObjectID:    host.HostFid,\n+\t\t\t\tObjectName:  hostName,\n+\t\t\t\tObjectType:  adm.PolarisAuditObjectType_HOST,\n+\t\t\t}\n+\n+\t\t\taudit := auditslib.NewRegisterSecondaryHostFailureAudit(\n+\t\t\t\tcommonFields,\n+\t\t\t\tauditslib.RegisterSecondaryHostFailureMessageVars{\n+\t\t\t\t\tUsername: req.ReqCtx.GetUsername(),\n+\t\t\t\t\tHostName: hostName,\n+\t\t\t\t\tReason:   hostResults[host.HostFid].Error(),\n+\t\t\t\t},\n+\t\t\t)\n+\t\t\terr := auditSender.Send(ctx, audit)\n+\t\t\tif err != nil {\n+\t\t\t\tlog.Errorf(\n+\t\t\t\t\tctx,\n+\t\t\t\t\t\"Failed to send audit for host %s: %v\",\n+\t\t\t\t\thost.HostFid,\n+\t\t\t\t\terr,\n+\t\t\t\t)\n+\t\t\t\tauditErrors = append(auditErrors, err)\n+\t\t\t}\n+\t\t}\n+\t}\n+\treturn errors.Join(auditErrors...)\n+}"
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration_test.go",
          "status": "modified",
          "additions": 16,
          "deletions": 2,
          "patch": "@@ -16,6 +16,7 @@ import (\n \tcrs \"rubrik/cdm-rest-service/proto\"\n \tcrstypes \"rubrik/cdm-rest-service/proto/types\"\n \tcontextproto \"rubrik/common-go/api/context/proto\"\n+\tauditslib \"rubrik/common-go/audits\"\n \tacpb \"rubrik/common-go/authz/proto\"\n \tauthzcommon \"rubrik/common-go/authz/proto\"\n \t\"rubrik/physicalhost/proto\"\n@@ -1693,14 +1694,18 @@ func TestProcessBulkRegistration(t *testing.T) {\n \t\tt.Run(tt.name, func(t *testing.T) {\n \t\t\tmockCRS := &crs.MockCDMRestServiceClient{}\n \t\t\tmockAuthz := &authz.MockAuthzClient{}\n+\t\t\tmockAuditSender := &auditslib.MockAuditSender{}\n \t\t\ttt.setupMocks(mockCRS, mockAuthz)\n \n+\t\t\t// Mock audit sender to accept any audit calls\n+\t\t\tmockAuditSender.On(\"Send\", mock.Anything, mock.Anything).Return(nil)\n+\n \t\t\tresult, err := processBulkRegistration(\n \t\t\t\tctx,\n \t\t\t\ttt.request,\n \t\t\t\ttt.hostFidToCdmHost,\n \t\t\t\tmockCRS,\n-\t\t\t\tmockAuthz,\n+\t\t\t\tmockAuditSender,\n \t\t\t)\n \n \t\t\tif tt.expectError {\n@@ -1825,12 +1830,16 @@ func TestProcessBulkRegistrationBulkAPIFailure(t *testing.T) {\n \t\terrors.New(\"bulk registration service unavailable\"),\n \t)\n \n+\t// Mock audit sender\n+\tmockAuditSender := &auditslib.MockAuditSender{}\n+\tmockAuditSender.On(\"Send\", mock.Anything, mock.Anything).Return(nil)\n+\n \tresult, err := processBulkRegistration(\n \t\tctx,\n \t\trequest,\n \t\thostFidToCdmHost,\n \t\tmockCRS,\n-\t\tmockAuthz,\n+\t\tmockAuditSender,\n \t)\n \n \t// Function should return error\n@@ -2213,10 +2222,15 @@ func TestBulkRegisterSecondaryHostsPartialSuccess(t *testing.T) {\n \t\tItems: []*crstypes.HostDetail{},\n \t}, nil)\n \n+\t// Create mock audit sender\n+\tmockAuditSender := &auditslib.MockAuditSender{}\n+\tmockAuditSender.On(\"Send\", mock.Anything, mock.Anything).Return(nil)\n+\n \t// Create service instance\n \tservice := &PhysicalHostService{\n \t\tcrsClient:   mockCRS,\n \t\tauthzClient: mockAuthz,\n+\t\tauditSender: mockAuditSender,\n \t}\n \n \tresult, err := service.BulkRegisterSecondaryHosts(ctx, request)"
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/svc/service.go",
          "status": "modified",
          "additions": 4,
          "deletions": 0,
          "patch": "@@ -9,6 +9,7 @@ import (\n \n \tauthzclient \"rubrik/authz-service/proto\"\n \tcrs \"rubrik/cdm-rest-service/proto\"\n+\tauditslib \"rubrik/common-go/audits\"\n \tphysicalhosterrors \"rubrik/physicalhost/errors\"\n \t\"rubrik/physicalhost/proto\"\n )\n@@ -17,16 +18,19 @@ import (\n type PhysicalHostService struct {\n \tcrsClient   crs.CDMRestServiceClient\n \tauthzClient authzclient.AuthzClient\n+\tauditSender auditslib.AuditSender\n }\n \n // NewPhysicalHostService constructs a new PhysicalHostService.\n func NewPhysicalHostService(\n \tcrsClient crs.CDMRestServiceClient,\n \tauthzClient authzclient.AuthzClient,\n+\tauditSender auditslib.AuditSender,\n ) (*PhysicalHostService, error) {\n \tservice := &PhysicalHostService{\n \t\tcrsClient:   crsClient,\n \t\tauthzClient: authzClient,\n+\t\tauditSender: auditSender,\n \t}\n \n \treturn service, nil"
        },
        {
          "filename": "polaris/src/rubrik/sdk_internal/services/gps/datacenter/physicalhost_service.py",
          "status": "modified",
          "additions": 16,
          "deletions": 1,
          "patch": "@@ -1,6 +1,6 @@\n \"\"\"Physical Host Service\"\"\"\n \n-from typing import Sequence, Set\n+from typing import Mapping, Sequence, Set\n \n from rubrik.sdk_internal.security.capabilities import Capabilities, Capability\n from rubrik.sdk_internal.security.scopes import Scope\n@@ -45,3 +45,18 @@ def capabilities(self, dependencies: Capabilities) -> Sequence[Capability]:\n             dependencies.access('cdm-rest-service', Scope.rw),\n             dependencies.access('forever-uuid-service', Scope.rw),\n         ]\n+\n+    def env(\n+        self,\n+        realm: 'Realm',\n+        deployment: 'Deployment',\n+        config: 'ConfigSet',\n+    ) -> Mapping[str, str]:\n+        \"\"\"Environment variables for the service.\"\"\"\n+        env_vars = super().env(realm, deployment, config)\n+        env_vars.update(\n+            {\n+                'MESSAGE_QUEUE_PREFIX': deployment.name,\n+            }\n+        )\n+        return env_vars"
        }
      ],
      "statistics": {
        "commits": 7,
        "files_changed": 9,
        "additions": 133,
        "deletions": 9,
        "total_comments": 21
      }
    },
    "processed_data": {
      "title": "PR Review: Send audits for failed secondary host registration",
      "summary": "## Summary:\n- Added new audit for failed secondary host registration.\r\n- Added an audit sender to the physicalhost service.\r\n- Sending audits for failed secondary host registration.\r\n\r\nRef: https://ru...",
      "action_items": [
        {
          "item": "Review PR: Send audits for failed secondary host registration",
          "priority": "medium",
          "next_steps": [
            "Read description",
            "Review code changes",
            "Test locally"
          ]
        },
        {
          "item": "Address code review comments",
          "priority": "high",
          "next_steps": [
            "Review inline comments",
            "Make necessary changes",
            "Respond to reviewers"
          ]
        }
      ],
      "urgency_score": 1.0,
      "context": "GitHub PR in gh/moht-agrawal-rubrik/17/head branch"
    }
  },
  {
    "source": "github",
    "candidate_id": "github_pr_97450",
    "raw_data": {
      "pr_title": "Implement bulk register secondary host rpc",
      "pr_summary": "## Summary:\nImplemented the bulk secondary registration api.\n\n## Test Plan:\nManual testing\r\n\r\n<img width=\"1574\" height=\"1036\" alt=\"image\" src=\"https://github.com/user-attachments/assets/5760fe70-a9d6-42f1-af8c-a0fc9b94eba5\" />\n\n## JIRA Issues:\nSPARK-572184\n\n## Revert Plan:\n## PR Stack:\nStack from arc wrapper with help from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):\n* #97821\n* #97551\n* __->__ #97450\n* #97449\n",
      "pr_url": "https://github.com/scaledata/sdmain/pull/97450",
      "metadata": {
        "number": 97450,
        "state": "open",
        "author": "moht-agrawal-rubrik",
        "created_at": "2025-09-02T06:41:23Z",
        "updated_at": "2025-09-09T18:39:25Z",
        "merged_at": null,
        "base_branch": "gh/moht-agrawal-rubrik/15/head",
        "head_branch": "gh/moht-agrawal-rubrik/16/head",
        "labels": [],
        "assignees": [],
        "reviewers": []
      },
      "comments": {
        "global_comments": [
          {
            "type": "discussion",
            "author": "rogers-sail-information[bot]",
            "created_at": "2025-09-02T06:41:53Z",
            "body": "<!-- rogers sail info comment -->\n## Sail Request\n\n> Rogers will automatically update this comment to reflect the current sail status of your PR when you begin a sail request.",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97450#issuecomment-3243993939"
          },
          {
            "type": "discussion",
            "author": "rubrik-alfred[bot]",
            "created_at": "2025-09-09T18:39:25Z",
            "body": "## :man_in_tuxedo: Alfred Comments\n<input type='hidden' commit='7b02789a315d78d15cc64bf14a306a4ddf041931' global='true'/>\n<!--Header_Done-->\n\nChanges in RBA code require review from #rba_rba-reviews. For guidelines, please check [RBA Code Review Checklist](https://rubrik.atlassian.net/wiki/spaces/EN/pages/3835331585/RBA+Code+Review+Checklist).\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/physicalhost/cmd/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/physicalhost/cmd/flags.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/cmd/run.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/errors/errors.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/service.go</code></li>\n</ul>\n</details>\n\n\n------\n\nTriggering the detect-changed-services pipeline. If your PR is raised against a Polaris release branch, this pipeline will leave a comment with a list of the services that will be affected by the changes in your PR.\n\n\nThe following jobs are triggered:\n\n\n- [detect-changed-services](https://polaris-builds.stark.rubrik.com/job/detect-changed-services)\n\n\n<details>\n<summary>Click here to view the file paths triggering these jobs</summary>\n<ul>\n<li><code>polaris/src/rubrik/physicalhost/cmd/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/physicalhost/cmd/flags.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/cmd/run.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/errors/errors.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/service.go</code></li>\n</ul>\n</details>\n\n\n------\n\n<!--Footer_Start-->\n\n",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97450#issuecomment-3271864564"
          }
        ],
        "inline_comments": []
      },
      "files_changed": [
        {
          "filename": "polaris/src/rubrik/physicalhost/cmd/BUILD.bazel",
          "status": "modified",
          "additions": 2,
          "deletions": 0,
          "patch": "@@ -8,6 +8,8 @@ go_library(\n     importpath = \"rubrik/physicalhost/cmd\",\n     visibility = [\"//visibility:public\"],\n     deps = [\n+        \"//rubrik/authz-service/proto:go_default_library\",\n+        \"//rubrik/cdm-rest-service/proto:go_default_library\",\n         \"//rubrik/common-go/dual:go_default_library\",\n         \"//rubrik/common-go/flaggy:go_default_library\",\n         \"//rubrik/common-go/log:go_default_library\","
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/cmd/flags.go",
          "status": "modified",
          "additions": 6,
          "deletions": 0,
          "patch": "@@ -9,6 +9,10 @@ import (\n \n // config stores the configuration loaded from flags and the environment.\n type config struct {\n+\t// other services\n+\tauthzServiceAddr dual.ClientAddr\n+\tcdmRestSvcAddr   dual.ClientAddr\n+\n \t// security configuration\n \tflaggy.TLSConfig\n \tjwtSecretFile string\n@@ -28,6 +32,8 @@ func parseArgs(\n \tflaggy.LoadCapabilitiesServerFlags(&conf.jwtSecretFile)\n \tflaggy.LoadCapabilitiesClientFlags(&conf.jwtTokenFile)\n \tflaggy.LoadGRPCPort(&conf.grpcPort)\n+\tflaggy.LoadCdmRestServiceAddr(&conf.cdmRestSvcAddr)\n+\tflaggy.LoadAuthzServiceAddr(&conf.authzServiceAddr)\n \n \tflaggy.Parse()\n "
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/cmd/run.go",
          "status": "modified",
          "additions": 49,
          "deletions": 1,
          "patch": "@@ -8,6 +8,8 @@ import (\n \topentracing \"github.com/opentracing/opentracing-go\"\n \t\"google.golang.org/grpc\"\n \n+\tauthz \"rubrik/authz-service/proto\"\n+\tcrs \"rubrik/cdm-rest-service/proto\"\n \t\"rubrik/physicalhost/proto\"\n \t\"rubrik/physicalhost/svc\"\n \n@@ -59,5 +61,51 @@ func buildService(\n \tctx context.Context,\n \tconf *config,\n ) (*svc.PhysicalHostService, error) {\n-\treturn svc.NewPhysicalHostService(ctx)\n+\treturn svc.NewPhysicalHostService(\n+\t\tnewCDMRestServiceClient(ctx, conf),\n+\t\tnewAuthzClient(ctx, conf),\n+\t)\n+}\n+\n+func newAuthzClient(ctx context.Context, conf *config) authz.AuthzClient {\n+\tauthzConn, err := service.NewGRPCClient(\n+\t\tctx,\n+\t\t\"authz-service\",\n+\t\tconf.authzServiceAddr,\n+\t\tconf.CARootFile,\n+\t\tconf.TLSCertFile,\n+\t\tconf.TLSKeyFile,\n+\t\tconf.jwtTokenFile,\n+\t)\n+\tif err != nil {\n+\t\tlog.Panicf(\n+\t\t\tctx,\n+\t\t\t\"Couldn't create connection to authz-service: %v\",\n+\t\t\terr,\n+\t\t)\n+\t}\n+\treturn authz.NewAuthzClient(authzConn)\n+}\n+\n+func newCDMRestServiceClient(\n+\tctx context.Context,\n+\tconf *config,\n+) crs.CDMRestServiceClient {\n+\tcrsConn, err := service.NewGRPCClient(\n+\t\tctx,\n+\t\t\"cdm-rest-service\",\n+\t\tconf.cdmRestSvcAddr,\n+\t\tconf.CARootFile,\n+\t\tconf.TLSCertFile,\n+\t\tconf.TLSKeyFile,\n+\t\tconf.jwtTokenFile,\n+\t)\n+\tif err != nil {\n+\t\tlog.Panicf(\n+\t\t\tctx,\n+\t\t\t\"Couldn't create connection to cdm-rest-service: %v\",\n+\t\t\terr,\n+\t\t)\n+\t}\n+\treturn crs.NewCDMRestServiceClient(crsConn)\n }"
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/errors/errors.go",
          "status": "modified",
          "additions": 0,
          "deletions": 2,
          "patch": "@@ -24,12 +24,10 @@ func ToProtobufError(err error) error {\n \tif err == nil {\n \t\treturn nil\n \t}\n-\n \t_, ok := status.FromError(err)\n \tif ok {\n \t\treturn err\n \t}\n-\n \tswitch err {\n \tcase ErrNetwork:\n \t\treturn status.Error(codes.Unavailable, err.Error())"
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/svc/BUILD.bazel",
          "status": "modified",
          "additions": 14,
          "deletions": 1,
          "patch": "@@ -1,11 +1,24 @@\n \n go_library(\n     name = \"go_default_library\",\n-    srcs = [\"service.go\"],\n+    srcs = [\n+        \"bulk_secondary_registration.go\",\n+        \"service.go\",\n+    ],\n     importpath = \"rubrik/physicalhost/svc\",\n     visibility = [\"//visibility:public\"],\n     deps = [\n+        \"//rubrik/authz-service/proto:go_default_library\",\n+        \"//rubrik/cdm-rest-service/proto:go_default_library\",\n+        \"//rubrik/cdm-rest-service/proto/types:go_default_library\",\n+        \"//rubrik/common-go/authz/proto:go_default_library\",\n+        \"//rubrik/common-go/log:go_default_library\",\n         \"//rubrik/physicalhost/errors:go_default_library\",\n         \"//rubrik/physicalhost/proto:go_default_library\",\n+        \"//rubrik/vendor/github.com/golang/protobuf/ptypes/wrappers:go_default_library\",\n+        \"//rubrik/vendor/golang.org/x/sync/errgroup:go_default_library\",\n+        \"//rubrik/vendor/google.golang.org/grpc/codes:go_default_library\",\n+        \"//rubrik/vendor/google.golang.org/grpc/status:go_default_library\",\n     ],\n )\n+"
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration.go",
          "status": "added",
          "additions": 665,
          "deletions": 0,
          "patch": "@@ -0,0 +1,665 @@\n+package svc\n+\n+import (\n+\t\"context\"\n+\t\"errors\"\n+\t\"fmt\"\n+\t\"strings\"\n+\n+\t\"github.com/golang/protobuf/ptypes/wrappers\"\n+\t\"golang.org/x/sync/errgroup\"\n+\t\"google.golang.org/grpc/codes\"\n+\t\"google.golang.org/grpc/status\"\n+\n+\taspb \"rubrik/authz-service/proto\"\n+\tauthz \"rubrik/authz-service/proto\"\n+\tauthzclient \"rubrik/authz-service/proto\"\n+\tcrs \"rubrik/cdm-rest-service/proto\"\n+\tcrstypes \"rubrik/cdm-rest-service/proto/types\"\n+\tacpb \"rubrik/common-go/authz/proto\"\n+\t\"rubrik/common-go/log\"\n+\t\"rubrik/physicalhost/proto\"\n+)\n+\n+const (\n+\tWindowsOsType = \"Windows\"\n+\tLinuxOsType   = \"Linux\"\n+\tAixOsType     = \"AIX\"\n+\tHpuxOsType    = \"HPUX\"\n+\tSunosOsType   = \"SunOS\"\n+\tSuseOsType    = \"SUSE\"\n+)\n+\n+// HostsByPrimaryCluster groups hosts by their primary cluster UUID for\n+// efficient processing\n+type HostsByPrimaryCluster map[string][]*proto.SecondaryRegisterHostInput\n+\n+// BulkRegisterSecondaryHosts registers multiple hosts as secondary hosts on\n+// the specified cluster.\n+func (service *PhysicalHostService) BulkRegisterSecondaryHosts(\n+\tctx context.Context,\n+\treq *proto.BulkRegisterSecondaryHostsReq,\n+) (*proto.BulkRegisterSecondaryHostsReply, error) {\n+\t// For input validation failures, we are not sending any audits.\n+\tif err := validateBulkSecondaryRegisterHostInput(req); err != nil {\n+\t\treturn nil, status.Error(codes.InvalidArgument, err.Error())\n+\t}\n+\n+\t// Fetch and verify managed objects exist and have matching OS types.\n+\t// It will also initialize hostFidToCdmHost map.\n+\thostFidToCdmPhysicalHost, err := fetchAndVerifyManagedObjects(\n+\t\tctx,\n+\t\treq.Hosts,\n+\t\tservice.authzClient,\n+\t\treq.ReqCtx.GetAuthzCtx().GetAccount(),\n+\t)\n+\n+\tif err != nil {\n+\t\treturn nil, status.Error(codes.InvalidArgument, err.Error())\n+\t}\n+\treturn processBulkRegistration(\n+\t\tctx,\n+\t\treq,\n+\t\thostFidToCdmPhysicalHost,\n+\t\tservice.crsClient,\n+\t\tservice.authzClient,\n+\t)\n+}\n+\n+// ProcessBulkRegistration handles the complete bulk registration workflow\n+func processBulkRegistration(\n+\tctx context.Context,\n+\treq *proto.BulkRegisterSecondaryHostsReq,\n+\thostFidToCdmHost map[string]*aspb.CdmPhysicalHost,\n+\tcrsClient crs.CDMRestServiceClient,\n+\tauthzClient authzclient.AuthzClient,\n+) (*proto.BulkRegisterSecondaryHostsReply, error) {\n+\tlog.Infof(\n+\t\tctx, \"Starting bulk secondary host registration for %d hosts on cluster %s\",\n+\t\tlen(req.Hosts), req.SecondaryClusterUuid,\n+\t)\n+\n+\t// Fetch secondary cluster certificate\n+\tsecondaryClusterCert, err :=\n+\t\tcrsClient.V1GetClusterCertificateRPC(\n+\t\t\tctx,\n+\t\t\t&crstypes.V1GetClusterCertificateRequest{\n+\t\t\t\tId:          req.SecondaryClusterUuid,\n+\t\t\t\tAccountName: req.GetReqCtx().GetAuthzCtx().GetAccount(),\n+\t\t\t},\n+\t\t)\n+\tif err != nil {\n+\t\tlog.Errorf(\n+\t\t\tctx,\n+\t\t\t\"Failed to fetch secondary cluster certificate: %v\", err,\n+\t\t)\n+\t\treturn nil, err\n+\t}\n+\n+\t// This will try to transfer the certificate of the secondary\n+\t// cluster to all the hosts.\n+\thostResults := processHostsForRegistration(\n+\t\tctx,\n+\t\treq,\n+\t\tcrsClient,\n+\t\tsecondaryClusterCert,\n+\t)\n+\thostRegisters := make([]*crstypes.HostRegister, 0)\n+\tfor _, host := range req.Hosts {\n+\t\tif hostResults[host.HostFid] == nil {\n+\t\t\thostRegisters = append(hostRegisters, &crstypes.HostRegister{\n+\t\t\t\tHostname: hostFidToCdmHost[host.HostFid].GetName(),\n+\t\t\t\tOsType:   host.OsType,\n+\t\t\t})\n+\t\t}\n+\t}\n+\n+\tif len(hostRegisters) == 0 {\n+\t\t// Certificate transfer failed to all the hosts\n+\t\tlog.Errorf(\n+\t\t\tctx,\n+\t\t\t\"Failed to transfer certificate to any of the hosts. \"+\n+\t\t\t\t\"Aborting bulk host registration.\",\n+\t\t)\n+\n+\t\treturn &proto.BulkRegisterSecondaryHostsReply{\n+\t\t\tHostResults: buildHostRegistrationResults(\n+\t\t\t\treq.Hosts,\n+\t\t\t\thostResults,\n+\t\t\t\thostFidToCdmHost,\n+\t\t\t\tnil,\n+\t\t\t),\n+\t\t}, nil\n+\t}\n+\n+\tbulkRegisterResponse, err := crsClient.V1BulkRegisterHostAsyncRPC(\n+\t\tctx,\n+\t\t&crstypes.V1BulkRegisterHostAsyncRequest{\n+\t\t\tAccountName: req.ReqCtx.AuthzCtx.GetAccount(),\n+\t\t\tClusterUuid: req.SecondaryClusterUuid,\n+\t\t\tHosts:       hostRegisters,\n+\t\t\tReqCtx:      req.ReqCtx,\n+\t\t},\n+\t)\n+\tif err != nil {\n+\t\t// The V1BulkRegisterHostAsyncRPC API does not support partial\n+\t\t// success. So, there might be some hosts that are already\n+\t\t// registered as secondary hosts. Still, returning error for\n+\t\t// all the hosts, since there is no good way to know which\n+\t\t// hosts got registered successfully.\n+\t\tlog.Errorf(\n+\t\t\tctx,\n+\t\t\t\"Failed to complete bulk host registration: %v\",\n+\t\t\terr,\n+\t\t)\n+\n+\t\tfor _, host := range req.Hosts {\n+\t\t\t// Set the error for all the hosts that did not failed in\n+\t\t\t// the certificate transfer\n+\t\t\tif hostResults[host.HostFid] == nil {\n+\t\t\t\thostResults[host.HostFid] = err\n+\t\t\t}\n+\t\t}\n+\t\treturn &proto.BulkRegisterSecondaryHostsReply{\n+\t\t\tHostResults: buildHostRegistrationResults(\n+\t\t\t\treq.Hosts,\n+\t\t\t\thostResults,\n+\t\t\t\thostFidToCdmHost,\n+\t\t\t\tnil,\n+\t\t\t),\n+\t\t}, err\n+\t}\n+\t// Bulk registration succeeded for all the hosts provided to the\n+\t// V1BulkRegisterHostAsyncRPC API.\n+\treturn &proto.BulkRegisterSecondaryHostsReply{\n+\t\tHostResults: buildHostRegistrationResults(\n+\t\t\treq.Hosts,\n+\t\t\thostResults,\n+\t\t\thostFidToCdmHost,\n+\t\t\tbulkRegisterResponse,\n+\t\t),\n+\t}, nil\n+}\n+\n+func buildHostRegistrationResults(\n+\thosts []*proto.SecondaryRegisterHostInput,\n+\thostResults map[string]error,\n+\thostFidToCdmHost map[string]*aspb.CdmPhysicalHost,\n+\tbulkRegisterResponse *crstypes.V1BulkRegisterHostAsyncResponse,\n+) []*proto.HostSecondaryRegistrationResult {\n+\thostResultsList := make([]*proto.HostSecondaryRegistrationResult, 0)\n+\thostnameToHostDetail := make(map[string]*crstypes.HostDetail)\n+\tif bulkRegisterResponse != nil {\n+\t\tfor _, hostDetail := range bulkRegisterResponse.Items {\n+\t\t\t// Sanity check\n+\t\t\tif hostDetail == nil || hostDetail.HostSummary == nil || hostDetail.HostSummary.Hostname == \"\" {\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t\thostnameToHostDetail[hostDetail.HostSummary.Hostname] = hostDetail\n+\t\t}\n+\t}\n+\n+\tfor _, host := range hosts {\n+\t\terrMessage := \"\"\n+\t\tif hostResults[host.HostFid] != nil {\n+\t\t\terrMessage = hostResults[host.HostFid].Error()\n+\t\t}\n+\t\thostResultsList = append(hostResultsList, &proto.HostSecondaryRegistrationResult{\n+\t\t\tPrimaryHostFid: host.HostFid,\n+\t\t\tErrorMessage:   errMessage,\n+\t\t\tHostDetail:     hostnameToHostDetail[hostFidToCdmHost[host.HostFid].GetName()],\n+\t\t})\n+\t}\n+\treturn hostResultsList\n+}\n+\n+// processHostsForRegistration processes all hosts concurrently\n+func processHostsForRegistration(\n+\tctx context.Context,\n+\trequest *proto.BulkRegisterSecondaryHostsReq,\n+\tcrsClient crs.CDMRestServiceClient,\n+\tsecondaryClusterCert *crstypes.ClusterCertificate,\n+) map[string]error {\n+\t// Group hosts by primary cluster for certificate transfer optimization\n+\thostsByPrimaryCluster := make(HostsByPrimaryCluster)\n+\tfor _, host := range request.Hosts {\n+\t\thostsByPrimaryCluster[host.PrimaryClusterUuid] = append(\n+\t\t\thostsByPrimaryCluster[host.PrimaryClusterUuid], host,\n+\t\t)\n+\t}\n+\n+\t// Process each primary cluster concurrently\n+\tresultChan := make(chan map[string]error, len(hostsByPrimaryCluster))\n+\tg, gCtx := errgroup.WithContext(ctx)\n+\n+\tfor primaryClusterUuid, hostsInCluster := range hostsByPrimaryCluster {\n+\t\tcurrentClusterUuid := primaryClusterUuid\n+\t\tcurrentHosts := hostsInCluster\n+\n+\t\tg.Go(func() error {\n+\t\t\tclusterRes := processHostsInCluster(\n+\t\t\t\tgCtx,\n+\t\t\t\tcurrentClusterUuid,\n+\t\t\t\tcurrentHosts,\n+\t\t\t\trequest.SecondaryClusterUuid,\n+\t\t\t\tsecondaryClusterCert,\n+\t\t\t\tcrsClient,\n+\t\t\t\trequest.ReqCtx.AuthzCtx.GetAccount(),\n+\t\t\t)\n+\n+\t\t\tselect {\n+\t\t\tcase resultChan <- clusterRes:\n+\t\t\tcase <-gCtx.Done():\n+\t\t\t}\n+\t\t\treturn nil\n+\t\t})\n+\t}\n+\n+\t// Will not given any error, since we are not returning any error\n+\t// from the goroutines.\n+\t_ = g.Wait()\n+\tclose(resultChan)\n+\n+\t// Aggregate results from all clusters\n+\thostResults := make(map[string]error)\n+\tfor clusterRes := range resultChan {\n+\t\tfor hostFid, err := range clusterRes {\n+\t\t\thostResults[hostFid] = err\n+\t\t}\n+\t}\n+\n+\treturn hostResults\n+}\n+\n+// processHostsInCluster processes all hosts in a single primary cluster\n+func processHostsInCluster(\n+\tctx context.Context,\n+\tprimaryClusterUuid string,\n+\thosts []*proto.SecondaryRegisterHostInput,\n+\tsecondaryClusterUuid string,\n+\tsecondaryClusterCert *crstypes.ClusterCertificate,\n+\tcrsClient crs.CDMRestServiceClient,\n+\taccountName string,\n+) map[string]error {\n+\tresults := make(map[string]error)\n+\n+\t// Initialize all host results\n+\tfor _, host := range hosts {\n+\t\tresults[host.HostFid] = nil\n+\t}\n+\n+\t// Step 1: Transfer certificate to primary cluster\n+\tcertTransferErr := transferCertificateToPrimary(\n+\t\tctx,\n+\t\tprimaryClusterUuid,\n+\t\tsecondaryClusterUuid,\n+\t\tcrsClient,\n+\t\taccountName,\n+\t\tsecondaryClusterCert,\n+\t)\n+\n+\tif certTransferErr != nil {\n+\t\tfor hostFid := range results {\n+\t\t\tresults[hostFid] = certTransferErr\n+\t\t}\n+\t\treturn results\n+\t}\n+\n+\t// Step 2: Run host diagnosis for all hosts in this cluster\n+\tdiagnosisResults := runHostDiagnosis(\n+\t\tctx,\n+\t\thosts,\n+\t\tprimaryClusterUuid,\n+\t\tcrsClient,\n+\t\taccountName,\n+\t)\n+\n+\tfor hostFid, diagnosisErr := range diagnosisResults {\n+\t\tif diagnosisErr != nil {\n+\t\t\tresults[hostFid] = diagnosisErr\n+\t\t}\n+\t}\n+\n+\treturn results\n+}\n+\n+// validates the bulk registration request\n+func validateBulkSecondaryRegisterHostInput(\n+\trequest *proto.BulkRegisterSecondaryHostsReq,\n+) error {\n+\tvar validationErrors []error\n+\n+\tif request.SecondaryClusterUuid == \"\" {\n+\t\tvalidationErrors = append(\n+\t\t\tvalidationErrors,\n+\t\t\terrors.New(\"secondary cluster UUID is required\"),\n+\t\t)\n+\t}\n+\n+\tif len(request.Hosts) == 0 {\n+\t\tvalidationErrors = append(\n+\t\t\tvalidationErrors,\n+\t\t\terrors.New(\"at least one host is required\"),\n+\t\t)\n+\t}\n+\n+\tfor i, host := range request.Hosts {\n+\t\tif host.HostFid == \"\" {\n+\t\t\tvalidationErrors = append(\n+\t\t\t\tvalidationErrors,\n+\t\t\t\tfmt.Errorf(\"host[%d]: host FID is required\", i),\n+\t\t\t)\n+\t\t}\n+\t\tif host.PrimaryClusterUuid == \"\" {\n+\t\t\tvalidationErrors = append(\n+\t\t\t\tvalidationErrors,\n+\t\t\t\tfmt.Errorf(\n+\t\t\t\t\t\"host[%d]: primary cluster UUID is required\", i,\n+\t\t\t\t),\n+\t\t\t)\n+\t\t}\n+\t}\n+\n+\tif len(validationErrors) > 0 {\n+\t\tvar errorMessages []string\n+\t\tfor _, err := range validationErrors {\n+\t\t\terrorMessages = append(errorMessages, err.Error())\n+\t\t}\n+\t\treturn status.Errorf(\n+\t\t\tcodes.InvalidArgument,\n+\t\t\t\"validation failed: %s\", strings.Join(errorMessages, \"; \"),\n+\t\t)\n+\t}\n+\treturn nil\n+}\n+\n+// fetchAndVerifyManagedObjects fetches host managed objects and verifies their\n+// OS types. This validation ensures that:\n+// 1. All provided host FIDs exist as managed objects\n+// 2. All managed objects are physical hosts\n+// 3. The OS type specified in the input matches the actual OS type of the host\n+func fetchAndVerifyManagedObjects(\n+\tctx context.Context,\n+\thosts []*proto.SecondaryRegisterHostInput,\n+\tauthzClient authzclient.AuthzClient,\n+\taccountName string,\n+) (map[string]*aspb.CdmPhysicalHost, error) {\n+\thostFids := make([]string, 0, len(hosts))\n+\tfor _, host := range hosts {\n+\t\thostFids = append(hostFids, host.HostFid)\n+\t}\n+\t// Fetch managed objects (note: results are ordered by ID, not input order)\n+\tmanagedObjectsResponse, err := authzClient.GetManagedObjects(\n+\t\tctx,\n+\t\t&authz.GetManagedObjectsRequest{\n+\t\t\tAccount: accountName,\n+\t\t\tIds:     hostFids,\n+\t\t},\n+\t)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"failed to fetch managed objects: %w\", err)\n+\t}\n+\tmanagedObjects := managedObjectsResponse.GetObjects()\n+\t// Check if all hosts were found\n+\tif len(managedObjects) != len(hostFids) {\n+\t\treturn nil, fmt.Errorf(\n+\t\t\t\"expected %d managed objects, got %d\",\n+\t\t\tlen(hostFids),\n+\t\t\tlen(managedObjects),\n+\t\t)\n+\t}\n+\t// Create a map for quick lookup by FID\n+\tmanagedObjectMap := make(map[string]*aspb.ManagedObject)\n+\tfor _, mo := range managedObjects {\n+\t\tmanagedObjectMap[mo.GetId()] = mo\n+\t}\n+\n+\thostFidToCdmHost := make(map[string]*aspb.CdmPhysicalHost)\n+\n+\t// Verify each host exists and has matching OS type\n+\tvar validationErrors []error\n+\tfor i, host := range hosts {\n+\t\tmo, _ := managedObjectMap[host.HostFid]\n+\n+\t\tif mo.GetManagedObjectType() != acpb.ManagedObjectType_PHYSICAL_HOST {\n+\t\t\tvalidationErrors = append(\n+\t\t\t\tvalidationErrors,\n+\t\t\t\tfmt.Errorf(\n+\t\t\t\t\t\"host[%d]: object %s is not a physical host (type: %s)\",\n+\t\t\t\t\ti, host.HostFid, mo.GetManagedObjectType().String(),\n+\t\t\t\t),\n+\t\t\t)\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\tphysicalHost := mo.GetSpecificObject().GetCdmPhysicalHost()\n+\t\tif physicalHost == nil {\n+\t\t\tvalidationErrors = append(\n+\t\t\t\tvalidationErrors,\n+\t\t\t\tfmt.Errorf(\n+\t\t\t\t\t\"host[%d]: host %s is not a CDM physical host\",\n+\t\t\t\t\ti,\n+\t\t\t\t\thost.HostFid,\n+\t\t\t\t),\n+\t\t\t)\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\terr := verifyOSTypeMatch(host, physicalHost, i)\n+\t\tif err != nil {\n+\t\t\tvalidationErrors = append(validationErrors, err)\n+\t\t\tcontinue\n+\t\t}\n+\t\t// Store host name, it will be used later for sending bulk register rpc call\n+\t\thostFidToCdmHost[host.HostFid] = physicalHost\n+\t}\n+\tif len(validationErrors) > 0 {\n+\t\tvar errorMessages []string\n+\t\tfor _, err := range validationErrors {\n+\t\t\terrorMessages = append(errorMessages, err.Error())\n+\t\t}\n+\t\treturn nil, fmt.Errorf(\n+\t\t\t\"host validation failed: %s\",\n+\t\t\tstrings.Join(errorMessages, \"; \"),\n+\t\t)\n+\t}\n+\treturn hostFidToCdmHost, nil\n+}\n+\n+// verifyOSTypeMatch verifies that the input OS type matches the managed\n+// object's OS type\n+func verifyOSTypeMatch(\n+\thost *proto.SecondaryRegisterHostInput,\n+\tphysicalHost *aspb.CdmPhysicalHost,\n+\thostIndex int,\n+) error {\n+\tvar expectedOSType string\n+\tswitch host.OsType {\n+\tcase crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX:\n+\t\texpectedOSType = LinuxOsType\n+\tcase crstypes.HostRegister_HOST_REGISTER_OS_TYPE_WINDOWS:\n+\t\texpectedOSType = WindowsOsType\n+\tcase crstypes.HostRegister_HOST_REGISTER_OS_TYPE_HPUX:\n+\t\texpectedOSType = HpuxOsType\n+\tcase crstypes.HostRegister_HOST_REGISTER_OS_TYPE_AIX:\n+\t\texpectedOSType = AixOsType\n+\tcase crstypes.HostRegister_HOST_REGISTER_OS_TYPE_SUN_OS:\n+\t\texpectedOSType = SunosOsType\n+\tcase crstypes.HostRegister_HOST_REGISTER_OS_TYPE_EMPTY_VALUE:\n+\t\t// If unspecified, we don't validate OS type, meaning going further\n+\t\t// we will need AddInventory permission on both WINDOWS_HOST_ROOT and\n+\t\t// LINUX_HOST_ROOT\n+\t\treturn nil\n+\tdefault:\n+\t\treturn fmt.Errorf(\n+\t\t\t\"host[%d]: unsupported OS type %s for host %s\",\n+\t\t\thostIndex, host.OsType.String(), host.HostFid,\n+\t\t)\n+\t}\n+\n+\tactualOSType := physicalHost.GetOperatingSystemType()\n+\tlinuxFamily := map[string]bool{\n+\t\tLinuxOsType: true,\n+\t\tAixOsType:   true,\n+\t\tHpuxOsType:  true,\n+\t\tSunosOsType: true,\n+\t\tSuseOsType:  true,\n+\t}\n+\tif actualOSType == expectedOSType ||\n+\t\t(expectedOSType == LinuxOsType && linuxFamily[actualOSType]) {\n+\t\treturn nil\n+\t}\n+\treturn fmt.Errorf(\n+\t\t\"host[%d]: OS type mismatch for host %s - expected %s, got %s\",\n+\t\thostIndex, host.HostFid, expectedOSType, actualOSType,\n+\t)\n+}\n+\n+// transferCertificateToPrimary imports the secondary cluster certificate to\n+// the primary cluster if it doesn't already exist. This function is safe for\n+// concurrent execution across multiple primary clusters.\n+func transferCertificateToPrimary(\n+\tctx context.Context,\n+\tprimaryClusterUuid string,\n+\tsecondaryClusterUuid string,\n+\tcrsClient crs.CDMRestServiceClient,\n+\taccountName string,\n+\tsecondaryClusterCert *crstypes.ClusterCertificate,\n+) error {\n+\tlog.Infof(\n+\t\tctx,\n+\t\t\"Transferring certificate from secondary cluster %s to primary cluster %s\",\n+\t\tsecondaryClusterUuid,\n+\t\tprimaryClusterUuid,\n+\t)\n+\n+\t// Check if certificate already exists\n+\tqueryResponse, err := crsClient.V1QueryCertificatesRPC(\n+\t\tctx,\n+\t\t&crstypes.V1QueryCertificatesRequest{\n+\t\t\tAccountName: accountName,\n+\t\t\tClusterUuid: primaryClusterUuid,\n+\t\t\tSortBy:      crstypes.V1QueryCertificatesRequest_V1_QUERY_CERTIFICATES_REQUEST_SORT_BY_NAME,\n+\t\t\tIsInternal: &wrappers.BoolValue{\n+\t\t\t\tValue: true,\n+\t\t\t},\n+\t\t\tPemFile: &wrappers.StringValue{\n+\t\t\t\tValue: strings.TrimSpace(secondaryClusterCert.Certificate),\n+\t\t\t},\n+\t\t},\n+\t)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\n+\t\t\t\"failed to query certificates on primary cluster %s: %w\",\n+\t\t\tprimaryClusterUuid,\n+\t\t\terr,\n+\t\t)\n+\t}\n+\tvar trustedCertificateId string\n+\tif len(queryResponse.Data) > 0 {\n+\t\ttrustedCertificateId = queryResponse.Data[0].CertId\n+\t} else {\n+\t\t// Certificate doesn't exist, import it\n+\t\timportResponse, err := crsClient.V1ImportCertificateRPC(\n+\t\t\tctx,\n+\t\t\t&crstypes.V1ImportCertificateRequest{\n+\t\t\t\tAccountName: accountName,\n+\t\t\t\tClusterUuid: primaryClusterUuid,\n+\t\t\t\tCertImportRequest: &crstypes.CertificateImportRequest{\n+\t\t\t\t\tName: fmt.Sprintf(\n+\t\t\t\t\t\t\"Cluster %s Certificate\", secondaryClusterUuid,\n+\t\t\t\t\t),\n+\t\t\t\t\tDescription: &wrappers.StringValue{\n+\t\t\t\t\t\tValue: \"Rubrik managed cluster certificate for secondary\" +\n+\t\t\t\t\t\t\t\" registration.\",\n+\t\t\t\t\t},\n+\t\t\t\t\tPemFile: strings.TrimSpace(secondaryClusterCert.Certificate),\n+\t\t\t\t\tIsInternal: &wrappers.BoolValue{\n+\t\t\t\t\t\tValue: true,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t)\n+\t\tif err != nil {\n+\t\t\treturn fmt.Errorf(\n+\t\t\t\t\"failed to import certificate to primary cluster %s: %w\",\n+\t\t\t\tprimaryClusterUuid,\n+\t\t\t\terr,\n+\t\t\t)\n+\t\t}\n+\t\ttrustedCertificateId = importResponse.CertId\n+\t}\n+\n+\t// Mark the certificate as agent secondary certificate\n+\t_, err = crsClient.V1MarkAgentSecondaryCertificateRPC(\n+\t\tctx,\n+\t\t&crstypes.V1MarkAgentSecondaryCertificateRequest{\n+\t\t\tCertId:      trustedCertificateId,\n+\t\t\tAccountName: accountName,\n+\t\t\tClusterUuid: primaryClusterUuid,\n+\t\t},\n+\t)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\n+\t\t\t\"failed to mark certificate as agent secondary certificate\"+\n+\t\t\t\t\" on cluster %s: %w\",\n+\t\t\tprimaryClusterUuid,\n+\t\t\terr,\n+\t\t)\n+\t}\n+\treturn nil\n+}\n+\n+// runHostDiagnosis validates host connectivity and readiness for secondary\n+// registration. Returns a map from hostFid to error, indicating which hosts\n+// passed/failed diagnosis\n+func runHostDiagnosis(\n+\tctx context.Context,\n+\thosts []*proto.SecondaryRegisterHostInput,\n+\tprimaryClusterUuid string,\n+\tcrsClient crs.CDMRestServiceClient,\n+\taccountName string,\n+) map[string]error {\n+\ttype hostResult struct {\n+\t\thostFid string\n+\t\terr     error\n+\t}\n+\n+\tresultChan := make(chan hostResult, len(hosts))\n+\tg, gCtx := errgroup.WithContext(ctx)\n+\n+\tfor _, host := range hosts {\n+\t\tcurrentHost := host\n+\t\tg.Go(func() error {\n+\t\t\t_, err := crsClient.InternalGetHostDiagnosisRPC(\n+\t\t\t\tctx,\n+\t\t\t\t&crstypes.InternalGetHostDiagnosisRequest{\n+\t\t\t\t\tAccountName: accountName,\n+\t\t\t\t\tClusterUuid: primaryClusterUuid,\n+\t\t\t\t\tId:          currentHost.HostFid,\n+\t\t\t\t},\n+\t\t\t)\n+\n+\t\t\tselect {\n+\t\t\tcase resultChan <- hostResult{hostFid: currentHost.HostFid, err: err}:\n+\t\t\tcase <-gCtx.Done():\n+\t\t\t\t// Prevents panic from sending to closed channel when context is cancelled\n+\t\t\t}\n+\n+\t\t\t// Don't return error to errgroup - we want all diagnoses to complete\n+\t\t\treturn nil\n+\t\t})\n+\t}\n+\n+\t// Wait for all goroutines to complete or context cancellation\n+\t_ = g.Wait()\n+\tclose(resultChan)\n+\n+\t// Collect results into map\n+\tdiagnosisResults := make(map[string]error)\n+\tfor result := range resultChan {\n+\t\tdiagnosisResults[result.hostFid] = result.err\n+\t}\n+\n+\treturn diagnosisResults\n+}"
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/svc/service.go",
          "status": "modified",
          "additions": 16,
          "deletions": 11,
          "patch": "@@ -7,30 +7,35 @@ package svc\n import (\n \t\"context\"\n \n-\t\"rubrik/physicalhost/errors\"\n+\tauthzclient \"rubrik/authz-service/proto\"\n+\tcrs \"rubrik/cdm-rest-service/proto\"\n+\tphysicalhosterrors \"rubrik/physicalhost/errors\"\n \t\"rubrik/physicalhost/proto\"\n )\n \n // PhysicalHostService provides physical host management functionality.\n type PhysicalHostService struct {\n+\tcrsClient   crs.CDMRestServiceClient\n+\tauthzClient authzclient.AuthzClient\n }\n \n // NewPhysicalHostService constructs a new PhysicalHostService.\n-func NewPhysicalHostService(ctx context.Context) (*PhysicalHostService, error) {\n-\treturn &PhysicalHostService{}, nil\n+func NewPhysicalHostService(\n+\tcrsClient crs.CDMRestServiceClient,\n+\tauthzClient authzclient.AuthzClient,\n+) (*PhysicalHostService, error) {\n+\tservice := &PhysicalHostService{\n+\t\tcrsClient:   crsClient,\n+\t\tauthzClient: authzClient,\n+\t}\n+\n+\treturn service, nil\n }\n \n // Echo implements the echo RPC endpoint.\n func (service *PhysicalHostService) Echo(\n \tctx context.Context,\n \tin *proto.EchoReq,\n ) (*proto.EchoReply, error) {\n-\treturn nil, errors.ErrNotImplemented\n-}\n-\n-func (service *PhysicalHostService) BulkRegisterSecondaryHosts(\n-\tctx context.Context,\n-\tin *proto.BulkRegisterSecondaryHostsReq,\n-) (*proto.BulkRegisterSecondaryHostsReply, error) {\n-\treturn nil, errors.ErrNotImplemented\n+\treturn nil, physicalhosterrors.ErrNotImplemented\n }"
        }
      ],
      "statistics": {
        "commits": 7,
        "files_changed": 7,
        "additions": 752,
        "deletions": 15,
        "total_comments": 2
      }
    },
    "processed_data": {
      "title": "PR Review: Implement bulk register secondary host rpc",
      "summary": "## Summary:\nImplemented the bulk secondary registration api.\n\n## Test Plan:\nManual testing\r\n\r\n<img width=\"1574\" height=\"1036\" alt=\"image\" src=\"https://github.com/user-attachments/assets/5760fe70-a9d6-...",
      "action_items": [
        {
          "item": "Review PR: Implement bulk register secondary host rpc",
          "priority": "medium",
          "next_steps": [
            "Read description",
            "Review code changes",
            "Test locally"
          ]
        }
      ],
      "urgency_score": 1.0,
      "context": "GitHub PR in gh/moht-agrawal-rubrik/15/head branch"
    }
  },
  {
    "source": "github",
    "candidate_id": "github_pr_97551",
    "raw_data": {
      "pr_title": "Add unit tests for bulk secondary registration api",
      "pr_summary": "## Summary:\nAdded unit tests for bulk secondary registration api.\n\n## Test Plan:\nUnit tests\n\n## JIRA Issues:\nSPARK-572184\n\n## Revert Plan:\n## PR Stack:\nStack from arc wrapper with help from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):\n* #97821\n* __->__ #97551\n* #97450\n* #97449\n",
      "pr_url": "https://github.com/scaledata/sdmain/pull/97551",
      "metadata": {
        "number": 97551,
        "state": "open",
        "author": "moht-agrawal-rubrik",
        "created_at": "2025-09-02T11:32:33Z",
        "updated_at": "2025-09-09T18:39:25Z",
        "merged_at": null,
        "base_branch": "gh/moht-agrawal-rubrik/16/head",
        "head_branch": "gh/moht-agrawal-rubrik/17/head",
        "labels": [],
        "assignees": [],
        "reviewers": []
      },
      "comments": {
        "global_comments": [
          {
            "type": "discussion",
            "author": "rogers-sail-information[bot]",
            "created_at": "2025-09-02T11:32:58Z",
            "body": "<!-- rogers sail info comment -->\n## Sail Request\n\n> Rogers will automatically update this comment to reflect the current sail status of your PR when you begin a sail request.",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97551#issuecomment-3244941012"
          },
          {
            "type": "discussion",
            "author": "rubrik-alfred[bot]",
            "created_at": "2025-09-09T18:39:25Z",
            "body": "## :man_in_tuxedo: Alfred Comments\n<input type='hidden' commit='5b2b8f20178aa5a3824e1b3b250300244fd54f06' global='true'/>\n<!--Header_Done-->\n\nChanges in RBA code require review from #rba_rba-reviews. For guidelines, please check [RBA Code Review Checklist](https://rubrik.atlassian.net/wiki/spaces/EN/pages/3835331585/RBA+Code+Review+Checklist).\n\n<details>\n<summary>Click here to view the file paths triggering this rule</summary>\n<ul>\n<li><code>polaris/src/rubrik/physicalhost/svc/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration_test.go</code></li>\n</ul>\n</details>\n\n\n------\n\nTriggering the detect-changed-services pipeline. If your PR is raised against a Polaris release branch, this pipeline will leave a comment with a list of the services that will be affected by the changes in your PR.\n\n\nThe following jobs are triggered:\n\n\n- [detect-changed-services](https://polaris-builds.stark.rubrik.com/job/detect-changed-services)\n\n\n<details>\n<summary>Click here to view the file paths triggering these jobs</summary>\n<ul>\n<li><code>polaris/src/rubrik/physicalhost/svc/BUILD.bazel</code></li>\n<li><code>polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration_test.go</code></li>\n</ul>\n</details>\n\n\n------\n\n<!--Footer_Start-->\n\n",
            "comment_url": "https://github.com/scaledata/sdmain/pull/97551#issuecomment-3271864561"
          }
        ],
        "inline_comments": []
      },
      "files_changed": [
        {
          "filename": "polaris/src/rubrik/physicalhost/svc/BUILD.bazel",
          "status": "modified",
          "additions": 19,
          "deletions": 0,
          "patch": "@@ -22,3 +22,22 @@ go_library(\n     ],\n )\n \n+go_test(\n+    name = \"go_default_test\",\n+    srcs = [\"bulk_secondary_registration_test.go\"],\n+    embed = [\":go_default_library\"],\n+    deps = [\n+        \"//rubrik/authz-service/proto:go_default_library\",\n+        \"//rubrik/cdm-rest-service/proto:go_default_library\",\n+        \"//rubrik/cdm-rest-service/proto/types:go_default_library\",\n+        \"//rubrik/common-go/api/context/proto:go_default_library\",\n+        \"//rubrik/common-go/authz/proto:go_default_library\",\n+        \"//rubrik/physicalhost/proto:go_default_library\",\n+        \"//rubrik/vendor/github.com/golang/protobuf/ptypes/wrappers:go_default_library\",\n+        \"//rubrik/vendor/github.com/stretchr/testify/assert:go_default_library\",\n+        \"//rubrik/vendor/github.com/stretchr/testify/mock:go_default_library\",\n+        \"//rubrik/vendor/github.com/stretchr/testify/require:go_default_library\",\n+        \"//rubrik/vendor/google.golang.org/grpc/codes:go_default_library\",\n+        \"//rubrik/vendor/google.golang.org/grpc/status:go_default_library\",\n+    ],\n+)"
        },
        {
          "filename": "polaris/src/rubrik/physicalhost/svc/bulk_secondary_registration_test.go",
          "status": "added",
          "additions": 2341,
          "deletions": 0,
          "patch": "@@ -0,0 +1,2341 @@\n+package svc\n+\n+import (\n+\t\"context\"\n+\t\"errors\"\n+\t\"testing\"\n+\n+\t\"github.com/stretchr/testify/assert\"\n+\t\"github.com/stretchr/testify/mock\"\n+\t\"github.com/stretchr/testify/require\"\n+\t\"google.golang.org/grpc/codes\"\n+\t\"google.golang.org/grpc/status\"\n+\n+\taspb \"rubrik/authz-service/proto\"\n+\tauthz \"rubrik/authz-service/proto\"\n+\tcrs \"rubrik/cdm-rest-service/proto\"\n+\tcrstypes \"rubrik/cdm-rest-service/proto/types\"\n+\tcontextproto \"rubrik/common-go/api/context/proto\"\n+\tacpb \"rubrik/common-go/authz/proto\"\n+\tauthzcommon \"rubrik/common-go/authz/proto\"\n+\t\"rubrik/physicalhost/proto\"\n+)\n+\n+// Test constants\n+const (\n+\ttestAccountName          = \"test-account\"\n+\ttestSecondaryClusterUUID = \"secondary-cluster-uuid\"\n+\ttestPrimaryClusterUUID1  = \"primary-cluster-uuid-1\"\n+\ttestHostFID1             = \"host-fid-1\"\n+\ttestHostFID2             = \"host-fid-2\"\n+\ttestHostFID3             = \"host-fid-3\"\n+\ttestHostname1            = \"hostname1.example.com\"\n+\ttestHostname2            = \"hostname2.example.com\"\n+\ttestHostname3            = \"hostname3.example.com\"\n+\ttestCertificate          = \"-----BEGIN CERTIFICATE-----\\ntest-cert-data\\n-----END CERTIFICATE-----\"\n+\ttestCertID               = \"cert-id-123\"\n+)\n+\n+// Helper functions to create test data\n+func createTestRequest() *proto.BulkRegisterSecondaryHostsReq {\n+\treturn &proto.BulkRegisterSecondaryHostsReq{\n+\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\tAccount: testAccountName,\n+\t\t\t},\n+\t\t},\n+\t\tSecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\tHosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t{\n+\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t},\n+\t\t\t{\n+\t\t\t\tHostFid:            testHostFID2,\n+\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_WINDOWS,\n+\t\t\t},\n+\t\t},\n+\t}\n+}\n+\n+// Helper functions for certificate tests\n+func createTestClusterCertificate() *crstypes.ClusterCertificate {\n+\treturn &crstypes.ClusterCertificate{\n+\t\tCertificate: testCertificate,\n+\t}\n+}\n+\n+func createTestCertificateSummary(certId string) *crstypes.CertificateSummary {\n+\treturn &crstypes.CertificateSummary{\n+\t\tCertId: certId,\n+\t\tName:   \"Test Certificate\",\n+\t}\n+}\n+\n+func createTestManagedObject(hostFID, hostname, osType string) *aspb.ManagedObject {\n+\treturn &aspb.ManagedObject{\n+\t\tId:                hostFID,\n+\t\tManagedObjectType: acpb.ManagedObjectType_PHYSICAL_HOST,\n+\t\tSpecificObject: &aspb.SpecificManagedObject{\n+\t\t\tObject: &aspb.SpecificManagedObject_CdmPhysicalHost{\n+\t\t\t\tCdmPhysicalHost: &aspb.CdmPhysicalHost{\n+\t\t\t\t\tName:                hostname,\n+\t\t\t\t\tOperatingSystemType: osType,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t},\n+\t}\n+}\n+\n+func createTestManagedObjectWithType(\n+\thostFID string,\n+\tobjectType acpb.ManagedObjectType,\n+) *aspb.ManagedObject {\n+\treturn &aspb.ManagedObject{\n+\t\tId:                hostFID,\n+\t\tManagedObjectType: objectType,\n+\t}\n+}\n+\n+// TestValidateBulkSecondaryRegisterHostInput tests the input validation function\n+func TestValidateBulkSecondaryRegisterHostInput(t *testing.T) {\n+\ttests := []struct {\n+\t\tname        string\n+\t\trequest     *proto.BulkRegisterSecondaryHostsReq\n+\t\texpectError bool\n+\t\terrorCode   codes.Code\n+\t\terrorMsg    string\n+\t}{\n+\t\t{\n+\t\t\tname:        \"valid request\",\n+\t\t\trequest:     createTestRequest(),\n+\t\t\texpectError: false,\n+\t\t},\n+\t\t{\n+\t\t\tname: \"missing secondary cluster UUID\",\n+\t\t\trequest: &proto.BulkRegisterSecondaryHostsReq{\n+\t\t\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\t\t\tAccount: testAccountName,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t\tSecondaryClusterUuid: \"\",\n+\t\t\t\tHosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\texpectError: true,\n+\t\t\terrorCode:   codes.InvalidArgument,\n+\t\t\terrorMsg:    \"secondary cluster UUID is required\",\n+\t\t},\n+\t\t{\n+\t\t\tname: \"empty hosts list\",\n+\t\t\trequest: &proto.BulkRegisterSecondaryHostsReq{\n+\t\t\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\t\t\tAccount: testAccountName,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t\tSecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\t\t\tHosts:                []*proto.SecondaryRegisterHostInput{},\n+\t\t\t},\n+\t\t\texpectError: true,\n+\t\t\terrorCode:   codes.InvalidArgument,\n+\t\t\terrorMsg:    \"at least one host is required\",\n+\t\t},\n+\t\t{\n+\t\t\tname: \"missing host FID\",\n+\t\t\trequest: &proto.BulkRegisterSecondaryHostsReq{\n+\t\t\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\t\t\tAccount: testAccountName,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t\tSecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\t\t\tHosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            \"\",\n+\t\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\texpectError: true,\n+\t\t\terrorCode:   codes.InvalidArgument,\n+\t\t\terrorMsg:    \"host[0]: host FID is required\",\n+\t\t},\n+\t\t{\n+\t\t\tname: \"missing primary cluster UUID\",\n+\t\t\trequest: &proto.BulkRegisterSecondaryHostsReq{\n+\t\t\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\t\t\tAccount: testAccountName,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t\tSecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\t\t\tHosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\t\t\tPrimaryClusterUuid: \"\",\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\texpectError: true,\n+\t\t\terrorCode:   codes.InvalidArgument,\n+\t\t\terrorMsg:    \"host[0]: primary cluster UUID is required\",\n+\t\t},\n+\t}\n+\n+\tfor _, tt := range tests {\n+\t\tt.Run(tt.name, func(t *testing.T) {\n+\t\t\terr := validateBulkSecondaryRegisterHostInput(tt.request)\n+\n+\t\t\tif tt.expectError {\n+\t\t\t\trequire.Error(t, err)\n+\t\t\t\tstatusErr, ok := status.FromError(err)\n+\t\t\t\trequire.True(t, ok, \"Expected gRPC status error\")\n+\t\t\t\tassert.Equal(t, tt.errorCode, statusErr.Code())\n+\t\t\t\tassert.Contains(t, statusErr.Message(), tt.errorMsg)\n+\t\t\t} else {\n+\t\t\t\tassert.NoError(t, err)\n+\t\t\t}\n+\t\t})\n+\t}\n+}\n+\n+// TestVerifyOSTypeMatch tests the OS type matching logic\n+func TestVerifyOSTypeMatch(t *testing.T) {\n+\ttests := []struct {\n+\t\tname         string\n+\t\thost         *proto.SecondaryRegisterHostInput\n+\t\tphysicalHost *aspb.CdmPhysicalHost\n+\t\thostIndex    int\n+\t\texpectError  bool\n+\t\terrorMsg     string\n+\t}{\n+\t\t{\n+\t\t\tname: \"exact Linux match\",\n+\t\t\thost: &proto.SecondaryRegisterHostInput{\n+\t\t\t\tHostFid: testHostFID1,\n+\t\t\t\tOsType:  crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t},\n+\t\t\tphysicalHost: &aspb.CdmPhysicalHost{\n+\t\t\t\tOperatingSystemType: LinuxOsType,\n+\t\t\t},\n+\t\t\thostIndex:   0,\n+\t\t\texpectError: false,\n+\t\t},\n+\t\t{\n+\t\t\tname: \"exact Windows match\",\n+\t\t\thost: &proto.SecondaryRegisterHostInput{\n+\t\t\t\tHostFid: testHostFID1,\n+\t\t\t\tOsType:  crstypes.HostRegister_HOST_REGISTER_OS_TYPE_WINDOWS,\n+\t\t\t},\n+\t\t\tphysicalHost: &aspb.CdmPhysicalHost{\n+\t\t\t\tOperatingSystemType: WindowsOsType,\n+\t\t\t},\n+\t\t\thostIndex:   0,\n+\t\t\texpectError: false,\n+\t\t},\n+\t\t{\n+\t\t\tname: \"exact AIX match\",\n+\t\t\thost: &proto.SecondaryRegisterHostInput{\n+\t\t\t\tHostFid: testHostFID1,\n+\t\t\t\tOsType:  crstypes.HostRegister_HOST_REGISTER_OS_TYPE_AIX,\n+\t\t\t},\n+\t\t\tphysicalHost: &aspb.CdmPhysicalHost{\n+\t\t\t\tOperatingSystemType: AixOsType,\n+\t\t\t},\n+\t\t\thostIndex:   0,\n+\t\t\texpectError: false,\n+\t\t},\n+\t\t{\n+\t\t\tname: \"exact HPUX match\",\n+\t\t\thost: &proto.SecondaryRegisterHostInput{\n+\t\t\t\tHostFid: testHostFID1,\n+\t\t\t\tOsType:  crstypes.HostRegister_HOST_REGISTER_OS_TYPE_HPUX,\n+\t\t\t},\n+\t\t\tphysicalHost: &aspb.CdmPhysicalHost{\n+\t\t\t\tOperatingSystemType: HpuxOsType,\n+\t\t\t},\n+\t\t\thostIndex:   0,\n+\t\t\texpectError: false,\n+\t\t},\n+\t\t{\n+\t\t\tname: \"exact SunOS match\",\n+\t\t\thost: &proto.SecondaryRegisterHostInput{\n+\t\t\t\tHostFid: testHostFID1,\n+\t\t\t\tOsType:  crstypes.HostRegister_HOST_REGISTER_OS_TYPE_SUN_OS,\n+\t\t\t},\n+\t\t\tphysicalHost: &aspb.CdmPhysicalHost{\n+\t\t\t\tOperatingSystemType: SunosOsType,\n+\t\t\t},\n+\t\t\thostIndex:   0,\n+\t\t\texpectError: false,\n+\t\t},\n+\t\t{\n+\t\t\tname: \"Linux family - AIX matches Linux\",\n+\t\t\thost: &proto.SecondaryRegisterHostInput{\n+\t\t\t\tHostFid: testHostFID1,\n+\t\t\t\tOsType:  crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t},\n+\t\t\tphysicalHost: &aspb.CdmPhysicalHost{\n+\t\t\t\tOperatingSystemType: AixOsType,\n+\t\t\t},\n+\t\t\thostIndex:   0,\n+\t\t\texpectError: false,\n+\t\t},\n+\t\t{\n+\t\t\tname: \"Linux family - HPUX matches Linux\",\n+\t\t\thost: &proto.SecondaryRegisterHostInput{\n+\t\t\t\tHostFid: testHostFID1,\n+\t\t\t\tOsType:  crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t},\n+\t\t\tphysicalHost: &aspb.CdmPhysicalHost{\n+\t\t\t\tOperatingSystemType: HpuxOsType,\n+\t\t\t},\n+\t\t\thostIndex:   0,\n+\t\t\texpectError: false,\n+\t\t},\n+\t\t{\n+\t\t\tname: \"Linux family - SunOS matches Linux\",\n+\t\t\thost: &proto.SecondaryRegisterHostInput{\n+\t\t\t\tHostFid: testHostFID1,\n+\t\t\t\tOsType:  crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t},\n+\t\t\tphysicalHost: &aspb.CdmPhysicalHost{\n+\t\t\t\tOperatingSystemType: SunosOsType,\n+\t\t\t},\n+\t\t\thostIndex:   0,\n+\t\t\texpectError: false,\n+\t\t},\n+\t\t{\n+\t\t\tname: \"Linux family - SUSE matches Linux\",\n+\t\t\thost: &proto.SecondaryRegisterHostInput{\n+\t\t\t\tHostFid: testHostFID1,\n+\t\t\t\tOsType:  crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t},\n+\t\t\tphysicalHost: &aspb.CdmPhysicalHost{\n+\t\t\t\tOperatingSystemType: SuseOsType,\n+\t\t\t},\n+\t\t\thostIndex:   0,\n+\t\t\texpectError: false,\n+\t\t},\n+\t\t{\n+\t\t\tname: \"empty OS type - no validation\",\n+\t\t\thost: &proto.SecondaryRegisterHostInput{\n+\t\t\t\tHostFid: testHostFID1,\n+\t\t\t\tOsType:  crstypes.HostRegister_HOST_REGISTER_OS_TYPE_EMPTY_VALUE,\n+\t\t\t},\n+\t\t\tphysicalHost: &aspb.CdmPhysicalHost{\n+\t\t\t\tOperatingSystemType: WindowsOsType,\n+\t\t\t},\n+\t\t\thostIndex:   0,\n+\t\t\texpectError: false,\n+\t\t},\n+\t\t{\n+\t\t\tname: \"OS type mismatch - Linux vs Windows\",\n+\t\t\thost: &proto.SecondaryRegisterHostInput{\n+\t\t\t\tHostFid: testHostFID1,\n+\t\t\t\tOsType:  crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t},\n+\t\t\tphysicalHost: &aspb.CdmPhysicalHost{\n+\t\t\t\tOperatingSystemType: WindowsOsType,\n+\t\t\t},\n+\t\t\thostIndex:   1,\n+\t\t\texpectError: true,\n+\t\t\terrorMsg:    \"host[1]: OS type mismatch for host host-fid-1 - expected Linux, got Windows\",\n+\t\t},\n+\t\t{\n+\t\t\tname: \"OS type mismatch - Windows vs Linux\",\n+\t\t\thost: &proto.SecondaryRegisterHostInput{\n+\t\t\t\tHostFid: testHostFID2,\n+\t\t\t\tOsType:  crstypes.HostRegister_HOST_REGISTER_OS_TYPE_WINDOWS,\n+\t\t\t},\n+\t\t\tphysicalHost: &aspb.CdmPhysicalHost{\n+\t\t\t\tOperatingSystemType: LinuxOsType,\n+\t\t\t},\n+\t\t\thostIndex:   2,\n+\t\t\texpectError: true,\n+\t\t\terrorMsg:    \"host[2]: OS type mismatch for host host-fid-2 - expected Windows, got Linux\",\n+\t\t},\n+\t\t{\n+\t\t\tname: \"OS type mismatch - AIX vs Windows\",\n+\t\t\thost: &proto.SecondaryRegisterHostInput{\n+\t\t\t\tHostFid: testHostFID1,\n+\t\t\t\tOsType:  crstypes.HostRegister_HOST_REGISTER_OS_TYPE_AIX,\n+\t\t\t},\n+\t\t\tphysicalHost: &aspb.CdmPhysicalHost{\n+\t\t\t\tOperatingSystemType: WindowsOsType,\n+\t\t\t},\n+\t\t\thostIndex:   0,\n+\t\t\texpectError: true,\n+\t\t\terrorMsg:    \"host[0]: OS type mismatch for host host-fid-1 - expected AIX, got Windows\",\n+\t\t},\n+\t}\n+\n+\tfor _, tt := range tests {\n+\t\tt.Run(\n+\t\t\ttt.name, func(t *testing.T) {\n+\t\t\t\terr := verifyOSTypeMatch(tt.host, tt.physicalHost, tt.hostIndex)\n+\n+\t\t\t\tif tt.expectError {\n+\t\t\t\t\trequire.Error(t, err)\n+\t\t\t\t\tassert.Contains(t, err.Error(), tt.errorMsg)\n+\t\t\t\t} else {\n+\t\t\t\t\tassert.NoError(t, err)\n+\t\t\t\t}\n+\t\t\t},\n+\t\t)\n+\t}\n+}\n+\n+// TestRunHostDiagnosis tests the concurrent host diagnosis function\n+func TestRunHostDiagnosis(t *testing.T) {\n+\tctx := context.Background()\n+\n+\ttests := []struct {\n+\t\tname               string\n+\t\thosts              []*proto.SecondaryRegisterHostInput\n+\t\tprimaryClusterUuid string\n+\t\taccountName        string\n+\t\tsetupMocks         func(*crs.MockCDMRestServiceClient)\n+\t\texpectedResults    map[string]error\n+\t}{\n+\t\t{\n+\t\t\tname: \"all hosts diagnosis successful\",\n+\t\t\thosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t{HostFid: testHostFID1},\n+\t\t\t\t{HostFid: testHostFID2},\n+\t\t\t},\n+\t\t\tprimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\taccountName:        testAccountName,\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient) {\n+\t\t\t\t// Both hosts succeed\n+\t\t\t\tmockCRS.On(\n+\t\t\t\t\t\"InternalGetHostDiagnosisRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(\n+\t\t\t\t\t\tfunc(req *crstypes.InternalGetHostDiagnosisRequest) bool {\n+\t\t\t\t\t\t\treturn req.AccountName == testAccountName &&\n+\t\t\t\t\t\t\t\treq.ClusterUuid == testPrimaryClusterUUID1 &&\n+\t\t\t\t\t\t\t\t(req.Id == testHostFID1 || req.Id == testHostFID2)\n+\t\t\t\t\t\t},\n+\t\t\t\t\t),\n+\t\t\t\t).Return(&crstypes.HostDiagnosisSummary{}, nil)\n+\t\t\t},\n+\t\t\texpectedResults: map[string]error{\n+\t\t\t\ttestHostFID1: nil,\n+\t\t\t\ttestHostFID2: nil,\n+\t\t\t},\n+\t\t},\n+\t\t{\n+\t\t\tname: \"mixed diagnosis results\",\n+\t\t\thosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t{HostFid: testHostFID1},\n+\t\t\t\t{HostFid: testHostFID2},\n+\t\t\t\t{HostFid: testHostFID3},\n+\t\t\t},\n+\t\t\tprimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\taccountName:        testAccountName,\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient) {\n+\t\t\t\t// Host 1 succeeds\n+\t\t\t\tmockCRS.On(\n+\t\t\t\t\t\"InternalGetHostDiagnosisRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(\n+\t\t\t\t\t\tfunc(req *crstypes.InternalGetHostDiagnosisRequest) bool {\n+\t\t\t\t\t\t\treturn req.Id == testHostFID1\n+\t\t\t\t\t\t},\n+\t\t\t\t\t),\n+\t\t\t\t).Return(&crstypes.HostDiagnosisSummary{}, nil)\n+\n+\t\t\t\t// Host 2 fails\n+\t\t\t\tmockCRS.On(\n+\t\t\t\t\t\"InternalGetHostDiagnosisRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(\n+\t\t\t\t\t\tfunc(req *crstypes.InternalGetHostDiagnosisRequest) bool {\n+\t\t\t\t\t\t\treturn req.Id == testHostFID2\n+\t\t\t\t\t\t},\n+\t\t\t\t\t),\n+\t\t\t\t).Return(\n+\t\t\t\t\t(*crstypes.HostDiagnosisSummary)(nil),\n+\t\t\t\t\terrors.New(\"host unreachable\"),\n+\t\t\t\t)\n+\n+\t\t\t\t// Host 3 succeeds\n+\t\t\t\tmockCRS.On(\n+\t\t\t\t\t\"InternalGetHostDiagnosisRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(\n+\t\t\t\t\t\tfunc(req *crstypes.InternalGetHostDiagnosisRequest) bool {\n+\t\t\t\t\t\t\treturn req.Id == testHostFID3\n+\t\t\t\t\t\t},\n+\t\t\t\t\t),\n+\t\t\t\t).Return(&crstypes.HostDiagnosisSummary{}, nil)\n+\t\t\t},\n+\t\t\texpectedResults: map[string]error{\n+\t\t\t\ttestHostFID1: nil,\n+\t\t\t\ttestHostFID2: errors.New(\"host unreachable\"),\n+\t\t\t\ttestHostFID3: nil,\n+\t\t\t},\n+\t\t},\n+\t\t{\n+\t\t\tname: \"all hosts diagnosis fail\",\n+\t\t\thosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t{HostFid: testHostFID1},\n+\t\t\t\t{HostFid: testHostFID2},\n+\t\t\t},\n+\t\t\tprimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\taccountName:        testAccountName,\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient) {\n+\t\t\t\t// Both hosts fail\n+\t\t\t\tmockCRS.On(\n+\t\t\t\t\t\"InternalGetHostDiagnosisRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(\n+\t\t\t\t\t\tfunc(req *crstypes.InternalGetHostDiagnosisRequest) bool {\n+\t\t\t\t\t\t\treturn req.Id == testHostFID1 || req.Id == testHostFID2\n+\t\t\t\t\t\t},\n+\t\t\t\t\t),\n+\t\t\t\t).Return(\n+\t\t\t\t\t(*crstypes.HostDiagnosisSummary)(nil),\n+\t\t\t\t\terrors.New(\"diagnosis failed\"),\n+\t\t\t\t)\n+\t\t\t},\n+\t\t\texpectedResults: map[string]error{\n+\t\t\t\ttestHostFID1: errors.New(\"diagnosis failed\"),\n+\t\t\t\ttestHostFID2: errors.New(\"diagnosis failed\"),\n+\t\t\t},\n+\t\t},\n+\t\t{\n+\t\t\tname: \"single host diagnosis success\",\n+\t\t\thosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t{HostFid: testHostFID1},\n+\t\t\t},\n+\t\t\tprimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\taccountName:        testAccountName,\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient) {\n+\t\t\t\tmockCRS.On(\n+\t\t\t\t\t\"InternalGetHostDiagnosisRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(\n+\t\t\t\t\t\tfunc(req *crstypes.InternalGetHostDiagnosisRequest) bool {\n+\t\t\t\t\t\t\treturn req.Id == testHostFID1 &&\n+\t\t\t\t\t\t\t\treq.AccountName == testAccountName &&\n+\t\t\t\t\t\t\t\treq.ClusterUuid == testPrimaryClusterUUID1\n+\t\t\t\t\t\t},\n+\t\t\t\t\t),\n+\t\t\t\t).Return(&crstypes.HostDiagnosisSummary{}, nil)\n+\t\t\t},\n+\t\t\texpectedResults: map[string]error{\n+\t\t\t\ttestHostFID1: nil,\n+\t\t\t},\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"empty hosts list\",\n+\t\t\thosts:              []*proto.SecondaryRegisterHostInput{},\n+\t\t\tprimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\taccountName:        testAccountName,\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient) {\n+\t\t\t\t// No mocks needed for empty list\n+\t\t\t},\n+\t\t\texpectedResults: map[string]error{},\n+\t\t},\n+\t}\n+\n+\tfor _, tt := range tests {\n+\t\tt.Run(\n+\t\t\ttt.name, func(t *testing.T) {\n+\t\t\t\tmockCRS := &crs.MockCDMRestServiceClient{}\n+\t\t\t\ttt.setupMocks(mockCRS)\n+\n+\t\t\t\tresults := runHostDiagnosis(\n+\t\t\t\t\tctx,\n+\t\t\t\t\ttt.hosts,\n+\t\t\t\t\ttt.primaryClusterUuid,\n+\t\t\t\t\tmockCRS,\n+\t\t\t\t\ttt.accountName,\n+\t\t\t\t)\n+\n+\t\t\t\trequire.Equal(t, len(tt.expectedResults), len(results))\n+\n+\t\t\t\tfor hostFid, expectedErr := range tt.expectedResults {\n+\t\t\t\t\tactualErr, exists := results[hostFid]\n+\t\t\t\t\trequire.True(\n+\t\t\t\t\t\tt,\n+\t\t\t\t\t\texists,\n+\t\t\t\t\t\t\"Expected result for host %s not found\",\n+\t\t\t\t\t\thostFid,\n+\t\t\t\t\t)\n+\n+\t\t\t\t\tif expectedErr == nil {\n+\t\t\t\t\t\tassert.NoError(t, actualErr)\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\trequire.Error(t, actualErr)\n+\t\t\t\t\t\tassert.Contains(t, actualErr.Error(), expectedErr.Error())\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\tmockCRS.AssertExpectations(t)\n+\t\t\t},\n+\t\t)\n+\t}\n+}\n+\n+// TestTransferCertificateToPrimary tests the certificate transfer logic\n+func TestTransferCertificateToPrimary(t *testing.T) {\n+\tctx := context.Background()\n+\n+\ttests := []struct {\n+\t\tname                 string\n+\t\tprimaryClusterUuid   string\n+\t\tsecondaryClusterUuid string\n+\t\taccountName          string\n+\t\tsecondaryClusterCert *crstypes.ClusterCertificate\n+\t\tsetupMocks           func(*crs.MockCDMRestServiceClient)\n+\t\texpectError          bool\n+\t\texpectedErrorMsg     string\n+\t}{\n+\t\t{\n+\t\t\tname:                 \"certificate already exists\",\n+\t\t\tprimaryClusterUuid:   testPrimaryClusterUUID1,\n+\t\t\tsecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\t\taccountName:          testAccountName,\n+\t\t\tsecondaryClusterCert: createTestClusterCertificate(),\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient) {\n+\t\t\t\t// Certificate query returns existing certificate\n+\t\t\t\tmockCRS.On(\n+\t\t\t\t\t\"V1QueryCertificatesRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(\n+\t\t\t\t\t\tfunc(req *crstypes.V1QueryCertificatesRequest) bool {\n+\t\t\t\t\t\t\treturn req.AccountName == testAccountName &&\n+\t\t\t\t\t\t\t\treq.ClusterUuid == testPrimaryClusterUUID1 &&\n+\t\t\t\t\t\t\t\treq.PemFile.Value == testCertificate &&\n+\t\t\t\t\t\t\t\treq.IsInternal.Value == true\n+\t\t\t\t\t\t},\n+\t\t\t\t\t),\n+\t\t\t\t).Return(\n+\t\t\t\t\t&crstypes.CertificateSummaryListResponse{\n+\t\t\t\t\t\tData: []*crstypes.CertificateSummary{\n+\t\t\t\t\t\t\tcreateTestCertificateSummary(testCertID),\n+\t\t\t\t\t\t},\n+\t\t\t\t\t}, nil,\n+\t\t\t\t)\n+\n+\t\t\t\t// Mark as agent secondary certificate\n+\t\t\t\tmockCRS.On(\n+\t\t\t\t\t\"V1MarkAgentSecondaryCertificateRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(\n+\t\t\t\t\t\tfunc(req *crstypes.V1MarkAgentSecondaryCertificateRequest) bool {\n+\t\t\t\t\t\t\treturn req.CertId == testCertID &&\n+\t\t\t\t\t\t\t\treq.AccountName == testAccountName &&\n+\t\t\t\t\t\t\t\treq.ClusterUuid == testPrimaryClusterUUID1\n+\t\t\t\t\t\t},\n+\t\t\t\t\t),\n+\t\t\t\t).Return(&crstypes.AgentSecondaryCertificateInfo{}, nil)\n+\t\t\t},\n+\t\t\texpectError: false,\n+\t\t},\n+\t\t{\n+\t\t\tname:                 \"certificate does not exist - import new\",\n+\t\t\tprimaryClusterUuid:   testPrimaryClusterUUID1,\n+\t\t\tsecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\t\taccountName:          testAccountName,\n+\t\t\tsecondaryClusterCert: createTestClusterCertificate(),\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient) {\n+\t\t\t\t// Certificate query returns no existing certificates\n+\t\t\t\tmockCRS.On(\n+\t\t\t\t\t\"V1QueryCertificatesRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(\n+\t\t\t\t\t\tfunc(req *crstypes.V1QueryCertificatesRequest) bool {\n+\t\t\t\t\t\t\treturn req.AccountName == testAccountName &&\n+\t\t\t\t\t\t\t\treq.ClusterUuid == testPrimaryClusterUUID1\n+\t\t\t\t\t\t},\n+\t\t\t\t\t),\n+\t\t\t\t).Return(\n+\t\t\t\t\t&crstypes.CertificateSummaryListResponse{\n+\t\t\t\t\t\tData: []*crstypes.CertificateSummary{}, // Empty - no existing certs\n+\t\t\t\t\t}, nil,\n+\t\t\t\t)\n+\n+\t\t\t\t// Import certificate\n+\t\t\t\tmockCRS.On(\n+\t\t\t\t\t\"V1ImportCertificateRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(\n+\t\t\t\t\t\tfunc(req *crstypes.V1ImportCertificateRequest) bool {\n+\t\t\t\t\t\t\treturn req.AccountName == testAccountName &&\n+\t\t\t\t\t\t\t\treq.ClusterUuid == testPrimaryClusterUUID1 &&\n+\t\t\t\t\t\t\t\treq.CertImportRequest.PemFile == testCertificate &&\n+\t\t\t\t\t\t\t\treq.CertImportRequest.IsInternal.Value == true &&\n+\t\t\t\t\t\t\t\treq.CertImportRequest.Name == \"Cluster \"+testSecondaryClusterUUID+\" Certificate\"\n+\t\t\t\t\t\t},\n+\t\t\t\t\t),\n+\t\t\t\t).Return(createTestCertificateSummary(testCertID), nil)\n+\n+\t\t\t\t// Mark as agent secondary certificate\n+\t\t\t\tmockCRS.On(\n+\t\t\t\t\t\"V1MarkAgentSecondaryCertificateRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(\n+\t\t\t\t\t\tfunc(req *crstypes.V1MarkAgentSecondaryCertificateRequest) bool {\n+\t\t\t\t\t\t\treturn req.CertId == testCertID\n+\t\t\t\t\t\t},\n+\t\t\t\t\t),\n+\t\t\t\t).Return(&crstypes.AgentSecondaryCertificateInfo{}, nil)\n+\t\t\t},\n+\t\t\texpectError: false,\n+\t\t},\n+\t\t{\n+\t\t\tname:                 \"query certificates fails\",\n+\t\t\tprimaryClusterUuid:   testPrimaryClusterUUID1,\n+\t\t\tsecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\t\taccountName:          testAccountName,\n+\t\t\tsecondaryClusterCert: createTestClusterCertificate(),\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient) {\n+\t\t\t\tmockCRS.On(\n+\t\t\t\t\t\"V1QueryCertificatesRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1QueryCertificatesRequest\"),\n+\t\t\t\t).Return(\n+\t\t\t\t\t(*crstypes.CertificateSummaryListResponse)(nil),\n+\t\t\t\t\terrors.New(\"query failed\"),\n+\t\t\t\t)\n+\t\t\t},\n+\t\t\texpectError:      true,\n+\t\t\texpectedErrorMsg: \"failed to query certificates on primary cluster\",\n+\t\t},\n+\t\t{\n+\t\t\tname:                 \"import certificate fails\",\n+\t\t\tprimaryClusterUuid:   testPrimaryClusterUUID1,\n+\t\t\tsecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\t\taccountName:          testAccountName,\n+\t\t\tsecondaryClusterCert: createTestClusterCertificate(),\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient) {\n+\t\t\t\t// Query returns no certificates\n+\t\t\t\tmockCRS.On(\n+\t\t\t\t\t\"V1QueryCertificatesRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1QueryCertificatesRequest\"),\n+\t\t\t\t).Return(\n+\t\t\t\t\t&crstypes.CertificateSummaryListResponse{Data: []*crstypes.CertificateSummary{}},\n+\t\t\t\t\tnil,\n+\t\t\t\t)\n+\n+\t\t\t\t// Import fails\n+\t\t\t\tmockCRS.On(\n+\t\t\t\t\t\"V1ImportCertificateRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1ImportCertificateRequest\"),\n+\t\t\t\t).Return(\n+\t\t\t\t\t(*crstypes.CertificateSummary)(nil),\n+\t\t\t\t\terrors.New(\"import failed\"),\n+\t\t\t\t)\n+\t\t\t},\n+\t\t\texpectError:      true,\n+\t\t\texpectedErrorMsg: \"failed to import certificate to primary cluster\",\n+\t\t},\n+\t\t{\n+\t\t\tname:                 \"mark agent secondary certificate fails\",\n+\t\t\tprimaryClusterUuid:   testPrimaryClusterUUID1,\n+\t\t\tsecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\t\taccountName:          testAccountName,\n+\t\t\tsecondaryClusterCert: createTestClusterCertificate(),\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient) {\n+\t\t\t\t// Query returns existing certificate\n+\t\t\t\tmockCRS.On(\n+\t\t\t\t\t\"V1QueryCertificatesRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1QueryCertificatesRequest\"),\n+\t\t\t\t).Return(\n+\t\t\t\t\t&crstypes.CertificateSummaryListResponse{\n+\t\t\t\t\t\tData: []*crstypes.CertificateSummary{createTestCertificateSummary(testCertID)},\n+\t\t\t\t\t},\n+\t\t\t\t\tnil,\n+\t\t\t\t)\n+\n+\t\t\t\t// Mark as agent secondary fails\n+\t\t\t\tmockCRS.On(\n+\t\t\t\t\t\"V1MarkAgentSecondaryCertificateRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1MarkAgentSecondaryCertificateRequest\"),\n+\t\t\t\t).Return(\n+\t\t\t\t\t(*crstypes.AgentSecondaryCertificateInfo)(nil),\n+\t\t\t\t\terrors.New(\"mark failed\"),\n+\t\t\t\t)\n+\t\t\t},\n+\t\t\texpectError:      true,\n+\t\t\texpectedErrorMsg: \"failed to mark certificate as agent secondary certificate\",\n+\t\t},\n+\t}\n+\n+\tfor _, tt := range tests {\n+\t\tt.Run(\n+\t\t\ttt.name, func(t *testing.T) {\n+\t\t\t\tmockCRS := &crs.MockCDMRestServiceClient{}\n+\t\t\t\ttt.setupMocks(mockCRS)\n+\n+\t\t\t\terr := transferCertificateToPrimary(\n+\t\t\t\t\tctx,\n+\t\t\t\t\ttt.primaryClusterUuid,\n+\t\t\t\t\ttt.secondaryClusterUuid,\n+\t\t\t\t\tmockCRS,\n+\t\t\t\t\ttt.accountName,\n+\t\t\t\t\ttt.secondaryClusterCert,\n+\t\t\t\t)\n+\n+\t\t\t\tif tt.expectError {\n+\t\t\t\t\trequire.Error(t, err)\n+\t\t\t\t\tassert.Contains(t, err.Error(), tt.expectedErrorMsg)\n+\t\t\t\t} else {\n+\t\t\t\t\tassert.NoError(t, err)\n+\t\t\t\t}\n+\n+\t\t\t\tmockCRS.AssertExpectations(t)\n+\t\t\t},\n+\t\t)\n+\t}\n+}\n+\n+// TestFetchAndVerifyManagedObjects tests the managed object fetching and verification\n+func TestFetchAndVerifyManagedObjects(t *testing.T) {\n+\tctx := context.Background()\n+\n+\ttests := []struct {\n+\t\tname               string\n+\t\thosts              []*proto.SecondaryRegisterHostInput\n+\t\tsetupMocks         func(*authz.MockAuthzClient)\n+\t\texpectError        bool\n+\t\texpectedErrorMsg   string\n+\t\texpectedHostFidMap map[string]*aspb.CdmPhysicalHost\n+\t}{\n+\t\t{\n+\t\t\tname: \"successful fetch and verification\",\n+\t\t\thosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t{\n+\t\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t\t},\n+\t\t\t\t{\n+\t\t\t\t\tHostFid:            testHostFID2,\n+\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_WINDOWS,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\tsetupMocks: func(mockAuthz *authz.MockAuthzClient) {\n+\t\t\t\tmockAuthz.On(\n+\t\t\t\t\t\"GetManagedObjects\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(\n+\t\t\t\t\t\tfunc(req *authz.GetManagedObjectsRequest) bool {\n+\t\t\t\t\t\t\treturn req.Account == testAccountName &&\n+\t\t\t\t\t\t\t\tlen(req.Ids) == 2 &&\n+\t\t\t\t\t\t\t\tcontains(req.Ids, testHostFID1) &&\n+\t\t\t\t\t\t\t\tcontains(req.Ids, testHostFID2)\n+\t\t\t\t\t\t},\n+\t\t\t\t\t),\n+\t\t\t\t).Return(\n+\t\t\t\t\t&authz.GetManagedObjectsResponse{\n+\t\t\t\t\t\tObjects: []*aspb.ManagedObject{\n+\t\t\t\t\t\t\tcreateTestManagedObject(testHostFID1, testHostname1, LinuxOsType),\n+\t\t\t\t\t\t\tcreateTestManagedObject(\n+\t\t\t\t\t\t\t\ttestHostFID2,\n+\t\t\t\t\t\t\t\ttestHostname2,\n+\t\t\t\t\t\t\t\tWindowsOsType,\n+\t\t\t\t\t\t\t),\n+\t\t\t\t\t\t},\n+\t\t\t\t\t}, nil,\n+\t\t\t\t)\n+\t\t\t},\n+\t\t\texpectError: false,\n+\t\t\texpectedHostFidMap: map[string]*aspb.CdmPhysicalHost{\n+\t\t\t\ttestHostFID1: {\n+\t\t\t\t\tName:                testHostname1,\n+\t\t\t\t\tOperatingSystemType: LinuxOsType,\n+\t\t\t\t},\n+\t\t\t\ttestHostFID2: {\n+\t\t\t\t\tName:                testHostname2,\n+\t\t\t\t\tOperatingSystemType: WindowsOsType,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t},\n+\t\t{\n+\t\t\tname: \"authz client error\",\n+\t\t\thosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t{\n+\t\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\tsetupMocks: func(mockAuthz *authz.MockAuthzClient) {\n+\t\t\t\tmockAuthz.On(\n+\t\t\t\t\t\"GetManagedObjects\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*proto.GetManagedObjectsRequest\"),\n+\t\t\t\t).Return(\n+\t\t\t\t\t(*authz.GetManagedObjectsResponse)(nil),\n+\t\t\t\t\terrors.New(\"authz service unavailable\"),\n+\t\t\t\t)\n+\t\t\t},\n+\t\t\texpectError:      true,\n+\t\t\texpectedErrorMsg: \"failed to fetch managed objects\",\n+\t\t},\n+\t\t{\n+\t\t\tname: \"missing managed objects\",\n+\t\t\thosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t{\n+\t\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t\t},\n+\t\t\t\t{\n+\t\t\t\t\tHostFid:            testHostFID2,\n+\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_WINDOWS,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\tsetupMocks: func(mockAuthz *authz.MockAuthzClient) {\n+\t\t\t\tmockAuthz.On(\n+\t\t\t\t\t\"GetManagedObjects\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*proto.GetManagedObjectsRequest\"),\n+\t\t\t\t).Return(\n+\t\t\t\t\t&authz.GetManagedObjectsResponse{\n+\t\t\t\t\t\tObjects: []*aspb.ManagedObject{\n+\t\t\t\t\t\t\tcreateTestManagedObject(testHostFID1, testHostname1, LinuxOsType),\n+\t\t\t\t\t\t\t// Missing testHostFID2\n+\t\t\t\t\t\t},\n+\t\t\t\t\t}, nil,\n+\t\t\t\t)\n+\t\t\t},\n+\t\t\texpectError:      true,\n+\t\t\texpectedErrorMsg: \"expected 2 managed objects, got 1\",\n+\t\t},\n+\t\t{\n+\t\t\tname: \"wrong object type\",\n+\t\t\thosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t{\n+\t\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\tsetupMocks: func(mockAuthz *authz.MockAuthzClient) {\n+\t\t\t\tmockAuthz.On(\n+\t\t\t\t\t\"GetManagedObjects\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*proto.GetManagedObjectsRequest\"),\n+\t\t\t\t).Return(\n+\t\t\t\t\t&authz.GetManagedObjectsResponse{\n+\t\t\t\t\t\tObjects: []*aspb.ManagedObject{\n+\t\t\t\t\t\t\tcreateTestManagedObjectWithType(\n+\t\t\t\t\t\t\t\ttestHostFID1,\n+\t\t\t\t\t\t\t\tacpb.ManagedObjectType_VSPHERE_VIRTUAL_MACHINE,\n+\t\t\t\t\t\t\t),\n+\t\t\t\t\t\t},\n+\t\t\t\t\t}, nil,\n+\t\t\t\t)\n+\t\t\t},\n+\t\t\texpectError:      true,\n+\t\t\texpectedErrorMsg: \"host[0]: object host-fid-1 is not a physical host\",\n+\t\t},\n+\t\t{\n+\t\t\tname: \"nil CDM physical host\",\n+\t\t\thosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t{\n+\t\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\tsetupMocks: func(mockAuthz *authz.MockAuthzClient) {\n+\t\t\t\tmockAuthz.On(\n+\t\t\t\t\t\"GetManagedObjects\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*proto.GetManagedObjectsRequest\"),\n+\t\t\t\t).Return(\n+\t\t\t\t\t&authz.GetManagedObjectsResponse{\n+\t\t\t\t\t\tObjects: []*aspb.ManagedObject{\n+\t\t\t\t\t\t\t{\n+\t\t\t\t\t\t\t\tId:                testHostFID1,\n+\t\t\t\t\t\t\t\tManagedObjectType: acpb.ManagedObjectType_PHYSICAL_HOST,\n+\t\t\t\t\t\t\t\tSpecificObject:    nil, // Nil specific object\n+\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t},\n+\t\t\t\t\t}, nil,\n+\t\t\t\t)\n+\t\t\t},\n+\t\t\texpectError:      true,\n+\t\t\texpectedErrorMsg: \"host[0]: host host-fid-1 is not a CDM physical host\",\n+\t\t},\n+\t\t{\n+\t\t\tname: \"OS type mismatch\",\n+\t\t\thosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t{\n+\t\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\tsetupMocks: func(mockAuthz *authz.MockAuthzClient) {\n+\t\t\t\tmockAuthz.On(\n+\t\t\t\t\t\"GetManagedObjects\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*proto.GetManagedObjectsRequest\"),\n+\t\t\t\t).Return(\n+\t\t\t\t\t&authz.GetManagedObjectsResponse{\n+\t\t\t\t\t\tObjects: []*aspb.ManagedObject{\n+\t\t\t\t\t\t\tcreateTestManagedObject(\n+\t\t\t\t\t\t\t\ttestHostFID1,\n+\t\t\t\t\t\t\t\ttestHostname1,\n+\t\t\t\t\t\t\t\tWindowsOsType,\n+\t\t\t\t\t\t\t), // Wrong OS\n+\t\t\t\t\t\t},\n+\t\t\t\t\t}, nil,\n+\t\t\t\t)\n+\t\t\t},\n+\t\t\texpectError:      true,\n+\t\t\texpectedErrorMsg: \"OS type mismatch for host host-fid-1 - expected Linux, got Windows\",\n+\t\t},\n+\t}\n+\n+\tfor _, tt := range tests {\n+\t\tt.Run(\n+\t\t\ttt.name, func(t *testing.T) {\n+\t\t\t\tmockAuthz := &authz.MockAuthzClient{}\n+\t\t\t\ttt.setupMocks(mockAuthz)\n+\n+\t\t\t\tresult, err := fetchAndVerifyManagedObjects(\n+\t\t\t\t\tctx,\n+\t\t\t\t\ttt.hosts,\n+\t\t\t\t\tmockAuthz,\n+\t\t\t\t\ttestAccountName,\n+\t\t\t\t)\n+\n+\t\t\t\tif tt.expectError {\n+\t\t\t\t\trequire.Error(t, err)\n+\t\t\t\t\tassert.Contains(t, err.Error(), tt.expectedErrorMsg)\n+\t\t\t\t\tassert.Nil(t, result)\n+\t\t\t\t} else {\n+\t\t\t\t\trequire.NoError(t, err)\n+\t\t\t\t\trequire.NotNil(t, result)\n+\t\t\t\t\tassert.Equal(t, len(tt.expectedHostFidMap), len(result))\n+\n+\t\t\t\t\tfor hostFid, expectedHost := range tt.expectedHostFidMap {\n+\t\t\t\t\t\tactualHost, exists := result[hostFid]\n+\t\t\t\t\t\trequire.True(\n+\t\t\t\t\t\t\tt,\n+\t\t\t\t\t\t\texists,\n+\t\t\t\t\t\t\t\"Expected host FID %s not found in result\",\n+\t\t\t\t\t\t\thostFid,\n+\t\t\t\t\t\t)\n+\t\t\t\t\t\tassert.Equal(t, expectedHost.Name, actualHost.Name)\n+\t\t\t\t\t\tassert.Equal(\n+\t\t\t\t\t\t\tt,\n+\t\t\t\t\t\t\texpectedHost.OperatingSystemType,\n+\t\t\t\t\t\t\tactualHost.OperatingSystemType,\n+\t\t\t\t\t\t)\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\tmockAuthz.AssertExpectations(t)\n+\t\t\t},\n+\t\t)\n+\t}\n+}\n+\n+// Helper function to check if a slice contains a string\n+func contains(slice []string, item string) bool {\n+\tfor _, s := range slice {\n+\t\tif s == item {\n+\t\t\treturn true\n+\t\t}\n+\t}\n+\treturn false\n+}\n+\n+// TestProcessHostsForRegistration tests the main orchestrator function\n+func TestProcessHostsForRegistration(t *testing.T) {\n+\tctx := context.Background()\n+\n+\ttests := []struct {\n+\t\tname                   string\n+\t\trequest                *proto.BulkRegisterSecondaryHostsReq\n+\t\tsecondaryClusterCert   *crstypes.ClusterCertificate\n+\t\tsetupMocks             func(*crs.MockCDMRestServiceClient)\n+\t\texpectedResults        map[string]error\n+\t\texpectedCertTransfers  int // Number of certificate transfer calls expected\n+\t\texpectedDiagnosisCalls int // Number of diagnosis calls expected\n+\t}{\n+\t\t{\n+\t\t\tname: \"single cluster - all hosts successful\",\n+\t\t\trequest: &proto.BulkRegisterSecondaryHostsReq{\n+\t\t\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\t\t\tAccount: testAccountName,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t\tSecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\t\t\tHosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t\t\t},\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            testHostFID2,\n+\t\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_WINDOWS,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\tsecondaryClusterCert: createTestClusterCertificate(),\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient) {\n+\t\t\t\t// Certificate transfer - query returns no existing certificates\n+\t\t\t\tmockCRS.On(\"V1QueryCertificatesRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1QueryCertificatesRequest\")).Return(\n+\t\t\t\t\t&crstypes.CertificateSummaryListResponse{Data: []*crstypes.CertificateSummary{}},\n+\t\t\t\t\tnil,\n+\t\t\t\t)\n+\n+\t\t\t\t// Certificate import\n+\t\t\t\tmockCRS.On(\"V1ImportCertificateRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1ImportCertificateRequest\")).Return(\n+\t\t\t\t\tcreateTestCertificateSummary(testCertID), nil,\n+\t\t\t\t)\n+\n+\t\t\t\t// Mark as agent secondary certificate\n+\t\t\t\tmockCRS.On(\"V1MarkAgentSecondaryCertificateRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1MarkAgentSecondaryCertificateRequest\")).Return(\n+\t\t\t\t\t&crstypes.AgentSecondaryCertificateInfo{}, nil,\n+\t\t\t\t)\n+\n+\t\t\t\t// Host diagnosis - both hosts succeed\n+\t\t\t\tmockCRS.On(\"InternalGetHostDiagnosisRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(func(req *crstypes.InternalGetHostDiagnosisRequest) bool {\n+\t\t\t\t\t\treturn req.Id == testHostFID1 || req.Id == testHostFID2\n+\t\t\t\t\t})).Return(&crstypes.HostDiagnosisSummary{}, nil)\n+\t\t\t},\n+\t\t\texpectedResults: map[string]error{\n+\t\t\t\ttestHostFID1: nil,\n+\t\t\t\ttestHostFID2: nil,\n+\t\t\t},\n+\t\t\texpectedCertTransfers:  1, // One transfer per cluster\n+\t\t\texpectedDiagnosisCalls: 2, // One call per host\n+\t\t},\n+\t\t{\n+\t\t\tname: \"multiple clusters - mixed results\",\n+\t\t\trequest: &proto.BulkRegisterSecondaryHostsReq{\n+\t\t\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\t\t\tAccount: testAccountName,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t\tSecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\t\t\tHosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t\t\t},\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            testHostFID2,\n+\t\t\t\t\t\tPrimaryClusterUuid: \"primary-cluster-uuid-2\",\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_WINDOWS,\n+\t\t\t\t\t},\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            testHostFID3,\n+\t\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\tsecondaryClusterCert: createTestClusterCertificate(),\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient) {\n+\t\t\t\t// Certificate transfers - both clusters succeed\n+\t\t\t\tmockCRS.On(\"V1QueryCertificatesRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1QueryCertificatesRequest\")).Return(\n+\t\t\t\t\t&crstypes.CertificateSummaryListResponse{Data: []*crstypes.CertificateSummary{}},\n+\t\t\t\t\tnil,\n+\t\t\t\t)\n+\n+\t\t\t\tmockCRS.On(\"V1ImportCertificateRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1ImportCertificateRequest\")).Return(\n+\t\t\t\t\tcreateTestCertificateSummary(testCertID), nil,\n+\t\t\t\t)\n+\n+\t\t\t\tmockCRS.On(\"V1MarkAgentSecondaryCertificateRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1MarkAgentSecondaryCertificateRequest\")).Return(\n+\t\t\t\t\t&crstypes.AgentSecondaryCertificateInfo{}, nil,\n+\t\t\t\t)\n+\n+\t\t\t\t// Host diagnosis - mixed results\n+\t\t\t\t// Host 1 succeeds\n+\t\t\t\tmockCRS.On(\"InternalGetHostDiagnosisRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(func(req *crstypes.InternalGetHostDiagnosisRequest) bool {\n+\t\t\t\t\t\treturn req.Id == testHostFID1\n+\t\t\t\t\t})).Return(&crstypes.HostDiagnosisSummary{}, nil)\n+\n+\t\t\t\t// Host 2 fails\n+\t\t\t\tmockCRS.On(\"InternalGetHostDiagnosisRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(func(req *crstypes.InternalGetHostDiagnosisRequest) bool {\n+\t\t\t\t\t\treturn req.Id == testHostFID2\n+\t\t\t\t\t})).Return((*crstypes.HostDiagnosisSummary)(nil), errors.New(\"host unreachable\"))\n+\n+\t\t\t\t// Host 3 succeeds\n+\t\t\t\tmockCRS.On(\"InternalGetHostDiagnosisRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(func(req *crstypes.InternalGetHostDiagnosisRequest) bool {\n+\t\t\t\t\t\treturn req.Id == testHostFID3\n+\t\t\t\t\t})).Return(&crstypes.HostDiagnosisSummary{}, nil)\n+\t\t\t},\n+\t\t\texpectedResults: map[string]error{\n+\t\t\t\ttestHostFID1: nil,\n+\t\t\t\ttestHostFID2: errors.New(\"host unreachable\"),\n+\t\t\t\ttestHostFID3: nil,\n+\t\t\t},\n+\t\t\texpectedCertTransfers:  2, // Two transfers (one per cluster)\n+\t\t\texpectedDiagnosisCalls: 3, // One call per host\n+\t\t},\n+\t\t{\n+\t\t\tname: \"certificate transfer failure affects all hosts in cluster\",\n+\t\t\trequest: &proto.BulkRegisterSecondaryHostsReq{\n+\t\t\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\t\t\tAccount: testAccountName,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t\tSecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\t\t\tHosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t\t\t},\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            testHostFID2,\n+\t\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_WINDOWS,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\tsecondaryClusterCert: createTestClusterCertificate(),\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient) {\n+\t\t\t\t// Certificate transfer fails\n+\t\t\t\tmockCRS.On(\"V1QueryCertificatesRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1QueryCertificatesRequest\")).Return(\n+\t\t\t\t\t(*crstypes.CertificateSummaryListResponse)(nil),\n+\t\t\t\t\terrors.New(\"certificate query failed\"),\n+\t\t\t\t)\n+\t\t\t\t// No diagnosis calls should be made since certificate transfer fails\n+\t\t\t},\n+\t\t\texpectedResults: map[string]error{\n+\t\t\t\ttestHostFID1: errors.New(\"failed to query certificates on primary cluster\"),\n+\t\t\t\ttestHostFID2: errors.New(\"failed to query certificates on primary cluster\"),\n+\t\t\t},\n+\t\t\texpectedCertTransfers:  1, // One failed transfer\n+\t\t\texpectedDiagnosisCalls: 0, // No diagnosis calls due to cert failure\n+\t\t},\n+\t}\n+\n+\tfor _, tt := range tests {\n+\t\tt.Run(tt.name, func(t *testing.T) {\n+\t\t\tmockCRS := &crs.MockCDMRestServiceClient{}\n+\t\t\ttt.setupMocks(mockCRS)\n+\n+\t\t\tresults := processHostsForRegistration(\n+\t\t\t\tctx,\n+\t\t\t\ttt.request,\n+\t\t\t\tmockCRS,\n+\t\t\t\ttt.secondaryClusterCert,\n+\t\t\t)\n+\n+\t\t\t// Verify results\n+\t\t\trequire.Equal(t, len(tt.expectedResults), len(results))\n+\t\t\tfor hostFid, expectedErr := range tt.expectedResults {\n+\t\t\t\tactualErr, exists := results[hostFid]\n+\t\t\t\trequire.True(t, exists, \"Expected result for host %s not found\", hostFid)\n+\n+\t\t\t\tif expectedErr == nil {\n+\t\t\t\t\tassert.NoError(t, actualErr)\n+\t\t\t\t} else {\n+\t\t\t\t\trequire.Error(t, actualErr)\n+\t\t\t\t\tassert.Contains(t, actualErr.Error(), expectedErr.Error())\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tmockCRS.AssertExpectations(t)\n+\t\t})\n+\t}\n+}\n+\n+// TestProcessHostsForRegistrationConcurrency tests concurrent processing behavior\n+func TestProcessHostsForRegistrationConcurrency(t *testing.T) {\n+\tctx := context.Background()\n+\n+\t// Test with hosts in different clusters to verify concurrent processing\n+\trequest := &proto.BulkRegisterSecondaryHostsReq{\n+\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\tAccount: testAccountName,\n+\t\t\t},\n+\t\t},\n+\t\tSecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\tHosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t{\n+\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\tPrimaryClusterUuid: \"cluster-1\",\n+\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t},\n+\t\t\t{\n+\t\t\t\tHostFid:            testHostFID2,\n+\t\t\t\tPrimaryClusterUuid: \"cluster-2\",\n+\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_WINDOWS,\n+\t\t\t},\n+\t\t\t{\n+\t\t\t\tHostFid:            testHostFID3,\n+\t\t\t\tPrimaryClusterUuid: \"cluster-3\",\n+\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t},\n+\t\t},\n+\t}\n+\n+\tmockCRS := &crs.MockCDMRestServiceClient{}\n+\n+\t// Set up mocks for all clusters\n+\tmockCRS.On(\"V1QueryCertificatesRPC\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*types.V1QueryCertificatesRequest\")).Return(\n+\t\t&crstypes.CertificateSummaryListResponse{Data: []*crstypes.CertificateSummary{}},\n+\t\tnil,\n+\t)\n+\n+\tmockCRS.On(\"V1ImportCertificateRPC\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*types.V1ImportCertificateRequest\")).Return(\n+\t\tcreateTestCertificateSummary(testCertID), nil,\n+\t)\n+\n+\tmockCRS.On(\"V1MarkAgentSecondaryCertificateRPC\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*types.V1MarkAgentSecondaryCertificateRequest\")).Return(\n+\t\t&crstypes.AgentSecondaryCertificateInfo{}, nil,\n+\t)\n+\n+\t// All hosts succeed\n+\tmockCRS.On(\"InternalGetHostDiagnosisRPC\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*types.InternalGetHostDiagnosisRequest\")).Return(\n+\t\t&crstypes.HostDiagnosisSummary{}, nil,\n+\t)\n+\n+\tresults := processHostsForRegistration(\n+\t\tctx,\n+\t\trequest,\n+\t\tmockCRS,\n+\t\tcreateTestClusterCertificate(),\n+\t)\n+\n+\t// Verify all hosts processed successfully\n+\trequire.Equal(t, 3, len(results))\n+\tassert.NoError(t, results[testHostFID1])\n+\tassert.NoError(t, results[testHostFID2])\n+\tassert.NoError(t, results[testHostFID3])\n+\n+\tmockCRS.AssertExpectations(t)\n+}\n+\n+// TestProcessHostsForRegistrationWithContextCancellation tests context cancellation\n+func TestProcessHostsForRegistrationWithContextCancellation(t *testing.T) {\n+\tctx, cancel := context.WithCancel(context.Background())\n+\n+\trequest := &proto.BulkRegisterSecondaryHostsReq{\n+\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\tAccount: testAccountName,\n+\t\t\t},\n+\t\t},\n+\t\tSecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\tHosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t{\n+\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t},\n+\t\t},\n+\t}\n+\n+\tmockCRS := &crs.MockCDMRestServiceClient{}\n+\n+\t// Set up mocks that may or may not be called due to cancellation\n+\tmockCRS.On(\"V1QueryCertificatesRPC\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*types.V1QueryCertificatesRequest\")).Return(\n+\t\t&crstypes.CertificateSummaryListResponse{Data: []*crstypes.CertificateSummary{}},\n+\t\tnil,\n+\t).Maybe()\n+\n+\tmockCRS.On(\"V1ImportCertificateRPC\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*types.V1ImportCertificateRequest\")).Return(\n+\t\tcreateTestCertificateSummary(testCertID), nil,\n+\t).Maybe()\n+\n+\tmockCRS.On(\"V1MarkAgentSecondaryCertificateRPC\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*types.V1MarkAgentSecondaryCertificateRequest\")).Return(\n+\t\t&crstypes.AgentSecondaryCertificateInfo{}, nil,\n+\t).Maybe()\n+\n+\tmockCRS.On(\"InternalGetHostDiagnosisRPC\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*types.InternalGetHostDiagnosisRequest\")).Return(\n+\t\t&crstypes.HostDiagnosisSummary{}, nil,\n+\t).Maybe()\n+\n+\t// Cancel context immediately\n+\tcancel()\n+\n+\tresults := processHostsForRegistration(\n+\t\tctx,\n+\t\trequest,\n+\t\tmockCRS,\n+\t\tcreateTestClusterCertificate(),\n+\t)\n+\n+\t// Function should still return results (though they may be incomplete)\n+\tassert.NotNil(t, results)\n+\t// We can't assert exact results since cancellation timing is unpredictable\n+}\n+\n+// TestProcessBulkRegistration tests the main entry point function\n+func TestProcessBulkRegistration(t *testing.T) {\n+\tctx := context.Background()\n+\n+\t// Create test host FID to CDM host mapping\n+\thostFidToCdmHost := map[string]*aspb.CdmPhysicalHost{\n+\t\ttestHostFID1: {\n+\t\t\tName:                testHostname1,\n+\t\t\tOperatingSystemType: LinuxOsType,\n+\t\t},\n+\t\ttestHostFID2: {\n+\t\t\tName:                testHostname2,\n+\t\t\tOperatingSystemType: WindowsOsType,\n+\t\t},\n+\t\ttestHostFID3: {\n+\t\t\tName:                testHostname3,\n+\t\t\tOperatingSystemType: LinuxOsType,\n+\t\t},\n+\t}\n+\n+\ttests := []struct {\n+\t\tname                    string\n+\t\trequest                 *proto.BulkRegisterSecondaryHostsReq\n+\t\thostFidToCdmHost        map[string]*aspb.CdmPhysicalHost\n+\t\tsetupMocks              func(*crs.MockCDMRestServiceClient, *authz.MockAuthzClient)\n+\t\texpectError             bool\n+\t\texpectedErrorMsg        string\n+\t\texpectedSuccessfulHosts []string\n+\t\texpectedFailedHosts     []string\n+\t}{\n+\t\t{\n+\t\t\tname: \"complete success - all hosts registered\",\n+\t\t\trequest: &proto.BulkRegisterSecondaryHostsReq{\n+\t\t\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\t\t\tAccount: testAccountName,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t\tSecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\t\t\tHosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t\t\t},\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            testHostFID2,\n+\t\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_WINDOWS,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\thostFidToCdmHost: hostFidToCdmHost,\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient, mockAuthz *authz.MockAuthzClient) {\n+\t\t\t\t// Fetch secondary cluster certificate\n+\t\t\t\tmockCRS.On(\"V1GetClusterCertificateRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(func(req *crstypes.V1GetClusterCertificateRequest) bool {\n+\t\t\t\t\t\treturn req.Id == testSecondaryClusterUUID &&\n+\t\t\t\t\t\t\treq.AccountName == testAccountName\n+\t\t\t\t\t})).Return(createTestClusterCertificate(), nil)\n+\n+\t\t\t\t// Certificate transfer - query returns no existing certificates\n+\t\t\t\tmockCRS.On(\"V1QueryCertificatesRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1QueryCertificatesRequest\")).Return(\n+\t\t\t\t\t&crstypes.CertificateSummaryListResponse{Data: []*crstypes.CertificateSummary{}},\n+\t\t\t\t\tnil,\n+\t\t\t\t)\n+\n+\t\t\t\t// Certificate import\n+\t\t\t\tmockCRS.On(\"V1ImportCertificateRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1ImportCertificateRequest\")).Return(\n+\t\t\t\t\tcreateTestCertificateSummary(testCertID), nil,\n+\t\t\t\t)\n+\n+\t\t\t\t// Mark as agent secondary certificate\n+\t\t\t\tmockCRS.On(\"V1MarkAgentSecondaryCertificateRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1MarkAgentSecondaryCertificateRequest\")).Return(\n+\t\t\t\t\t&crstypes.AgentSecondaryCertificateInfo{}, nil,\n+\t\t\t\t)\n+\n+\t\t\t\t// Host diagnosis - both hosts succeed\n+\t\t\t\tmockCRS.On(\"InternalGetHostDiagnosisRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.InternalGetHostDiagnosisRequest\")).Return(\n+\t\t\t\t\t&crstypes.HostDiagnosisSummary{}, nil,\n+\t\t\t\t)\n+\n+\t\t\t\t// Bulk registration succeeds\n+\t\t\t\tmockCRS.On(\"V1BulkRegisterHostAsyncRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(func(req *crstypes.V1BulkRegisterHostAsyncRequest) bool {\n+\t\t\t\t\t\treturn req.AccountName == testAccountName &&\n+\t\t\t\t\t\t\treq.ClusterUuid == testSecondaryClusterUUID &&\n+\t\t\t\t\t\t\tlen(req.Hosts) == 2\n+\t\t\t\t\t})).Return(&crstypes.V1BulkRegisterHostAsyncResponse{\n+\t\t\t\t\tItems: []*crstypes.HostDetail{},\n+\t\t\t\t}, nil)\n+\t\t\t},\n+\t\t\texpectError:             false,\n+\t\t\texpectedSuccessfulHosts: []string{testHostFID1, testHostFID2},\n+\t\t\texpectedFailedHosts:     []string{},\n+\t\t},\n+\t\t{\n+\t\t\tname: \"secondary cluster certificate fetch fails\",\n+\t\t\trequest: &proto.BulkRegisterSecondaryHostsReq{\n+\t\t\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\t\t\tAccount: testAccountName,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t\tSecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\t\t\tHosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\thostFidToCdmHost: hostFidToCdmHost,\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient, mockAuthz *authz.MockAuthzClient) {\n+\t\t\t\t// Fetch secondary cluster certificate fails\n+\t\t\t\tmockCRS.On(\"V1GetClusterCertificateRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1GetClusterCertificateRequest\")).Return(\n+\t\t\t\t\t(*crstypes.ClusterCertificate)(nil),\n+\t\t\t\t\terrors.New(\"cluster not found\"),\n+\t\t\t\t)\n+\t\t\t},\n+\t\t\texpectError:      true,\n+\t\t\texpectedErrorMsg: \"cluster not found\",\n+\t\t},\n+\t\t{\n+\t\t\tname: \"certificate transfer fails for all hosts\",\n+\t\t\trequest: &proto.BulkRegisterSecondaryHostsReq{\n+\t\t\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\t\t\tAccount: testAccountName,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t\tSecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\t\t\tHosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t\t\t},\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            testHostFID2,\n+\t\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_WINDOWS,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\thostFidToCdmHost: hostFidToCdmHost,\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient, mockAuthz *authz.MockAuthzClient) {\n+\t\t\t\t// Fetch secondary cluster certificate succeeds\n+\t\t\t\tmockCRS.On(\"V1GetClusterCertificateRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1GetClusterCertificateRequest\")).Return(\n+\t\t\t\t\tcreateTestClusterCertificate(), nil,\n+\t\t\t\t)\n+\n+\t\t\t\t// Certificate transfer fails\n+\t\t\t\tmockCRS.On(\"V1QueryCertificatesRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1QueryCertificatesRequest\")).Return(\n+\t\t\t\t\t(*crstypes.CertificateSummaryListResponse)(nil),\n+\t\t\t\t\terrors.New(\"certificate query failed\"),\n+\t\t\t\t)\n+\t\t\t},\n+\t\t\texpectError:         false, // Function succeeds but returns failed results\n+\t\t\texpectedFailedHosts: []string{testHostFID1, testHostFID2},\n+\t\t},\n+\t\t{\n+\t\t\tname: \"partial success - some hosts fail certificate transfer\",\n+\t\t\trequest: &proto.BulkRegisterSecondaryHostsReq{\n+\t\t\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\t\t\tAccount: testAccountName,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t\tSecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\t\t\tHosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t\t\t},\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            testHostFID2,\n+\t\t\t\t\t\tPrimaryClusterUuid: \"primary-cluster-uuid-2\",\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_WINDOWS,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\thostFidToCdmHost: hostFidToCdmHost,\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient, mockAuthz *authz.MockAuthzClient) {\n+\t\t\t\t// Fetch secondary cluster certificate succeeds\n+\t\t\t\tmockCRS.On(\"V1GetClusterCertificateRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1GetClusterCertificateRequest\")).Return(\n+\t\t\t\t\tcreateTestClusterCertificate(), nil,\n+\t\t\t\t)\n+\n+\t\t\t\t// Certificate transfer for cluster 1 succeeds\n+\t\t\t\tmockCRS.On(\"V1QueryCertificatesRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(func(req *crstypes.V1QueryCertificatesRequest) bool {\n+\t\t\t\t\t\treturn req.ClusterUuid == testPrimaryClusterUUID1\n+\t\t\t\t\t})).Return(&crstypes.CertificateSummaryListResponse{Data: []*crstypes.CertificateSummary{}}, nil)\n+\n+\t\t\t\tmockCRS.On(\"V1ImportCertificateRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(func(req *crstypes.V1ImportCertificateRequest) bool {\n+\t\t\t\t\t\treturn req.ClusterUuid == testPrimaryClusterUUID1\n+\t\t\t\t\t})).Return(createTestCertificateSummary(testCertID), nil)\n+\n+\t\t\t\tmockCRS.On(\"V1MarkAgentSecondaryCertificateRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(func(req *crstypes.V1MarkAgentSecondaryCertificateRequest) bool {\n+\t\t\t\t\t\treturn req.ClusterUuid == testPrimaryClusterUUID1\n+\t\t\t\t\t})).Return(&crstypes.AgentSecondaryCertificateInfo{}, nil)\n+\n+\t\t\t\t// Certificate transfer for cluster 2 fails\n+\t\t\t\tmockCRS.On(\"V1QueryCertificatesRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(func(req *crstypes.V1QueryCertificatesRequest) bool {\n+\t\t\t\t\t\treturn req.ClusterUuid == \"primary-cluster-uuid-2\"\n+\t\t\t\t\t})).Return((*crstypes.CertificateSummaryListResponse)(nil), errors.New(\"cluster 2 cert failed\"))\n+\n+\t\t\t\t// Host diagnosis for successful host\n+\t\t\t\tmockCRS.On(\"InternalGetHostDiagnosisRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(func(req *crstypes.InternalGetHostDiagnosisRequest) bool {\n+\t\t\t\t\t\treturn req.Id == testHostFID1\n+\t\t\t\t\t})).Return(&crstypes.HostDiagnosisSummary{}, nil)\n+\n+\t\t\t\t// Bulk registration for successful host\n+\t\t\t\tmockCRS.On(\"V1BulkRegisterHostAsyncRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(func(req *crstypes.V1BulkRegisterHostAsyncRequest) bool {\n+\t\t\t\t\t\treturn len(req.Hosts) == 1 && req.Hosts[0].Hostname == testHostname1\n+\t\t\t\t\t})).Return(&crstypes.V1BulkRegisterHostAsyncResponse{\n+\t\t\t\t\tItems: []*crstypes.HostDetail{},\n+\t\t\t\t}, nil)\n+\t\t\t},\n+\t\t\texpectError:             false,\n+\t\t\texpectedSuccessfulHosts: []string{testHostFID1},\n+\t\t\texpectedFailedHosts:     []string{testHostFID2},\n+\t\t},\n+\t}\n+\n+\tfor _, tt := range tests {\n+\t\tt.Run(tt.name, func(t *testing.T) {\n+\t\t\tmockCRS := &crs.MockCDMRestServiceClient{}\n+\t\t\tmockAuthz := &authz.MockAuthzClient{}\n+\t\t\ttt.setupMocks(mockCRS, mockAuthz)\n+\n+\t\t\tresult, err := processBulkRegistration(\n+\t\t\t\tctx,\n+\t\t\t\ttt.request,\n+\t\t\t\ttt.hostFidToCdmHost,\n+\t\t\t\tmockCRS,\n+\t\t\t\tmockAuthz,\n+\t\t\t)\n+\n+\t\t\tif tt.expectError {\n+\t\t\t\trequire.Error(t, err)\n+\t\t\t\tassert.Contains(t, err.Error(), tt.expectedErrorMsg)\n+\t\t\t} else {\n+\t\t\t\trequire.NoError(t, err)\n+\t\t\t\trequire.NotNil(t, result)\n+\t\t\t\trequire.NotNil(t, result.HostResults)\n+\n+\t\t\t\t// Verify expected successful hosts\n+\t\t\t\tfor _, hostFid := range tt.expectedSuccessfulHosts {\n+\t\t\t\t\tfound := false\n+\t\t\t\t\tfor _, hostResult := range result.HostResults {\n+\t\t\t\t\t\tif hostResult.PrimaryHostFid == hostFid {\n+\t\t\t\t\t\t\tfound = true\n+\t\t\t\t\t\t\tassert.Empty(t, hostResult.ErrorMessage) // Success means no error\n+\t\t\t\t\t\t\tbreak\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t\tassert.True(t, found, \"Expected successful host %s not found in results\", hostFid)\n+\t\t\t\t}\n+\n+\t\t\t\t// Verify expected failed hosts\n+\t\t\t\tfor _, hostFid := range tt.expectedFailedHosts {\n+\t\t\t\t\tfound := false\n+\t\t\t\t\tfor _, hostResult := range result.HostResults {\n+\t\t\t\t\t\tif hostResult.PrimaryHostFid == hostFid {\n+\t\t\t\t\t\t\tfound = true\n+\t\t\t\t\t\t\tassert.NotEmpty(t, hostResult.ErrorMessage)\n+\t\t\t\t\t\t\tbreak\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t\tassert.True(t, found, \"Expected failed host %s not found in results\", hostFid)\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tmockCRS.AssertExpectations(t)\n+\t\t\tmockAuthz.AssertExpectations(t)\n+\t\t})\n+\t}\n+}\n+\n+// TestProcessBulkRegistrationBulkAPIFailure tests bulk registration API failure\n+func TestProcessBulkRegistrationBulkAPIFailure(t *testing.T) {\n+\tctx := context.Background()\n+\n+\thostFidToCdmHost := map[string]*aspb.CdmPhysicalHost{\n+\t\ttestHostFID1: {\n+\t\t\tName:                testHostname1,\n+\t\t\tOperatingSystemType: LinuxOsType,\n+\t\t},\n+\t\ttestHostFID2: {\n+\t\t\tName:                testHostname2,\n+\t\t\tOperatingSystemType: WindowsOsType,\n+\t\t},\n+\t}\n+\n+\trequest := &proto.BulkRegisterSecondaryHostsReq{\n+\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\tAccount: testAccountName,\n+\t\t\t},\n+\t\t},\n+\t\tSecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\tHosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t{\n+\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t},\n+\t\t\t{\n+\t\t\t\tHostFid:            testHostFID2,\n+\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_WINDOWS,\n+\t\t\t},\n+\t\t},\n+\t}\n+\n+\tmockCRS := &crs.MockCDMRestServiceClient{}\n+\tmockAuthz := &authz.MockAuthzClient{}\n+\n+\t// Fetch secondary cluster certificate succeeds\n+\tmockCRS.On(\"V1GetClusterCertificateRPC\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*types.V1GetClusterCertificateRequest\")).Return(\n+\t\tcreateTestClusterCertificate(), nil,\n+\t)\n+\n+\t// Certificate transfer succeeds\n+\tmockCRS.On(\"V1QueryCertificatesRPC\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*types.V1QueryCertificatesRequest\")).Return(\n+\t\t&crstypes.CertificateSummaryListResponse{Data: []*crstypes.CertificateSummary{}},\n+\t\tnil,\n+\t)\n+\n+\tmockCRS.On(\"V1ImportCertificateRPC\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*types.V1ImportCertificateRequest\")).Return(\n+\t\tcreateTestCertificateSummary(testCertID), nil,\n+\t)\n+\n+\tmockCRS.On(\"V1MarkAgentSecondaryCertificateRPC\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*types.V1MarkAgentSecondaryCertificateRequest\")).Return(\n+\t\t&crstypes.AgentSecondaryCertificateInfo{}, nil,\n+\t)\n+\n+\t// Host diagnosis succeeds for both hosts\n+\tmockCRS.On(\"InternalGetHostDiagnosisRPC\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*types.InternalGetHostDiagnosisRequest\")).Return(\n+\t\t&crstypes.HostDiagnosisSummary{}, nil,\n+\t)\n+\n+\t// Bulk registration fails\n+\tmockCRS.On(\"V1BulkRegisterHostAsyncRPC\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*types.V1BulkRegisterHostAsyncRequest\")).Return(\n+\t\t(*crstypes.V1BulkRegisterHostAsyncResponse)(nil),\n+\t\terrors.New(\"bulk registration service unavailable\"),\n+\t)\n+\n+\tresult, err := processBulkRegistration(\n+\t\tctx,\n+\t\trequest,\n+\t\thostFidToCdmHost,\n+\t\tmockCRS,\n+\t\tmockAuthz,\n+\t)\n+\n+\t// Function should return error\n+\trequire.Error(t, err)\n+\tassert.Contains(t, err.Error(), \"bulk registration service unavailable\")\n+\n+\t// But should still return results showing all hosts failed\n+\trequire.NotNil(t, result)\n+\trequire.NotNil(t, result.HostResults)\n+\trequire.Equal(t, 2, len(result.HostResults))\n+\n+\t// Both hosts should be marked as failed\n+\tfor _, hostResult := range result.HostResults {\n+\t\tassert.NotEmpty(t, hostResult.ErrorMessage)\n+\t\tassert.Contains(t, hostResult.ErrorMessage, \"bulk registration service unavailable\")\n+\t}\n+\n+\tmockCRS.AssertExpectations(t)\n+\tmockAuthz.AssertExpectations(t)\n+}\n+\n+// TestBulkRegisterSecondaryHosts tests the main gRPC service method\n+func TestBulkRegisterSecondaryHosts(t *testing.T) {\n+\tctx := context.Background()\n+\n+\ttests := []struct {\n+\t\tname                    string\n+\t\trequest                 *proto.BulkRegisterSecondaryHostsReq\n+\t\tsetupMocks              func(*crs.MockCDMRestServiceClient, *authz.MockAuthzClient)\n+\t\texpectError             bool\n+\t\texpectedGRPCCode        codes.Code\n+\t\texpectedErrorMsg        string\n+\t\texpectedSuccessfulHosts []string\n+\t\texpectedFailedHosts     []string\n+\t}{\n+\t\t{\n+\t\t\tname: \"complete success - end to end\",\n+\t\t\trequest: &proto.BulkRegisterSecondaryHostsReq{\n+\t\t\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\t\t\tAccount: testAccountName,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t\tSecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\t\t\tHosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t\t\t},\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            testHostFID2,\n+\t\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_WINDOWS,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient, mockAuthz *authz.MockAuthzClient) {\n+\t\t\t\t// Fetch and verify managed objects\n+\t\t\t\tmockAuthz.On(\"GetManagedObjects\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(func(req *authz.GetManagedObjectsRequest) bool {\n+\t\t\t\t\t\treturn req.Account == testAccountName &&\n+\t\t\t\t\t\t\tlen(req.Ids) == 2 &&\n+\t\t\t\t\t\t\tcontains(req.Ids, testHostFID1) &&\n+\t\t\t\t\t\t\tcontains(req.Ids, testHostFID2)\n+\t\t\t\t\t})).Return(&authz.GetManagedObjectsResponse{\n+\t\t\t\t\tObjects: []*aspb.ManagedObject{\n+\t\t\t\t\t\tcreateTestManagedObject(testHostFID1, testHostname1, LinuxOsType),\n+\t\t\t\t\t\tcreateTestManagedObject(testHostFID2, testHostname2, WindowsOsType),\n+\t\t\t\t\t},\n+\t\t\t\t}, nil)\n+\n+\t\t\t\t// Fetch secondary cluster certificate\n+\t\t\t\tmockCRS.On(\"V1GetClusterCertificateRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(func(req *crstypes.V1GetClusterCertificateRequest) bool {\n+\t\t\t\t\t\treturn req.Id == testSecondaryClusterUUID &&\n+\t\t\t\t\t\t\treq.AccountName == testAccountName\n+\t\t\t\t\t})).Return(createTestClusterCertificate(), nil)\n+\n+\t\t\t\t// Certificate transfer - query returns no existing certificates\n+\t\t\t\tmockCRS.On(\"V1QueryCertificatesRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1QueryCertificatesRequest\")).Return(\n+\t\t\t\t\t&crstypes.CertificateSummaryListResponse{Data: []*crstypes.CertificateSummary{}},\n+\t\t\t\t\tnil,\n+\t\t\t\t)\n+\n+\t\t\t\t// Certificate import\n+\t\t\t\tmockCRS.On(\"V1ImportCertificateRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1ImportCertificateRequest\")).Return(\n+\t\t\t\t\tcreateTestCertificateSummary(testCertID), nil,\n+\t\t\t\t)\n+\n+\t\t\t\t// Mark as agent secondary certificate\n+\t\t\t\tmockCRS.On(\"V1MarkAgentSecondaryCertificateRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.V1MarkAgentSecondaryCertificateRequest\")).Return(\n+\t\t\t\t\t&crstypes.AgentSecondaryCertificateInfo{}, nil,\n+\t\t\t\t)\n+\n+\t\t\t\t// Host diagnosis - both hosts succeed\n+\t\t\t\tmockCRS.On(\"InternalGetHostDiagnosisRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*types.InternalGetHostDiagnosisRequest\")).Return(\n+\t\t\t\t\t&crstypes.HostDiagnosisSummary{}, nil,\n+\t\t\t\t)\n+\n+\t\t\t\t// Bulk registration succeeds\n+\t\t\t\tmockCRS.On(\"V1BulkRegisterHostAsyncRPC\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.MatchedBy(func(req *crstypes.V1BulkRegisterHostAsyncRequest) bool {\n+\t\t\t\t\t\treturn req.AccountName == testAccountName &&\n+\t\t\t\t\t\t\treq.ClusterUuid == testSecondaryClusterUUID &&\n+\t\t\t\t\t\t\tlen(req.Hosts) == 2\n+\t\t\t\t\t})).Return(&crstypes.V1BulkRegisterHostAsyncResponse{\n+\t\t\t\t\tItems: []*crstypes.HostDetail{},\n+\t\t\t\t}, nil)\n+\t\t\t},\n+\t\t\texpectError:             false,\n+\t\t\texpectedSuccessfulHosts: []string{testHostFID1, testHostFID2},\n+\t\t\texpectedFailedHosts:     []string{},\n+\t\t},\n+\t\t{\n+\t\t\tname: \"input validation failure - missing secondary cluster UUID\",\n+\t\t\trequest: &proto.BulkRegisterSecondaryHostsReq{\n+\t\t\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\t\t\tAccount: testAccountName,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t\t// Missing SecondaryClusterUuid\n+\t\t\t\tHosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient, mockAuthz *authz.MockAuthzClient) {\n+\t\t\t\t// No mocks needed - validation fails before any service calls\n+\t\t\t},\n+\t\t\texpectError:      true,\n+\t\t\texpectedGRPCCode: codes.InvalidArgument,\n+\t\t\texpectedErrorMsg: \"secondary cluster UUID is required\",\n+\t\t},\n+\t\t{\n+\t\t\tname: \"input validation failure - empty hosts list\",\n+\t\t\trequest: &proto.BulkRegisterSecondaryHostsReq{\n+\t\t\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\t\t\tAccount: testAccountName,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t\tSecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\t\t\tHosts:                []*proto.SecondaryRegisterHostInput{}, // Empty hosts\n+\t\t\t},\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient, mockAuthz *authz.MockAuthzClient) {\n+\t\t\t\t// No mocks needed - validation fails before any service calls\n+\t\t\t},\n+\t\t\texpectError:      true,\n+\t\t\texpectedGRPCCode: codes.InvalidArgument,\n+\t\t\texpectedErrorMsg: \"at least one host is required\",\n+\t\t},\n+\t\t{\n+\t\t\tname: \"managed objects fetch failure\",\n+\t\t\trequest: &proto.BulkRegisterSecondaryHostsReq{\n+\t\t\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\t\t\tAccount: testAccountName,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t\tSecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\t\t\tHosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient, mockAuthz *authz.MockAuthzClient) {\n+\t\t\t\t// Managed objects fetch fails\n+\t\t\t\tmockAuthz.On(\"GetManagedObjects\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*proto.GetManagedObjectsRequest\")).Return(\n+\t\t\t\t\t(*authz.GetManagedObjectsResponse)(nil),\n+\t\t\t\t\terrors.New(\"authz service unavailable\"),\n+\t\t\t\t)\n+\t\t\t},\n+\t\t\texpectError:      true,\n+\t\t\texpectedGRPCCode: codes.InvalidArgument,\n+\t\t\texpectedErrorMsg: \"failed to fetch managed objects\",\n+\t\t},\n+\t\t{\n+\t\t\tname: \"OS type mismatch in managed objects\",\n+\t\t\trequest: &proto.BulkRegisterSecondaryHostsReq{\n+\t\t\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\t\t\tAccount: testAccountName,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t\tSecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\t\t\tHosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t\t\t{\n+\t\t\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\tsetupMocks: func(mockCRS *crs.MockCDMRestServiceClient, mockAuthz *authz.MockAuthzClient) {\n+\t\t\t\t// Managed objects fetch succeeds but OS type mismatches\n+\t\t\t\tmockAuthz.On(\"GetManagedObjects\",\n+\t\t\t\t\tmock.Anything,\n+\t\t\t\t\tmock.AnythingOfType(\"*proto.GetManagedObjectsRequest\")).Return(\n+\t\t\t\t\t&authz.GetManagedObjectsResponse{\n+\t\t\t\t\t\tObjects: []*aspb.ManagedObject{\n+\t\t\t\t\t\t\tcreateTestManagedObject(testHostFID1, testHostname1, WindowsOsType), // Wrong OS\n+\t\t\t\t\t\t},\n+\t\t\t\t\t}, nil)\n+\t\t\t},\n+\t\t\texpectError:      true,\n+\t\t\texpectedGRPCCode: codes.InvalidArgument,\n+\t\t\texpectedErrorMsg: \"OS type mismatch for host host-fid-1 - expected Linux, got Windows\",\n+\t\t},\n+\t}\n+\n+\tfor _, tt := range tests {\n+\t\tt.Run(tt.name, func(t *testing.T) {\n+\t\t\tmockCRS := &crs.MockCDMRestServiceClient{}\n+\t\t\tmockAuthz := &authz.MockAuthzClient{}\n+\t\t\ttt.setupMocks(mockCRS, mockAuthz)\n+\n+\t\t\t// Create service instance\n+\t\t\tservice := &PhysicalHostService{\n+\t\t\t\tcrsClient:   mockCRS,\n+\t\t\t\tauthzClient: mockAuthz,\n+\t\t\t}\n+\n+\t\t\tresult, err := service.BulkRegisterSecondaryHosts(ctx, tt.request)\n+\n+\t\t\tif tt.expectError {\n+\t\t\t\trequire.Error(t, err)\n+\n+\t\t\t\t// Verify gRPC status code\n+\t\t\t\tst, ok := status.FromError(err)\n+\t\t\t\trequire.True(t, ok, \"Expected gRPC status error\")\n+\t\t\t\tassert.Equal(t, tt.expectedGRPCCode, st.Code())\n+\t\t\t\tassert.Contains(t, st.Message(), tt.expectedErrorMsg)\n+\n+\t\t\t\t// Result should be nil on error\n+\t\t\t\tassert.Nil(t, result)\n+\t\t\t} else {\n+\t\t\t\trequire.NoError(t, err)\n+\t\t\t\trequire.NotNil(t, result)\n+\t\t\t\trequire.NotNil(t, result.HostResults)\n+\n+\t\t\t\t// Verify expected successful hosts\n+\t\t\t\tfor _, hostFid := range tt.expectedSuccessfulHosts {\n+\t\t\t\t\tfound := false\n+\t\t\t\t\tfor _, hostResult := range result.HostResults {\n+\t\t\t\t\t\tif hostResult.PrimaryHostFid == hostFid {\n+\t\t\t\t\t\t\tfound = true\n+\t\t\t\t\t\t\tassert.Empty(t, hostResult.ErrorMessage) // Success means no error\n+\t\t\t\t\t\t\tbreak\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t\tassert.True(t, found, \"Expected successful host %s not found in results\", hostFid)\n+\t\t\t\t}\n+\n+\t\t\t\t// Verify expected failed hosts\n+\t\t\t\tfor _, hostFid := range tt.expectedFailedHosts {\n+\t\t\t\t\tfound := false\n+\t\t\t\t\tfor _, hostResult := range result.HostResults {\n+\t\t\t\t\t\tif hostResult.PrimaryHostFid == hostFid {\n+\t\t\t\t\t\t\tfound = true\n+\t\t\t\t\t\t\tassert.NotEmpty(t, hostResult.ErrorMessage)\n+\t\t\t\t\t\t\tbreak\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t\tassert.True(t, found, \"Expected failed host %s not found in results\", hostFid)\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tmockCRS.AssertExpectations(t)\n+\t\t\tmockAuthz.AssertExpectations(t)\n+\t\t})\n+\t}\n+}\n+\n+// TestBulkRegisterSecondaryHostsPartialSuccess tests partial success scenarios\n+func TestBulkRegisterSecondaryHostsPartialSuccess(t *testing.T) {\n+\tctx := context.Background()\n+\n+\trequest := &proto.BulkRegisterSecondaryHostsReq{\n+\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\tAccount: testAccountName,\n+\t\t\t},\n+\t\t},\n+\t\tSecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\tHosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t{\n+\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t},\n+\t\t\t{\n+\t\t\t\tHostFid:            testHostFID2,\n+\t\t\t\tPrimaryClusterUuid: \"primary-cluster-uuid-2\",\n+\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_WINDOWS,\n+\t\t\t},\n+\t\t},\n+\t}\n+\n+\tmockCRS := &crs.MockCDMRestServiceClient{}\n+\tmockAuthz := &authz.MockAuthzClient{}\n+\n+\t// Fetch and verify managed objects - both succeed\n+\tmockAuthz.On(\"GetManagedObjects\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*proto.GetManagedObjectsRequest\")).Return(\n+\t\t&authz.GetManagedObjectsResponse{\n+\t\t\tObjects: []*aspb.ManagedObject{\n+\t\t\t\tcreateTestManagedObject(testHostFID1, testHostname1, LinuxOsType),\n+\t\t\t\tcreateTestManagedObject(testHostFID2, testHostname2, WindowsOsType),\n+\t\t\t},\n+\t\t}, nil)\n+\n+\t// Fetch secondary cluster certificate succeeds\n+\tmockCRS.On(\"V1GetClusterCertificateRPC\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*types.V1GetClusterCertificateRequest\")).Return(\n+\t\tcreateTestClusterCertificate(), nil,\n+\t)\n+\n+\t// Certificate transfer for cluster 1 succeeds\n+\tmockCRS.On(\"V1QueryCertificatesRPC\",\n+\t\tmock.Anything,\n+\t\tmock.MatchedBy(func(req *crstypes.V1QueryCertificatesRequest) bool {\n+\t\t\treturn req.ClusterUuid == testPrimaryClusterUUID1\n+\t\t})).Return(&crstypes.CertificateSummaryListResponse{Data: []*crstypes.CertificateSummary{}}, nil)\n+\n+\tmockCRS.On(\"V1ImportCertificateRPC\",\n+\t\tmock.Anything,\n+\t\tmock.MatchedBy(func(req *crstypes.V1ImportCertificateRequest) bool {\n+\t\t\treturn req.ClusterUuid == testPrimaryClusterUUID1\n+\t\t})).Return(createTestCertificateSummary(testCertID), nil)\n+\n+\tmockCRS.On(\"V1MarkAgentSecondaryCertificateRPC\",\n+\t\tmock.Anything,\n+\t\tmock.MatchedBy(func(req *crstypes.V1MarkAgentSecondaryCertificateRequest) bool {\n+\t\t\treturn req.ClusterUuid == testPrimaryClusterUUID1\n+\t\t})).Return(&crstypes.AgentSecondaryCertificateInfo{}, nil)\n+\n+\t// Certificate transfer for cluster 2 fails\n+\tmockCRS.On(\"V1QueryCertificatesRPC\",\n+\t\tmock.Anything,\n+\t\tmock.MatchedBy(func(req *crstypes.V1QueryCertificatesRequest) bool {\n+\t\t\treturn req.ClusterUuid == \"primary-cluster-uuid-2\"\n+\t\t})).Return((*crstypes.CertificateSummaryListResponse)(nil), errors.New(\"cluster 2 cert failed\"))\n+\n+\t// Host diagnosis for successful host\n+\tmockCRS.On(\"InternalGetHostDiagnosisRPC\",\n+\t\tmock.Anything,\n+\t\tmock.MatchedBy(func(req *crstypes.InternalGetHostDiagnosisRequest) bool {\n+\t\t\treturn req.Id == testHostFID1\n+\t\t})).Return(&crstypes.HostDiagnosisSummary{}, nil)\n+\n+\t// Bulk registration for successful host\n+\tmockCRS.On(\"V1BulkRegisterHostAsyncRPC\",\n+\t\tmock.Anything,\n+\t\tmock.MatchedBy(func(req *crstypes.V1BulkRegisterHostAsyncRequest) bool {\n+\t\t\treturn len(req.Hosts) == 1 && req.Hosts[0].Hostname == testHostname1\n+\t\t})).Return(&crstypes.V1BulkRegisterHostAsyncResponse{\n+\t\tItems: []*crstypes.HostDetail{},\n+\t}, nil)\n+\n+\t// Create service instance\n+\tservice := &PhysicalHostService{\n+\t\tcrsClient:   mockCRS,\n+\t\tauthzClient: mockAuthz,\n+\t}\n+\n+\tresult, err := service.BulkRegisterSecondaryHosts(ctx, request)\n+\n+\t// Should succeed overall but with mixed results\n+\trequire.NoError(t, err)\n+\trequire.NotNil(t, result)\n+\trequire.NotNil(t, result.HostResults)\n+\trequire.Equal(t, 2, len(result.HostResults))\n+\n+\t// Verify host 1 succeeded\n+\thost1Found := false\n+\thost2Found := false\n+\tfor _, hostResult := range result.HostResults {\n+\t\tif hostResult.PrimaryHostFid == testHostFID1 {\n+\t\t\thost1Found = true\n+\t\t\tassert.Empty(t, hostResult.ErrorMessage)\n+\t\t} else if hostResult.PrimaryHostFid == testHostFID2 {\n+\t\t\thost2Found = true\n+\t\t\tassert.NotEmpty(t, hostResult.ErrorMessage)\n+\t\t\tassert.Contains(t, hostResult.ErrorMessage, \"cluster 2 cert failed\")\n+\t\t}\n+\t}\n+\tassert.True(t, host1Found, \"Host 1 result not found\")\n+\tassert.True(t, host2Found, \"Host 2 result not found\")\n+\n+\tmockCRS.AssertExpectations(t)\n+\tmockAuthz.AssertExpectations(t)\n+}\n+\n+// TestBulkRegisterSecondaryHostsWithContextCancellation tests context cancellation\n+func TestBulkRegisterSecondaryHostsWithContextCancellation(t *testing.T) {\n+\tctx, cancel := context.WithCancel(context.Background())\n+\n+\trequest := &proto.BulkRegisterSecondaryHostsReq{\n+\t\tReqCtx: &contextproto.RequestContext{\n+\t\t\tAuthzCtx: &authzcommon.AuthorizationContext{\n+\t\t\t\tAccount: testAccountName,\n+\t\t\t},\n+\t\t},\n+\t\tSecondaryClusterUuid: testSecondaryClusterUUID,\n+\t\tHosts: []*proto.SecondaryRegisterHostInput{\n+\t\t\t{\n+\t\t\t\tHostFid:            testHostFID1,\n+\t\t\t\tPrimaryClusterUuid: testPrimaryClusterUUID1,\n+\t\t\t\tOsType:             crstypes.HostRegister_HOST_REGISTER_OS_TYPE_LINUX,\n+\t\t\t},\n+\t\t},\n+\t}\n+\n+\tmockCRS := &crs.MockCDMRestServiceClient{}\n+\tmockAuthz := &authz.MockAuthzClient{}\n+\n+\t// Set up mocks that may or may not be called due to cancellation\n+\tmockAuthz.On(\"GetManagedObjects\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*proto.GetManagedObjectsRequest\")).Return(\n+\t\t&authz.GetManagedObjectsResponse{\n+\t\t\tObjects: []*aspb.ManagedObject{\n+\t\t\t\tcreateTestManagedObject(testHostFID1, testHostname1, LinuxOsType),\n+\t\t\t},\n+\t\t}, nil).Maybe()\n+\n+\tmockCRS.On(\"V1GetClusterCertificateRPC\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*types.V1GetClusterCertificateRequest\")).Return(\n+\t\tcreateTestClusterCertificate(), nil,\n+\t).Maybe()\n+\n+\tmockCRS.On(\"V1QueryCertificatesRPC\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*types.V1QueryCertificatesRequest\")).Return(\n+\t\t&crstypes.CertificateSummaryListResponse{Data: []*crstypes.CertificateSummary{}},\n+\t\tnil,\n+\t).Maybe()\n+\n+\tmockCRS.On(\"V1ImportCertificateRPC\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*types.V1ImportCertificateRequest\")).Return(\n+\t\tcreateTestCertificateSummary(testCertID), nil,\n+\t).Maybe()\n+\n+\tmockCRS.On(\"V1MarkAgentSecondaryCertificateRPC\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*types.V1MarkAgentSecondaryCertificateRequest\")).Return(\n+\t\t&crstypes.AgentSecondaryCertificateInfo{}, nil,\n+\t).Maybe()\n+\n+\tmockCRS.On(\"InternalGetHostDiagnosisRPC\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*types.InternalGetHostDiagnosisRequest\")).Return(\n+\t\t&crstypes.HostDiagnosisSummary{}, nil,\n+\t).Maybe()\n+\n+\tmockCRS.On(\"V1BulkRegisterHostAsyncRPC\",\n+\t\tmock.Anything,\n+\t\tmock.AnythingOfType(\"*types.V1BulkRegisterHostAsyncRequest\")).Return(\n+\t\t&crstypes.V1BulkRegisterHostAsyncResponse{Items: []*crstypes.HostDetail{}}, nil,\n+\t).Maybe()\n+\n+\t// Create service instance\n+\tservice := &PhysicalHostService{\n+\t\tcrsClient:   mockCRS,\n+\t\tauthzClient: mockAuthz,\n+\t}\n+\n+\t// Cancel context immediately\n+\tcancel()\n+\n+\tresult, err := service.BulkRegisterSecondaryHosts(ctx, request)\n+\n+\t// The function should handle cancellation gracefully\n+\t// We can't assert exact behavior since cancellation timing is unpredictable\n+\t// But it should not panic and should return some result\n+\tif err != nil {\n+\t\t// If error, it should be context-related\n+\t\tassert.Contains(t, err.Error(), \"context\")\n+\t} else {\n+\t\t// If no error, result should be valid\n+\t\tassert.NotNil(t, result)\n+\t}\n+}"
        }
      ],
      "statistics": {
        "commits": 6,
        "files_changed": 2,
        "additions": 2360,
        "deletions": 0,
        "total_comments": 2
      }
    },
    "processed_data": {
      "title": "PR Review: Add unit tests for bulk secondary registration api",
      "summary": "## Summary:\nAdded unit tests for bulk secondary registration api.\n\n## Test Plan:\nUnit tests\n\n## JIRA Issues:\nSPARK-572184\n\n## Revert Plan:\n## PR Stack:\nStack from arc wrapper with help from [ghstack](...",
      "action_items": [
        {
          "item": "Review PR: Add unit tests for bulk secondary registration api",
          "priority": "medium",
          "next_steps": [
            "Read description",
            "Review code changes",
            "Test locally"
          ]
        }
      ],
      "urgency_score": 1.0,
      "context": "GitHub PR in gh/moht-agrawal-rubrik/16/head branch"
    }
  }
]
